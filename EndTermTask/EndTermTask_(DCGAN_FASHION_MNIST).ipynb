{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NAME : TRIANTO HARYO NUGROHO**\n",
        "\n",
        "**NPM : 2306288931**"
      ],
      "metadata": {
        "id": "1KkOzXyFblMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Import Library"
      ],
      "metadata": {
        "id": "yhYzu_Ofbrjo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BePWLCx7bgHZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Reshape\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, UpSampling2D, Dense, Reshape, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Generator Model Function"
      ],
      "metadata": {
        "id": "R1djPEB2c36I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units=1024, input_dim=100))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(Dense(128*7*7))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
        "  model.add(UpSampling2D(size=(2, 2)))\n",
        "  model.add(Conv2D(64, (5, 5), padding='same'))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(UpSampling2D(size=(2, 2)))\n",
        "  model.add(Conv2D(1, (5, 5), padding='same'))\n",
        "  model.add(Activation('tanh'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "bl6SpTrWdBZX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Discriminator Model Function"
      ],
      "metadata": {
        "id": "dANRt01MeQX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (5, 5), padding='same', input_shape=(28, 28, 1)))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(128, (5, 5)))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "jJxJQu1BeUCd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Generator Containing Discriminator Function"
      ],
      "metadata": {
        "id": "7dzUBdeRfLSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_containing_discriminator(g, d):\n",
        "  model = Sequential()\n",
        "  model.add(g)\n",
        "  d.trainable = False\n",
        "  model.add(d)\n",
        "  return model"
      ],
      "metadata": {
        "id": "4Y6096HmfPVA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Combines Image Function"
      ],
      "metadata": {
        "id": "9wwhG-0hfgb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_images(generated_images):\n",
        "  num = generated_images.shape[0]\n",
        "  width = int(math.sqrt(num))\n",
        "  height = int(math.ceil(float(num)/width))\n",
        "  shape = generated_images.shape[1:3]\n",
        "  image = np.zeros((height*shape[0], width*shape[1]), dtype=generated_images.dtype)\n",
        "  for index, img in enumerate(generated_images):\n",
        "    i = int(index/width)\n",
        "    j = index % width\n",
        "    image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]]= img[:, :, 0]\n",
        "  return image\n"
      ],
      "metadata": {
        "id": "P3gvvqQdfkkr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Training Function"
      ],
      "metadata": {
        "id": "tsYYoDX7g4IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(BATCH_SIZE):\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "\n",
        "    # Create discriminator and generator models\n",
        "    d = discriminator_model()\n",
        "    g = generator_model()\n",
        "    d_on_g = generator_containing_discriminator(g, d)\n",
        "\n",
        "    # Optimizers for generator and discriminator\n",
        "    d_optim = SGD(learning_rate=0.0005, momentum=0.9, nesterov=True)\n",
        "    g_optim = SGD(learning_rate=0.0005, momentum=0.9, nesterov=True)\n",
        "\n",
        "    g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "    d.trainable = True\n",
        "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(20):\n",
        "        print(f\"Epoch is {epoch}\")\n",
        "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
        "            # Generate noise for the generator\n",
        "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
        "\n",
        "            # Get a batch of real images\n",
        "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
        "\n",
        "            # Generate images from the noise\n",
        "            generated_images = g.predict(noise, verbose=0)\n",
        "\n",
        "            # Save generated images every 20 batches\n",
        "            if index % 20 == 0:\n",
        "                image = combine_images(generated_images)\n",
        "                image = image*127.5+127.5\n",
        "                Image.fromarray(image.astype(np.uint8)).save(f\"{epoch}_{index}.png\")\n",
        "\n",
        "            # Train discriminator\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = np.concatenate((np.ones(BATCH_SIZE), np.zeros(BATCH_SIZE)))\n",
        "            d_loss = d.train_on_batch(X, y)\n",
        "            print(f\"Batch {index} d_loss: {d_loss}\")\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
        "            d.trainable = False\n",
        "            g_loss = d_on_g.train_on_batch(noise, np.ones(BATCH_SIZE))\n",
        "            d.trainable = True\n",
        "            print(f\"Batch {index} g_loss: {g_loss}\")\n",
        "\n",
        "            # Save weights of generator and discriminator every 10 batches\n",
        "            if index % 10 == 9:\n",
        "                g.save_weights('generator.weights.h5')\n",
        "                d.save_weights('discriminator.weights.h5')\n"
      ],
      "metadata": {
        "id": "-PjekcK8kwP5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Image Generation Function"
      ],
      "metadata": {
        "id": "Apwq7vvmkz6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(BATCH_SIZE, nice=False):\n",
        "  g = generator_model()\n",
        "  g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "  g.load_weights('generator')\n",
        "  if nice:\n",
        "    d = discriminator_model()\n",
        "    d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    d.load_weights('discriminator')\n",
        "    noise = np.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
        "    generated_images = g.predict(noise, verbose=1)\n",
        "    d_pred = d.predict(generated_images, verbose=1)\n",
        "    index = np.arange(0, BATCH_SIZE*20)\n",
        "    index.resize((BATCH_SIZE*20, 1))\n",
        "    pre_with_index = list(np.append(d_pred, index, axis=1))\n",
        "    pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
        "    nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
        "    nice_images = nice_images[:, :, :, None]\n",
        "    for i in range(BATCH_SIZE):\n",
        "      idx = int(pre_with_index[1][1])\n",
        "      nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
        "    image = combine_images(nice_images)\n",
        "  else:\n",
        "    noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
        "    generated_images = g.predict(noise, verbose=1)\n",
        "    image = combine_images(generated_images)\n",
        "  image = image*127.5+127.5\n",
        "  Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")"
      ],
      "metadata": {
        "id": "OuGjgnSrk5LT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow keras numpy pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t2XVffSpbYa",
        "outputId": "25d23148-2bbb-4e70-94d5-f8b2d31e2473"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set BATCH_SIZE and EPOCHS\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 1\n",
        "\n",
        "# Train the GAN\n",
        "train(BATCH_SIZE)\n",
        "\n",
        "# Generate images after training\n",
        "generate(BATCH_SIZE, nice=False)  # For raw generated images\n",
        "generate(BATCH_SIZE, nice=True)   # For discriminator-selected images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkeLNMm5pjdM",
        "outputId": "969dc1ea-6776-4fc2-e34e-ef31d964242b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch is 0\n",
            "Batch 0 d_loss: 0.6492831707000732\n",
            "Batch 0 g_loss: [array(0.6492832, dtype=float32), array(0.6492832, dtype=float32), array(0.6492832, dtype=float32)]\n",
            "Batch 1 d_loss: 0.6477748155593872\n",
            "Batch 1 g_loss: [array(0.6477748, dtype=float32), array(0.6477748, dtype=float32), array(0.6477748, dtype=float32)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7f7ed493f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 2 d_loss: 0.6468207240104675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7f7ec00e6320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 2 g_loss: [array(0.6468207, dtype=float32), array(0.6468207, dtype=float32), array(0.6468207, dtype=float32)]\n",
            "Batch 3 d_loss: 0.6449121236801147\n",
            "Batch 3 g_loss: [array(0.6449121, dtype=float32), array(0.6449121, dtype=float32), array(0.6449121, dtype=float32)]\n",
            "Batch 4 d_loss: 0.6439757347106934\n",
            "Batch 4 g_loss: [array(0.64397573, dtype=float32), array(0.64397573, dtype=float32), array(0.64397573, dtype=float32)]\n",
            "Batch 5 d_loss: 0.6414857506752014\n",
            "Batch 5 g_loss: [array(0.64148575, dtype=float32), array(0.64148575, dtype=float32), array(0.64148575, dtype=float32)]\n",
            "Batch 6 d_loss: 0.6389860510826111\n",
            "Batch 6 g_loss: [array(0.63898605, dtype=float32), array(0.63898605, dtype=float32), array(0.63898605, dtype=float32)]\n",
            "Batch 7 d_loss: 0.6366456747055054\n",
            "Batch 7 g_loss: [array(0.6366457, dtype=float32), array(0.6366457, dtype=float32), array(0.6366457, dtype=float32)]\n",
            "Batch 8 d_loss: 0.6340944170951843\n",
            "Batch 8 g_loss: [array(0.6340944, dtype=float32), array(0.6340944, dtype=float32), array(0.6340944, dtype=float32)]\n",
            "Batch 9 d_loss: 0.6316824555397034\n",
            "Batch 9 g_loss: [array(0.63168246, dtype=float32), array(0.63168246, dtype=float32), array(0.63168246, dtype=float32)]\n",
            "Batch 10 d_loss: 0.629420816898346\n",
            "Batch 10 g_loss: [array(0.6294208, dtype=float32), array(0.6294208, dtype=float32), array(0.6294208, dtype=float32)]\n",
            "Batch 11 d_loss: 0.6266639232635498\n",
            "Batch 11 g_loss: [array(0.6266639, dtype=float32), array(0.6266639, dtype=float32), array(0.6266639, dtype=float32)]\n",
            "Batch 12 d_loss: 0.6242644786834717\n",
            "Batch 12 g_loss: [array(0.6242645, dtype=float32), array(0.6242645, dtype=float32), array(0.6242645, dtype=float32)]\n",
            "Batch 13 d_loss: 0.6213477253913879\n",
            "Batch 13 g_loss: [array(0.6213477, dtype=float32), array(0.6213477, dtype=float32), array(0.6213477, dtype=float32)]\n",
            "Batch 14 d_loss: 0.6186849474906921\n",
            "Batch 14 g_loss: [array(0.61868495, dtype=float32), array(0.61868495, dtype=float32), array(0.61868495, dtype=float32)]\n",
            "Batch 15 d_loss: 0.6159684658050537\n",
            "Batch 15 g_loss: [array(0.61596847, dtype=float32), array(0.61596847, dtype=float32), array(0.61596847, dtype=float32)]\n",
            "Batch 16 d_loss: 0.6134573817253113\n",
            "Batch 16 g_loss: [array(0.6134574, dtype=float32), array(0.6134574, dtype=float32), array(0.6134574, dtype=float32)]\n",
            "Batch 17 d_loss: 0.6107622385025024\n",
            "Batch 17 g_loss: [array(0.61076224, dtype=float32), array(0.61076224, dtype=float32), array(0.61076224, dtype=float32)]\n",
            "Batch 18 d_loss: 0.6080427169799805\n",
            "Batch 18 g_loss: [array(0.6080427, dtype=float32), array(0.6080427, dtype=float32), array(0.6080427, dtype=float32)]\n",
            "Batch 19 d_loss: 0.6053932309150696\n",
            "Batch 19 g_loss: [array(0.60539323, dtype=float32), array(0.60539323, dtype=float32), array(0.60539323, dtype=float32)]\n",
            "Batch 20 d_loss: 0.6030752658843994\n",
            "Batch 20 g_loss: [array(0.60307527, dtype=float32), array(0.60307527, dtype=float32), array(0.60307527, dtype=float32)]\n",
            "Batch 21 d_loss: 0.600587785243988\n",
            "Batch 21 g_loss: [array(0.6005878, dtype=float32), array(0.6005878, dtype=float32), array(0.6005878, dtype=float32)]\n",
            "Batch 22 d_loss: 0.5980865359306335\n",
            "Batch 22 g_loss: [array(0.59808654, dtype=float32), array(0.59808654, dtype=float32), array(0.59808654, dtype=float32)]\n",
            "Batch 23 d_loss: 0.5957127809524536\n",
            "Batch 23 g_loss: [array(0.5957128, dtype=float32), array(0.5957128, dtype=float32), array(0.5957128, dtype=float32)]\n",
            "Batch 24 d_loss: 0.5935680270195007\n",
            "Batch 24 g_loss: [array(0.593568, dtype=float32), array(0.593568, dtype=float32), array(0.593568, dtype=float32)]\n",
            "Batch 25 d_loss: 0.5912282466888428\n",
            "Batch 25 g_loss: [array(0.59122825, dtype=float32), array(0.59122825, dtype=float32), array(0.59122825, dtype=float32)]\n",
            "Batch 26 d_loss: 0.5888554453849792\n",
            "Batch 26 g_loss: [array(0.58885545, dtype=float32), array(0.58885545, dtype=float32), array(0.58885545, dtype=float32)]\n",
            "Batch 27 d_loss: 0.5865266919136047\n",
            "Batch 27 g_loss: [array(0.5865267, dtype=float32), array(0.5865267, dtype=float32), array(0.5865267, dtype=float32)]\n",
            "Batch 28 d_loss: 0.5847132205963135\n",
            "Batch 28 g_loss: [array(0.5847132, dtype=float32), array(0.5847132, dtype=float32), array(0.5847132, dtype=float32)]\n",
            "Batch 29 d_loss: 0.5825963616371155\n",
            "Batch 29 g_loss: [array(0.58259636, dtype=float32), array(0.58259636, dtype=float32), array(0.58259636, dtype=float32)]\n",
            "Batch 30 d_loss: 0.5808533430099487\n",
            "Batch 30 g_loss: [array(0.58085334, dtype=float32), array(0.58085334, dtype=float32), array(0.58085334, dtype=float32)]\n",
            "Batch 31 d_loss: 0.578653872013092\n",
            "Batch 31 g_loss: [array(0.5786539, dtype=float32), array(0.5786539, dtype=float32), array(0.5786539, dtype=float32)]\n",
            "Batch 32 d_loss: 0.5764961242675781\n",
            "Batch 32 g_loss: [array(0.5764961, dtype=float32), array(0.5764961, dtype=float32), array(0.5764961, dtype=float32)]\n",
            "Batch 33 d_loss: 0.5747417211532593\n",
            "Batch 33 g_loss: [array(0.5747417, dtype=float32), array(0.5747417, dtype=float32), array(0.5747417, dtype=float32)]\n",
            "Batch 34 d_loss: 0.5731874704360962\n",
            "Batch 34 g_loss: [array(0.5731875, dtype=float32), array(0.5731875, dtype=float32), array(0.5731875, dtype=float32)]\n",
            "Batch 35 d_loss: 0.5715423226356506\n",
            "Batch 35 g_loss: [array(0.5715423, dtype=float32), array(0.5715423, dtype=float32), array(0.5715423, dtype=float32)]\n",
            "Batch 36 d_loss: 0.5697230696678162\n",
            "Batch 36 g_loss: [array(0.56972307, dtype=float32), array(0.56972307, dtype=float32), array(0.56972307, dtype=float32)]\n",
            "Batch 37 d_loss: 0.5681179165840149\n",
            "Batch 37 g_loss: [array(0.5681179, dtype=float32), array(0.5681179, dtype=float32), array(0.5681179, dtype=float32)]\n",
            "Batch 38 d_loss: 0.5664108395576477\n",
            "Batch 38 g_loss: [array(0.56641084, dtype=float32), array(0.56641084, dtype=float32), array(0.56641084, dtype=float32)]\n",
            "Batch 39 d_loss: 0.5648036003112793\n",
            "Batch 39 g_loss: [array(0.5648036, dtype=float32), array(0.5648036, dtype=float32), array(0.5648036, dtype=float32)]\n",
            "Batch 40 d_loss: 0.5633072853088379\n",
            "Batch 40 g_loss: [array(0.5633073, dtype=float32), array(0.5633073, dtype=float32), array(0.5633073, dtype=float32)]\n",
            "Batch 41 d_loss: 0.5619392395019531\n",
            "Batch 41 g_loss: [array(0.56193924, dtype=float32), array(0.56193924, dtype=float32), array(0.56193924, dtype=float32)]\n",
            "Batch 42 d_loss: 0.5605738162994385\n",
            "Batch 42 g_loss: [array(0.5605738, dtype=float32), array(0.5605738, dtype=float32), array(0.5605738, dtype=float32)]\n",
            "Batch 43 d_loss: 0.5592017769813538\n",
            "Batch 43 g_loss: [array(0.5592018, dtype=float32), array(0.5592018, dtype=float32), array(0.5592018, dtype=float32)]\n",
            "Batch 44 d_loss: 0.5577101111412048\n",
            "Batch 44 g_loss: [array(0.5577101, dtype=float32), array(0.5577101, dtype=float32), array(0.5577101, dtype=float32)]\n",
            "Batch 45 d_loss: 0.5563622713088989\n",
            "Batch 45 g_loss: [array(0.5563623, dtype=float32), array(0.5563623, dtype=float32), array(0.5563623, dtype=float32)]\n",
            "Batch 46 d_loss: 0.5550081133842468\n",
            "Batch 46 g_loss: [array(0.5550081, dtype=float32), array(0.5550081, dtype=float32), array(0.5550081, dtype=float32)]\n",
            "Batch 47 d_loss: 0.5536245703697205\n",
            "Batch 47 g_loss: [array(0.5536246, dtype=float32), array(0.5536246, dtype=float32), array(0.5536246, dtype=float32)]\n",
            "Batch 48 d_loss: 0.5522334575653076\n",
            "Batch 48 g_loss: [array(0.55223346, dtype=float32), array(0.55223346, dtype=float32), array(0.55223346, dtype=float32)]\n",
            "Batch 49 d_loss: 0.5509808659553528\n",
            "Batch 49 g_loss: [array(0.55098087, dtype=float32), array(0.55098087, dtype=float32), array(0.55098087, dtype=float32)]\n",
            "Batch 50 d_loss: 0.549762487411499\n",
            "Batch 50 g_loss: [array(0.5497625, dtype=float32), array(0.5497625, dtype=float32), array(0.5497625, dtype=float32)]\n",
            "Batch 51 d_loss: 0.54863440990448\n",
            "Batch 51 g_loss: [array(0.5486344, dtype=float32), array(0.5486344, dtype=float32), array(0.5486344, dtype=float32)]\n",
            "Batch 52 d_loss: 0.5474638938903809\n",
            "Batch 52 g_loss: [array(0.5474639, dtype=float32), array(0.5474639, dtype=float32), array(0.5474639, dtype=float32)]\n",
            "Batch 53 d_loss: 0.5462803840637207\n",
            "Batch 53 g_loss: [array(0.5462804, dtype=float32), array(0.5462804, dtype=float32), array(0.5462804, dtype=float32)]\n",
            "Batch 54 d_loss: 0.5451093316078186\n",
            "Batch 54 g_loss: [array(0.54510933, dtype=float32), array(0.54510933, dtype=float32), array(0.54510933, dtype=float32)]\n",
            "Batch 55 d_loss: 0.5438242554664612\n",
            "Batch 55 g_loss: [array(0.54382426, dtype=float32), array(0.54382426, dtype=float32), array(0.54382426, dtype=float32)]\n",
            "Batch 56 d_loss: 0.5426604747772217\n",
            "Batch 56 g_loss: [array(0.5426605, dtype=float32), array(0.5426605, dtype=float32), array(0.5426605, dtype=float32)]\n",
            "Batch 57 d_loss: 0.5414769053459167\n",
            "Batch 57 g_loss: [array(0.5414769, dtype=float32), array(0.5414769, dtype=float32), array(0.5414769, dtype=float32)]\n",
            "Batch 58 d_loss: 0.5402576327323914\n",
            "Batch 58 g_loss: [array(0.54025763, dtype=float32), array(0.54025763, dtype=float32), array(0.54025763, dtype=float32)]\n",
            "Batch 59 d_loss: 0.5391749739646912\n",
            "Batch 59 g_loss: [array(0.539175, dtype=float32), array(0.539175, dtype=float32), array(0.539175, dtype=float32)]\n",
            "Batch 60 d_loss: 0.5378409028053284\n",
            "Batch 60 g_loss: [array(0.5378409, dtype=float32), array(0.5378409, dtype=float32), array(0.5378409, dtype=float32)]\n",
            "Batch 61 d_loss: 0.5367873311042786\n",
            "Batch 61 g_loss: [array(0.53678733, dtype=float32), array(0.53678733, dtype=float32), array(0.53678733, dtype=float32)]\n",
            "Batch 62 d_loss: 0.535625159740448\n",
            "Batch 62 g_loss: [array(0.53562516, dtype=float32), array(0.53562516, dtype=float32), array(0.53562516, dtype=float32)]\n",
            "Batch 63 d_loss: 0.5345785617828369\n",
            "Batch 63 g_loss: [array(0.53457856, dtype=float32), array(0.53457856, dtype=float32), array(0.53457856, dtype=float32)]\n",
            "Batch 64 d_loss: 0.5333613753318787\n",
            "Batch 64 g_loss: [array(0.5333614, dtype=float32), array(0.5333614, dtype=float32), array(0.5333614, dtype=float32)]\n",
            "Batch 65 d_loss: 0.532274603843689\n",
            "Batch 65 g_loss: [array(0.5322746, dtype=float32), array(0.5322746, dtype=float32), array(0.5322746, dtype=float32)]\n",
            "Batch 66 d_loss: 0.5310046672821045\n",
            "Batch 66 g_loss: [array(0.53100467, dtype=float32), array(0.53100467, dtype=float32), array(0.53100467, dtype=float32)]\n",
            "Batch 67 d_loss: 0.5298234224319458\n",
            "Batch 67 g_loss: [array(0.5298234, dtype=float32), array(0.5298234, dtype=float32), array(0.5298234, dtype=float32)]\n",
            "Batch 68 d_loss: 0.528537392616272\n",
            "Batch 68 g_loss: [array(0.5285374, dtype=float32), array(0.5285374, dtype=float32), array(0.5285374, dtype=float32)]\n",
            "Batch 69 d_loss: 0.5273871421813965\n",
            "Batch 69 g_loss: [array(0.52738714, dtype=float32), array(0.52738714, dtype=float32), array(0.52738714, dtype=float32)]\n",
            "Batch 70 d_loss: 0.5261791944503784\n",
            "Batch 70 g_loss: [array(0.5261792, dtype=float32), array(0.5261792, dtype=float32), array(0.5261792, dtype=float32)]\n",
            "Batch 71 d_loss: 0.525015652179718\n",
            "Batch 71 g_loss: [array(0.52501565, dtype=float32), array(0.52501565, dtype=float32), array(0.52501565, dtype=float32)]\n",
            "Batch 72 d_loss: 0.5237363576889038\n",
            "Batch 72 g_loss: [array(0.52373636, dtype=float32), array(0.52373636, dtype=float32), array(0.52373636, dtype=float32)]\n",
            "Batch 73 d_loss: 0.522472083568573\n",
            "Batch 73 g_loss: [array(0.5224721, dtype=float32), array(0.5224721, dtype=float32), array(0.5224721, dtype=float32)]\n",
            "Batch 74 d_loss: 0.5212099552154541\n",
            "Batch 74 g_loss: [array(0.52120996, dtype=float32), array(0.52120996, dtype=float32), array(0.52120996, dtype=float32)]\n",
            "Batch 75 d_loss: 0.519791305065155\n",
            "Batch 75 g_loss: [array(0.5197913, dtype=float32), array(0.5197913, dtype=float32), array(0.5197913, dtype=float32)]\n",
            "Batch 76 d_loss: 0.5184293985366821\n",
            "Batch 76 g_loss: [array(0.5184294, dtype=float32), array(0.5184294, dtype=float32), array(0.5184294, dtype=float32)]\n",
            "Batch 77 d_loss: 0.5169891715049744\n",
            "Batch 77 g_loss: [array(0.5169892, dtype=float32), array(0.5169892, dtype=float32), array(0.5169892, dtype=float32)]\n",
            "Batch 78 d_loss: 0.5156193971633911\n",
            "Batch 78 g_loss: [array(0.5156194, dtype=float32), array(0.5156194, dtype=float32), array(0.5156194, dtype=float32)]\n",
            "Batch 79 d_loss: 0.5142948031425476\n",
            "Batch 79 g_loss: [array(0.5142948, dtype=float32), array(0.5142948, dtype=float32), array(0.5142948, dtype=float32)]\n",
            "Batch 80 d_loss: 0.5131469964981079\n",
            "Batch 80 g_loss: [array(0.513147, dtype=float32), array(0.513147, dtype=float32), array(0.513147, dtype=float32)]\n",
            "Batch 81 d_loss: 0.5118584632873535\n",
            "Batch 81 g_loss: [array(0.51185846, dtype=float32), array(0.51185846, dtype=float32), array(0.51185846, dtype=float32)]\n",
            "Batch 82 d_loss: 0.5104061961174011\n",
            "Batch 82 g_loss: [array(0.5104062, dtype=float32), array(0.5104062, dtype=float32), array(0.5104062, dtype=float32)]\n",
            "Batch 83 d_loss: 0.5091854929924011\n",
            "Batch 83 g_loss: [array(0.5091855, dtype=float32), array(0.5091855, dtype=float32), array(0.5091855, dtype=float32)]\n",
            "Batch 84 d_loss: 0.5078274011611938\n",
            "Batch 84 g_loss: [array(0.5078274, dtype=float32), array(0.5078274, dtype=float32), array(0.5078274, dtype=float32)]\n",
            "Batch 85 d_loss: 0.5065856575965881\n",
            "Batch 85 g_loss: [array(0.50658566, dtype=float32), array(0.50658566, dtype=float32), array(0.50658566, dtype=float32)]\n",
            "Batch 86 d_loss: 0.505246102809906\n",
            "Batch 86 g_loss: [array(0.5052461, dtype=float32), array(0.5052461, dtype=float32), array(0.5052461, dtype=float32)]\n",
            "Batch 87 d_loss: 0.5037708878517151\n",
            "Batch 87 g_loss: [array(0.5037709, dtype=float32), array(0.5037709, dtype=float32), array(0.5037709, dtype=float32)]\n",
            "Batch 88 d_loss: 0.5023424029350281\n",
            "Batch 88 g_loss: [array(0.5023424, dtype=float32), array(0.5023424, dtype=float32), array(0.5023424, dtype=float32)]\n",
            "Batch 89 d_loss: 0.5009230971336365\n",
            "Batch 89 g_loss: [array(0.5009231, dtype=float32), array(0.5009231, dtype=float32), array(0.5009231, dtype=float32)]\n",
            "Batch 90 d_loss: 0.4994092285633087\n",
            "Batch 90 g_loss: [array(0.49940923, dtype=float32), array(0.49940923, dtype=float32), array(0.49940923, dtype=float32)]\n",
            "Batch 91 d_loss: 0.4980766475200653\n",
            "Batch 91 g_loss: [array(0.49807665, dtype=float32), array(0.49807665, dtype=float32), array(0.49807665, dtype=float32)]\n",
            "Batch 92 d_loss: 0.4969431161880493\n",
            "Batch 92 g_loss: [array(0.49694312, dtype=float32), array(0.49694312, dtype=float32), array(0.49694312, dtype=float32)]\n",
            "Batch 93 d_loss: 0.495766818523407\n",
            "Batch 93 g_loss: [array(0.49576682, dtype=float32), array(0.49576682, dtype=float32), array(0.49576682, dtype=float32)]\n",
            "Batch 94 d_loss: 0.4944641888141632\n",
            "Batch 94 g_loss: [array(0.4944642, dtype=float32), array(0.4944642, dtype=float32), array(0.4944642, dtype=float32)]\n",
            "Batch 95 d_loss: 0.49322763085365295\n",
            "Batch 95 g_loss: [array(0.49322763, dtype=float32), array(0.49322763, dtype=float32), array(0.49322763, dtype=float32)]\n",
            "Batch 96 d_loss: 0.4916650354862213\n",
            "Batch 96 g_loss: [array(0.49166504, dtype=float32), array(0.49166504, dtype=float32), array(0.49166504, dtype=float32)]\n",
            "Batch 97 d_loss: 0.4903036653995514\n",
            "Batch 97 g_loss: [array(0.49030367, dtype=float32), array(0.49030367, dtype=float32), array(0.49030367, dtype=float32)]\n",
            "Batch 98 d_loss: 0.4888087809085846\n",
            "Batch 98 g_loss: [array(0.48880878, dtype=float32), array(0.48880878, dtype=float32), array(0.48880878, dtype=float32)]\n",
            "Batch 99 d_loss: 0.4871968924999237\n",
            "Batch 99 g_loss: [array(0.4871969, dtype=float32), array(0.4871969, dtype=float32), array(0.4871969, dtype=float32)]\n",
            "Batch 100 d_loss: 0.4858504831790924\n",
            "Batch 100 g_loss: [array(0.48585048, dtype=float32), array(0.48585048, dtype=float32), array(0.48585048, dtype=float32)]\n",
            "Batch 101 d_loss: 0.4845120310783386\n",
            "Batch 101 g_loss: [array(0.48451203, dtype=float32), array(0.48451203, dtype=float32), array(0.48451203, dtype=float32)]\n",
            "Batch 102 d_loss: 0.48308491706848145\n",
            "Batch 102 g_loss: [array(0.48308492, dtype=float32), array(0.48308492, dtype=float32), array(0.48308492, dtype=float32)]\n",
            "Batch 103 d_loss: 0.4815990626811981\n",
            "Batch 103 g_loss: [array(0.48159906, dtype=float32), array(0.48159906, dtype=float32), array(0.48159906, dtype=float32)]\n",
            "Batch 104 d_loss: 0.4802415370941162\n",
            "Batch 104 g_loss: [array(0.48024154, dtype=float32), array(0.48024154, dtype=float32), array(0.48024154, dtype=float32)]\n",
            "Batch 105 d_loss: 0.47906577587127686\n",
            "Batch 105 g_loss: [array(0.47906578, dtype=float32), array(0.47906578, dtype=float32), array(0.47906578, dtype=float32)]\n",
            "Batch 106 d_loss: 0.4777524471282959\n",
            "Batch 106 g_loss: [array(0.47775245, dtype=float32), array(0.47775245, dtype=float32), array(0.47775245, dtype=float32)]\n",
            "Batch 107 d_loss: 0.476511150598526\n",
            "Batch 107 g_loss: [array(0.47651115, dtype=float32), array(0.47651115, dtype=float32), array(0.47651115, dtype=float32)]\n",
            "Batch 108 d_loss: 0.4751484990119934\n",
            "Batch 108 g_loss: [array(0.4751485, dtype=float32), array(0.4751485, dtype=float32), array(0.4751485, dtype=float32)]\n",
            "Batch 109 d_loss: 0.47404029965400696\n",
            "Batch 109 g_loss: [array(0.4740403, dtype=float32), array(0.4740403, dtype=float32), array(0.4740403, dtype=float32)]\n",
            "Batch 110 d_loss: 0.47291243076324463\n",
            "Batch 110 g_loss: [array(0.47291243, dtype=float32), array(0.47291243, dtype=float32), array(0.47291243, dtype=float32)]\n",
            "Batch 111 d_loss: 0.4716617465019226\n",
            "Batch 111 g_loss: [array(0.47166175, dtype=float32), array(0.47166175, dtype=float32), array(0.47166175, dtype=float32)]\n",
            "Batch 112 d_loss: 0.4702070653438568\n",
            "Batch 112 g_loss: [array(0.47020707, dtype=float32), array(0.47020707, dtype=float32), array(0.47020707, dtype=float32)]\n",
            "Batch 113 d_loss: 0.4689556956291199\n",
            "Batch 113 g_loss: [array(0.4689557, dtype=float32), array(0.4689557, dtype=float32), array(0.4689557, dtype=float32)]\n",
            "Batch 114 d_loss: 0.4677729308605194\n",
            "Batch 114 g_loss: [array(0.46777293, dtype=float32), array(0.46777293, dtype=float32), array(0.46777293, dtype=float32)]\n",
            "Batch 115 d_loss: 0.4664960205554962\n",
            "Batch 115 g_loss: [array(0.46649602, dtype=float32), array(0.46649602, dtype=float32), array(0.46649602, dtype=float32)]\n",
            "Batch 116 d_loss: 0.46509456634521484\n",
            "Batch 116 g_loss: [array(0.46509457, dtype=float32), array(0.46509457, dtype=float32), array(0.46509457, dtype=float32)]\n",
            "Batch 117 d_loss: 0.46383392810821533\n",
            "Batch 117 g_loss: [array(0.46383393, dtype=float32), array(0.46383393, dtype=float32), array(0.46383393, dtype=float32)]\n",
            "Batch 118 d_loss: 0.46283861994743347\n",
            "Batch 118 g_loss: [array(0.46283862, dtype=float32), array(0.46283862, dtype=float32), array(0.46283862, dtype=float32)]\n",
            "Batch 119 d_loss: 0.4617446959018707\n",
            "Batch 119 g_loss: [array(0.4617447, dtype=float32), array(0.4617447, dtype=float32), array(0.4617447, dtype=float32)]\n",
            "Batch 120 d_loss: 0.4606648087501526\n",
            "Batch 120 g_loss: [array(0.4606648, dtype=float32), array(0.4606648, dtype=float32), array(0.4606648, dtype=float32)]\n",
            "Batch 121 d_loss: 0.4596264660358429\n",
            "Batch 121 g_loss: [array(0.45962647, dtype=float32), array(0.45962647, dtype=float32), array(0.45962647, dtype=float32)]\n",
            "Batch 122 d_loss: 0.45853695273399353\n",
            "Batch 122 g_loss: [array(0.45853695, dtype=float32), array(0.45853695, dtype=float32), array(0.45853695, dtype=float32)]\n",
            "Batch 123 d_loss: 0.45733124017715454\n",
            "Batch 123 g_loss: [array(0.45733124, dtype=float32), array(0.45733124, dtype=float32), array(0.45733124, dtype=float32)]\n",
            "Batch 124 d_loss: 0.45643672347068787\n",
            "Batch 124 g_loss: [array(0.45643672, dtype=float32), array(0.45643672, dtype=float32), array(0.45643672, dtype=float32)]\n",
            "Batch 125 d_loss: 0.4553985595703125\n",
            "Batch 125 g_loss: [array(0.45539856, dtype=float32), array(0.45539856, dtype=float32), array(0.45539856, dtype=float32)]\n",
            "Batch 126 d_loss: 0.4542369544506073\n",
            "Batch 126 g_loss: [array(0.45423695, dtype=float32), array(0.45423695, dtype=float32), array(0.45423695, dtype=float32)]\n",
            "Batch 127 d_loss: 0.45320209860801697\n",
            "Batch 127 g_loss: [array(0.4532021, dtype=float32), array(0.4532021, dtype=float32), array(0.4532021, dtype=float32)]\n",
            "Batch 128 d_loss: 0.45205941796302795\n",
            "Batch 128 g_loss: [array(0.45205942, dtype=float32), array(0.45205942, dtype=float32), array(0.45205942, dtype=float32)]\n",
            "Batch 129 d_loss: 0.45105108618736267\n",
            "Batch 129 g_loss: [array(0.4510511, dtype=float32), array(0.4510511, dtype=float32), array(0.4510511, dtype=float32)]\n",
            "Batch 130 d_loss: 0.44993501901626587\n",
            "Batch 130 g_loss: [array(0.44993502, dtype=float32), array(0.44993502, dtype=float32), array(0.44993502, dtype=float32)]\n",
            "Batch 131 d_loss: 0.44905391335487366\n",
            "Batch 131 g_loss: [array(0.4490539, dtype=float32), array(0.4490539, dtype=float32), array(0.4490539, dtype=float32)]\n",
            "Batch 132 d_loss: 0.44805845618247986\n",
            "Batch 132 g_loss: [array(0.44805846, dtype=float32), array(0.44805846, dtype=float32), array(0.44805846, dtype=float32)]\n",
            "Batch 133 d_loss: 0.4471426010131836\n",
            "Batch 133 g_loss: [array(0.4471426, dtype=float32), array(0.4471426, dtype=float32), array(0.4471426, dtype=float32)]\n",
            "Batch 134 d_loss: 0.44631555676460266\n",
            "Batch 134 g_loss: [array(0.44631556, dtype=float32), array(0.44631556, dtype=float32), array(0.44631556, dtype=float32)]\n",
            "Batch 135 d_loss: 0.4454813003540039\n",
            "Batch 135 g_loss: [array(0.4454813, dtype=float32), array(0.4454813, dtype=float32), array(0.4454813, dtype=float32)]\n",
            "Batch 136 d_loss: 0.44452986121177673\n",
            "Batch 136 g_loss: [array(0.44452986, dtype=float32), array(0.44452986, dtype=float32), array(0.44452986, dtype=float32)]\n",
            "Batch 137 d_loss: 0.44344285130500793\n",
            "Batch 137 g_loss: [array(0.44344285, dtype=float32), array(0.44344285, dtype=float32), array(0.44344285, dtype=float32)]\n",
            "Batch 138 d_loss: 0.4424011707305908\n",
            "Batch 138 g_loss: [array(0.44240117, dtype=float32), array(0.44240117, dtype=float32), array(0.44240117, dtype=float32)]\n",
            "Batch 139 d_loss: 0.4413785934448242\n",
            "Batch 139 g_loss: [array(0.4413786, dtype=float32), array(0.4413786, dtype=float32), array(0.4413786, dtype=float32)]\n",
            "Batch 140 d_loss: 0.44047895073890686\n",
            "Batch 140 g_loss: [array(0.44047895, dtype=float32), array(0.44047895, dtype=float32), array(0.44047895, dtype=float32)]\n",
            "Batch 141 d_loss: 0.4394613802433014\n",
            "Batch 141 g_loss: [array(0.43946138, dtype=float32), array(0.43946138, dtype=float32), array(0.43946138, dtype=float32)]\n",
            "Batch 142 d_loss: 0.4384068250656128\n",
            "Batch 142 g_loss: [array(0.43840683, dtype=float32), array(0.43840683, dtype=float32), array(0.43840683, dtype=float32)]\n",
            "Batch 143 d_loss: 0.43724551796913147\n",
            "Batch 143 g_loss: [array(0.43724552, dtype=float32), array(0.43724552, dtype=float32), array(0.43724552, dtype=float32)]\n",
            "Batch 144 d_loss: 0.43630027770996094\n",
            "Batch 144 g_loss: [array(0.43630028, dtype=float32), array(0.43630028, dtype=float32), array(0.43630028, dtype=float32)]\n",
            "Batch 145 d_loss: 0.4353376626968384\n",
            "Batch 145 g_loss: [array(0.43533766, dtype=float32), array(0.43533766, dtype=float32), array(0.43533766, dtype=float32)]\n",
            "Batch 146 d_loss: 0.4343704879283905\n",
            "Batch 146 g_loss: [array(0.4343705, dtype=float32), array(0.4343705, dtype=float32), array(0.4343705, dtype=float32)]\n",
            "Batch 147 d_loss: 0.43339410424232483\n",
            "Batch 147 g_loss: [array(0.4333941, dtype=float32), array(0.4333941, dtype=float32), array(0.4333941, dtype=float32)]\n",
            "Batch 148 d_loss: 0.43250197172164917\n",
            "Batch 148 g_loss: [array(0.43250197, dtype=float32), array(0.43250197, dtype=float32), array(0.43250197, dtype=float32)]\n",
            "Batch 149 d_loss: 0.43156352639198303\n",
            "Batch 149 g_loss: [array(0.43156353, dtype=float32), array(0.43156353, dtype=float32), array(0.43156353, dtype=float32)]\n",
            "Batch 150 d_loss: 0.430601567029953\n",
            "Batch 150 g_loss: [array(0.43060157, dtype=float32), array(0.43060157, dtype=float32), array(0.43060157, dtype=float32)]\n",
            "Batch 151 d_loss: 0.42958566546440125\n",
            "Batch 151 g_loss: [array(0.42958567, dtype=float32), array(0.42958567, dtype=float32), array(0.42958567, dtype=float32)]\n",
            "Batch 152 d_loss: 0.4284899830818176\n",
            "Batch 152 g_loss: [array(0.42848998, dtype=float32), array(0.42848998, dtype=float32), array(0.42848998, dtype=float32)]\n",
            "Batch 153 d_loss: 0.42749884724617004\n",
            "Batch 153 g_loss: [array(0.42749885, dtype=float32), array(0.42749885, dtype=float32), array(0.42749885, dtype=float32)]\n",
            "Batch 154 d_loss: 0.42669427394866943\n",
            "Batch 154 g_loss: [array(0.42669427, dtype=float32), array(0.42669427, dtype=float32), array(0.42669427, dtype=float32)]\n",
            "Batch 155 d_loss: 0.4257444143295288\n",
            "Batch 155 g_loss: [array(0.4257444, dtype=float32), array(0.4257444, dtype=float32), array(0.4257444, dtype=float32)]\n",
            "Batch 156 d_loss: 0.4247562885284424\n",
            "Batch 156 g_loss: [array(0.4247563, dtype=float32), array(0.4247563, dtype=float32), array(0.4247563, dtype=float32)]\n",
            "Batch 157 d_loss: 0.4237712025642395\n",
            "Batch 157 g_loss: [array(0.4237712, dtype=float32), array(0.4237712, dtype=float32), array(0.4237712, dtype=float32)]\n",
            "Batch 158 d_loss: 0.4229109287261963\n",
            "Batch 158 g_loss: [array(0.42291093, dtype=float32), array(0.42291093, dtype=float32), array(0.42291093, dtype=float32)]\n",
            "Batch 159 d_loss: 0.4222005307674408\n",
            "Batch 159 g_loss: [array(0.42220053, dtype=float32), array(0.42220053, dtype=float32), array(0.42220053, dtype=float32)]\n",
            "Batch 160 d_loss: 0.4212537109851837\n",
            "Batch 160 g_loss: [array(0.4212537, dtype=float32), array(0.4212537, dtype=float32), array(0.4212537, dtype=float32)]\n",
            "Batch 161 d_loss: 0.4203251898288727\n",
            "Batch 161 g_loss: [array(0.4203252, dtype=float32), array(0.4203252, dtype=float32), array(0.4203252, dtype=float32)]\n",
            "Batch 162 d_loss: 0.41943398118019104\n",
            "Batch 162 g_loss: [array(0.41943398, dtype=float32), array(0.41943398, dtype=float32), array(0.41943398, dtype=float32)]\n",
            "Batch 163 d_loss: 0.41857004165649414\n",
            "Batch 163 g_loss: [array(0.41857004, dtype=float32), array(0.41857004, dtype=float32), array(0.41857004, dtype=float32)]\n",
            "Batch 164 d_loss: 0.4175925552845001\n",
            "Batch 164 g_loss: [array(0.41759256, dtype=float32), array(0.41759256, dtype=float32), array(0.41759256, dtype=float32)]\n",
            "Batch 165 d_loss: 0.4167214334011078\n",
            "Batch 165 g_loss: [array(0.41672143, dtype=float32), array(0.41672143, dtype=float32), array(0.41672143, dtype=float32)]\n",
            "Batch 166 d_loss: 0.41597071290016174\n",
            "Batch 166 g_loss: [array(0.4159707, dtype=float32), array(0.4159707, dtype=float32), array(0.4159707, dtype=float32)]\n",
            "Batch 167 d_loss: 0.41514813899993896\n",
            "Batch 167 g_loss: [array(0.41514814, dtype=float32), array(0.41514814, dtype=float32), array(0.41514814, dtype=float32)]\n",
            "Batch 168 d_loss: 0.41426438093185425\n",
            "Batch 168 g_loss: [array(0.41426438, dtype=float32), array(0.41426438, dtype=float32), array(0.41426438, dtype=float32)]\n",
            "Batch 169 d_loss: 0.41344255208969116\n",
            "Batch 169 g_loss: [array(0.41344255, dtype=float32), array(0.41344255, dtype=float32), array(0.41344255, dtype=float32)]\n",
            "Batch 170 d_loss: 0.41268661618232727\n",
            "Batch 170 g_loss: [array(0.41268662, dtype=float32), array(0.41268662, dtype=float32), array(0.41268662, dtype=float32)]\n",
            "Batch 171 d_loss: 0.4119489789009094\n",
            "Batch 171 g_loss: [array(0.41194898, dtype=float32), array(0.41194898, dtype=float32), array(0.41194898, dtype=float32)]\n",
            "Batch 172 d_loss: 0.41110458970069885\n",
            "Batch 172 g_loss: [array(0.4111046, dtype=float32), array(0.4111046, dtype=float32), array(0.4111046, dtype=float32)]\n",
            "Batch 173 d_loss: 0.4102635383605957\n",
            "Batch 173 g_loss: [array(0.41026354, dtype=float32), array(0.41026354, dtype=float32), array(0.41026354, dtype=float32)]\n",
            "Batch 174 d_loss: 0.4093950688838959\n",
            "Batch 174 g_loss: [array(0.40939507, dtype=float32), array(0.40939507, dtype=float32), array(0.40939507, dtype=float32)]\n",
            "Batch 175 d_loss: 0.4085427522659302\n",
            "Batch 175 g_loss: [array(0.40854275, dtype=float32), array(0.40854275, dtype=float32), array(0.40854275, dtype=float32)]\n",
            "Batch 176 d_loss: 0.40788403153419495\n",
            "Batch 176 g_loss: [array(0.40788403, dtype=float32), array(0.40788403, dtype=float32), array(0.40788403, dtype=float32)]\n",
            "Batch 177 d_loss: 0.4070742726325989\n",
            "Batch 177 g_loss: [array(0.40707427, dtype=float32), array(0.40707427, dtype=float32), array(0.40707427, dtype=float32)]\n",
            "Batch 178 d_loss: 0.40628525614738464\n",
            "Batch 178 g_loss: [array(0.40628526, dtype=float32), array(0.40628526, dtype=float32), array(0.40628526, dtype=float32)]\n",
            "Batch 179 d_loss: 0.4056518077850342\n",
            "Batch 179 g_loss: [array(0.4056518, dtype=float32), array(0.4056518, dtype=float32), array(0.4056518, dtype=float32)]\n",
            "Batch 180 d_loss: 0.4049440622329712\n",
            "Batch 180 g_loss: [array(0.40494406, dtype=float32), array(0.40494406, dtype=float32), array(0.40494406, dtype=float32)]\n",
            "Batch 181 d_loss: 0.4042834937572479\n",
            "Batch 181 g_loss: [array(0.4042835, dtype=float32), array(0.4042835, dtype=float32), array(0.4042835, dtype=float32)]\n",
            "Batch 182 d_loss: 0.40360844135284424\n",
            "Batch 182 g_loss: [array(0.40360844, dtype=float32), array(0.40360844, dtype=float32), array(0.40360844, dtype=float32)]\n",
            "Batch 183 d_loss: 0.4029068648815155\n",
            "Batch 183 g_loss: [array(0.40290686, dtype=float32), array(0.40290686, dtype=float32), array(0.40290686, dtype=float32)]\n",
            "Batch 184 d_loss: 0.4021488130092621\n",
            "Batch 184 g_loss: [array(0.4021488, dtype=float32), array(0.4021488, dtype=float32), array(0.4021488, dtype=float32)]\n",
            "Batch 185 d_loss: 0.4015754461288452\n",
            "Batch 185 g_loss: [array(0.40157545, dtype=float32), array(0.40157545, dtype=float32), array(0.40157545, dtype=float32)]\n",
            "Batch 186 d_loss: 0.40085911750793457\n",
            "Batch 186 g_loss: [array(0.40085912, dtype=float32), array(0.40085912, dtype=float32), array(0.40085912, dtype=float32)]\n",
            "Batch 187 d_loss: 0.4003155529499054\n",
            "Batch 187 g_loss: [array(0.40031555, dtype=float32), array(0.40031555, dtype=float32), array(0.40031555, dtype=float32)]\n",
            "Batch 188 d_loss: 0.399798184633255\n",
            "Batch 188 g_loss: [array(0.39979818, dtype=float32), array(0.39979818, dtype=float32), array(0.39979818, dtype=float32)]\n",
            "Batch 189 d_loss: 0.3993283808231354\n",
            "Batch 189 g_loss: [array(0.39932838, dtype=float32), array(0.39932838, dtype=float32), array(0.39932838, dtype=float32)]\n",
            "Batch 190 d_loss: 0.39885860681533813\n",
            "Batch 190 g_loss: [array(0.3988586, dtype=float32), array(0.3988586, dtype=float32), array(0.3988586, dtype=float32)]\n",
            "Batch 191 d_loss: 0.39837369322776794\n",
            "Batch 191 g_loss: [array(0.3983737, dtype=float32), array(0.3983737, dtype=float32), array(0.3983737, dtype=float32)]\n",
            "Batch 192 d_loss: 0.39780616760253906\n",
            "Batch 192 g_loss: [array(0.39780617, dtype=float32), array(0.39780617, dtype=float32), array(0.39780617, dtype=float32)]\n",
            "Batch 193 d_loss: 0.39735502004623413\n",
            "Batch 193 g_loss: [array(0.39735502, dtype=float32), array(0.39735502, dtype=float32), array(0.39735502, dtype=float32)]\n",
            "Batch 194 d_loss: 0.39683786034584045\n",
            "Batch 194 g_loss: [array(0.39683786, dtype=float32), array(0.39683786, dtype=float32), array(0.39683786, dtype=float32)]\n",
            "Batch 195 d_loss: 0.39644142985343933\n",
            "Batch 195 g_loss: [array(0.39644143, dtype=float32), array(0.39644143, dtype=float32), array(0.39644143, dtype=float32)]\n",
            "Batch 196 d_loss: 0.39599743485450745\n",
            "Batch 196 g_loss: [array(0.39599743, dtype=float32), array(0.39599743, dtype=float32), array(0.39599743, dtype=float32)]\n",
            "Batch 197 d_loss: 0.3956180810928345\n",
            "Batch 197 g_loss: [array(0.39561808, dtype=float32), array(0.39561808, dtype=float32), array(0.39561808, dtype=float32)]\n",
            "Batch 198 d_loss: 0.39534884691238403\n",
            "Batch 198 g_loss: [array(0.39534885, dtype=float32), array(0.39534885, dtype=float32), array(0.39534885, dtype=float32)]\n",
            "Batch 199 d_loss: 0.39499402046203613\n",
            "Batch 199 g_loss: [array(0.39499402, dtype=float32), array(0.39499402, dtype=float32), array(0.39499402, dtype=float32)]\n",
            "Batch 200 d_loss: 0.39466801285743713\n",
            "Batch 200 g_loss: [array(0.394668, dtype=float32), array(0.394668, dtype=float32), array(0.394668, dtype=float32)]\n",
            "Batch 201 d_loss: 0.3942715525627136\n",
            "Batch 201 g_loss: [array(0.39427155, dtype=float32), array(0.39427155, dtype=float32), array(0.39427155, dtype=float32)]\n",
            "Batch 202 d_loss: 0.3941512405872345\n",
            "Batch 202 g_loss: [array(0.39415124, dtype=float32), array(0.39415124, dtype=float32), array(0.39415124, dtype=float32)]\n",
            "Batch 203 d_loss: 0.39402422308921814\n",
            "Batch 203 g_loss: [array(0.39402422, dtype=float32), array(0.39402422, dtype=float32), array(0.39402422, dtype=float32)]\n",
            "Batch 204 d_loss: 0.39374491572380066\n",
            "Batch 204 g_loss: [array(0.39374492, dtype=float32), array(0.39374492, dtype=float32), array(0.39374492, dtype=float32)]\n",
            "Batch 205 d_loss: 0.3935297131538391\n",
            "Batch 205 g_loss: [array(0.3935297, dtype=float32), array(0.3935297, dtype=float32), array(0.3935297, dtype=float32)]\n",
            "Batch 206 d_loss: 0.3934159576892853\n",
            "Batch 206 g_loss: [array(0.39341596, dtype=float32), array(0.39341596, dtype=float32), array(0.39341596, dtype=float32)]\n",
            "Batch 207 d_loss: 0.3933432698249817\n",
            "Batch 207 g_loss: [array(0.39334327, dtype=float32), array(0.39334327, dtype=float32), array(0.39334327, dtype=float32)]\n",
            "Batch 208 d_loss: 0.39327308535575867\n",
            "Batch 208 g_loss: [array(0.3932731, dtype=float32), array(0.3932731, dtype=float32), array(0.3932731, dtype=float32)]\n",
            "Batch 209 d_loss: 0.39302554726600647\n",
            "Batch 209 g_loss: [array(0.39302555, dtype=float32), array(0.39302555, dtype=float32), array(0.39302555, dtype=float32)]\n",
            "Batch 210 d_loss: 0.39272788166999817\n",
            "Batch 210 g_loss: [array(0.39272788, dtype=float32), array(0.39272788, dtype=float32), array(0.39272788, dtype=float32)]\n",
            "Batch 211 d_loss: 0.3925938010215759\n",
            "Batch 211 g_loss: [array(0.3925938, dtype=float32), array(0.3925938, dtype=float32), array(0.3925938, dtype=float32)]\n",
            "Batch 212 d_loss: 0.3926267921924591\n",
            "Batch 212 g_loss: [array(0.3926268, dtype=float32), array(0.3926268, dtype=float32), array(0.3926268, dtype=float32)]\n",
            "Batch 213 d_loss: 0.3926789462566376\n",
            "Batch 213 g_loss: [array(0.39267895, dtype=float32), array(0.39267895, dtype=float32), array(0.39267895, dtype=float32)]\n",
            "Batch 214 d_loss: 0.39276865124702454\n",
            "Batch 214 g_loss: [array(0.39276865, dtype=float32), array(0.39276865, dtype=float32), array(0.39276865, dtype=float32)]\n",
            "Batch 215 d_loss: 0.39289119839668274\n",
            "Batch 215 g_loss: [array(0.3928912, dtype=float32), array(0.3928912, dtype=float32), array(0.3928912, dtype=float32)]\n",
            "Batch 216 d_loss: 0.39293038845062256\n",
            "Batch 216 g_loss: [array(0.3929304, dtype=float32), array(0.3929304, dtype=float32), array(0.3929304, dtype=float32)]\n",
            "Batch 217 d_loss: 0.39305436611175537\n",
            "Batch 217 g_loss: [array(0.39305437, dtype=float32), array(0.39305437, dtype=float32), array(0.39305437, dtype=float32)]\n",
            "Batch 218 d_loss: 0.3935643136501312\n",
            "Batch 218 g_loss: [array(0.3935643, dtype=float32), array(0.3935643, dtype=float32), array(0.3935643, dtype=float32)]\n",
            "Batch 219 d_loss: 0.39388421177864075\n",
            "Batch 219 g_loss: [array(0.3938842, dtype=float32), array(0.3938842, dtype=float32), array(0.3938842, dtype=float32)]\n",
            "Batch 220 d_loss: 0.39396539330482483\n",
            "Batch 220 g_loss: [array(0.3939654, dtype=float32), array(0.3939654, dtype=float32), array(0.3939654, dtype=float32)]\n",
            "Batch 221 d_loss: 0.39419394731521606\n",
            "Batch 221 g_loss: [array(0.39419395, dtype=float32), array(0.39419395, dtype=float32), array(0.39419395, dtype=float32)]\n",
            "Batch 222 d_loss: 0.3945818841457367\n",
            "Batch 222 g_loss: [array(0.39458188, dtype=float32), array(0.39458188, dtype=float32), array(0.39458188, dtype=float32)]\n",
            "Batch 223 d_loss: 0.3948032855987549\n",
            "Batch 223 g_loss: [array(0.3948033, dtype=float32), array(0.3948033, dtype=float32), array(0.3948033, dtype=float32)]\n",
            "Batch 224 d_loss: 0.3952316343784332\n",
            "Batch 224 g_loss: [array(0.39523163, dtype=float32), array(0.39523163, dtype=float32), array(0.39523163, dtype=float32)]\n",
            "Batch 225 d_loss: 0.395648717880249\n",
            "Batch 225 g_loss: [array(0.39564872, dtype=float32), array(0.39564872, dtype=float32), array(0.39564872, dtype=float32)]\n",
            "Batch 226 d_loss: 0.396140992641449\n",
            "Batch 226 g_loss: [array(0.396141, dtype=float32), array(0.396141, dtype=float32), array(0.396141, dtype=float32)]\n",
            "Batch 227 d_loss: 0.396549791097641\n",
            "Batch 227 g_loss: [array(0.3965498, dtype=float32), array(0.3965498, dtype=float32), array(0.3965498, dtype=float32)]\n",
            "Batch 228 d_loss: 0.397067129611969\n",
            "Batch 228 g_loss: [array(0.39706713, dtype=float32), array(0.39706713, dtype=float32), array(0.39706713, dtype=float32)]\n",
            "Batch 229 d_loss: 0.3974837064743042\n",
            "Batch 229 g_loss: [array(0.3974837, dtype=float32), array(0.3974837, dtype=float32), array(0.3974837, dtype=float32)]\n",
            "Batch 230 d_loss: 0.39801025390625\n",
            "Batch 230 g_loss: [array(0.39801025, dtype=float32), array(0.39801025, dtype=float32), array(0.39801025, dtype=float32)]\n",
            "Batch 231 d_loss: 0.3984331786632538\n",
            "Batch 231 g_loss: [array(0.39843318, dtype=float32), array(0.39843318, dtype=float32), array(0.39843318, dtype=float32)]\n",
            "Batch 232 d_loss: 0.3988533616065979\n",
            "Batch 232 g_loss: [array(0.39885336, dtype=float32), array(0.39885336, dtype=float32), array(0.39885336, dtype=float32)]\n",
            "Batch 233 d_loss: 0.399124413728714\n",
            "Batch 233 g_loss: [array(0.3991244, dtype=float32), array(0.3991244, dtype=float32), array(0.3991244, dtype=float32)]\n",
            "Batch 234 d_loss: 0.39947324991226196\n",
            "Batch 234 g_loss: [array(0.39947325, dtype=float32), array(0.39947325, dtype=float32), array(0.39947325, dtype=float32)]\n",
            "Batch 235 d_loss: 0.3998618721961975\n",
            "Batch 235 g_loss: [array(0.39986187, dtype=float32), array(0.39986187, dtype=float32), array(0.39986187, dtype=float32)]\n",
            "Batch 236 d_loss: 0.4005372226238251\n",
            "Batch 236 g_loss: [array(0.40053722, dtype=float32), array(0.40053722, dtype=float32), array(0.40053722, dtype=float32)]\n",
            "Batch 237 d_loss: 0.40141573548316956\n",
            "Batch 237 g_loss: [array(0.40141574, dtype=float32), array(0.40141574, dtype=float32), array(0.40141574, dtype=float32)]\n",
            "Batch 238 d_loss: 0.4019462466239929\n",
            "Batch 238 g_loss: [array(0.40194625, dtype=float32), array(0.40194625, dtype=float32), array(0.40194625, dtype=float32)]\n",
            "Batch 239 d_loss: 0.4025726020336151\n",
            "Batch 239 g_loss: [array(0.4025726, dtype=float32), array(0.4025726, dtype=float32), array(0.4025726, dtype=float32)]\n",
            "Batch 240 d_loss: 0.4031854569911957\n",
            "Batch 240 g_loss: [array(0.40318546, dtype=float32), array(0.40318546, dtype=float32), array(0.40318546, dtype=float32)]\n",
            "Batch 241 d_loss: 0.40398094058036804\n",
            "Batch 241 g_loss: [array(0.40398094, dtype=float32), array(0.40398094, dtype=float32), array(0.40398094, dtype=float32)]\n",
            "Batch 242 d_loss: 0.40463411808013916\n",
            "Batch 242 g_loss: [array(0.40463412, dtype=float32), array(0.40463412, dtype=float32), array(0.40463412, dtype=float32)]\n",
            "Batch 243 d_loss: 0.40508952736854553\n",
            "Batch 243 g_loss: [array(0.40508953, dtype=float32), array(0.40508953, dtype=float32), array(0.40508953, dtype=float32)]\n",
            "Batch 244 d_loss: 0.4055478274822235\n",
            "Batch 244 g_loss: [array(0.40554783, dtype=float32), array(0.40554783, dtype=float32), array(0.40554783, dtype=float32)]\n",
            "Batch 245 d_loss: 0.4060598313808441\n",
            "Batch 245 g_loss: [array(0.40605983, dtype=float32), array(0.40605983, dtype=float32), array(0.40605983, dtype=float32)]\n",
            "Batch 246 d_loss: 0.40654048323631287\n",
            "Batch 246 g_loss: [array(0.40654048, dtype=float32), array(0.40654048, dtype=float32), array(0.40654048, dtype=float32)]\n",
            "Batch 247 d_loss: 0.4070505201816559\n",
            "Batch 247 g_loss: [array(0.40705052, dtype=float32), array(0.40705052, dtype=float32), array(0.40705052, dtype=float32)]\n",
            "Batch 248 d_loss: 0.40760764479637146\n",
            "Batch 248 g_loss: [array(0.40760764, dtype=float32), array(0.40760764, dtype=float32), array(0.40760764, dtype=float32)]\n",
            "Batch 249 d_loss: 0.4084666669368744\n",
            "Batch 249 g_loss: [array(0.40846667, dtype=float32), array(0.40846667, dtype=float32), array(0.40846667, dtype=float32)]\n",
            "Batch 250 d_loss: 0.40894225239753723\n",
            "Batch 250 g_loss: [array(0.40894225, dtype=float32), array(0.40894225, dtype=float32), array(0.40894225, dtype=float32)]\n",
            "Batch 251 d_loss: 0.40946629643440247\n",
            "Batch 251 g_loss: [array(0.4094663, dtype=float32), array(0.4094663, dtype=float32), array(0.4094663, dtype=float32)]\n",
            "Batch 252 d_loss: 0.4100925326347351\n",
            "Batch 252 g_loss: [array(0.41009253, dtype=float32), array(0.41009253, dtype=float32), array(0.41009253, dtype=float32)]\n",
            "Batch 253 d_loss: 0.4109557271003723\n",
            "Batch 253 g_loss: [array(0.41095573, dtype=float32), array(0.41095573, dtype=float32), array(0.41095573, dtype=float32)]\n",
            "Batch 254 d_loss: 0.4119139611721039\n",
            "Batch 254 g_loss: [array(0.41191396, dtype=float32), array(0.41191396, dtype=float32), array(0.41191396, dtype=float32)]\n",
            "Batch 255 d_loss: 0.41246235370635986\n",
            "Batch 255 g_loss: [array(0.41246235, dtype=float32), array(0.41246235, dtype=float32), array(0.41246235, dtype=float32)]\n",
            "Batch 256 d_loss: 0.4130406677722931\n",
            "Batch 256 g_loss: [array(0.41304067, dtype=float32), array(0.41304067, dtype=float32), array(0.41304067, dtype=float32)]\n",
            "Batch 257 d_loss: 0.4137313961982727\n",
            "Batch 257 g_loss: [array(0.4137314, dtype=float32), array(0.4137314, dtype=float32), array(0.4137314, dtype=float32)]\n",
            "Batch 258 d_loss: 0.41419488191604614\n",
            "Batch 258 g_loss: [array(0.41419488, dtype=float32), array(0.41419488, dtype=float32), array(0.41419488, dtype=float32)]\n",
            "Batch 259 d_loss: 0.4148273468017578\n",
            "Batch 259 g_loss: [array(0.41482735, dtype=float32), array(0.41482735, dtype=float32), array(0.41482735, dtype=float32)]\n",
            "Batch 260 d_loss: 0.41534918546676636\n",
            "Batch 260 g_loss: [array(0.4153492, dtype=float32), array(0.4153492, dtype=float32), array(0.4153492, dtype=float32)]\n",
            "Batch 261 d_loss: 0.4157194197177887\n",
            "Batch 261 g_loss: [array(0.41571942, dtype=float32), array(0.41571942, dtype=float32), array(0.41571942, dtype=float32)]\n",
            "Batch 262 d_loss: 0.4165409207344055\n",
            "Batch 262 g_loss: [array(0.41654092, dtype=float32), array(0.41654092, dtype=float32), array(0.41654092, dtype=float32)]\n",
            "Batch 263 d_loss: 0.4170784652233124\n",
            "Batch 263 g_loss: [array(0.41707847, dtype=float32), array(0.41707847, dtype=float32), array(0.41707847, dtype=float32)]\n",
            "Batch 264 d_loss: 0.4176888167858124\n",
            "Batch 264 g_loss: [array(0.41768882, dtype=float32), array(0.41768882, dtype=float32), array(0.41768882, dtype=float32)]\n",
            "Batch 265 d_loss: 0.4183131754398346\n",
            "Batch 265 g_loss: [array(0.41831318, dtype=float32), array(0.41831318, dtype=float32), array(0.41831318, dtype=float32)]\n",
            "Batch 266 d_loss: 0.4189576804637909\n",
            "Batch 266 g_loss: [array(0.41895768, dtype=float32), array(0.41895768, dtype=float32), array(0.41895768, dtype=float32)]\n",
            "Batch 267 d_loss: 0.41936036944389343\n",
            "Batch 267 g_loss: [array(0.41936037, dtype=float32), array(0.41936037, dtype=float32), array(0.41936037, dtype=float32)]\n",
            "Batch 268 d_loss: 0.41997402906417847\n",
            "Batch 268 g_loss: [array(0.41997403, dtype=float32), array(0.41997403, dtype=float32), array(0.41997403, dtype=float32)]\n",
            "Batch 269 d_loss: 0.42042720317840576\n",
            "Batch 269 g_loss: [array(0.4204272, dtype=float32), array(0.4204272, dtype=float32), array(0.4204272, dtype=float32)]\n",
            "Batch 270 d_loss: 0.42100828886032104\n",
            "Batch 270 g_loss: [array(0.4210083, dtype=float32), array(0.4210083, dtype=float32), array(0.4210083, dtype=float32)]\n",
            "Batch 271 d_loss: 0.4216374456882477\n",
            "Batch 271 g_loss: [array(0.42163745, dtype=float32), array(0.42163745, dtype=float32), array(0.42163745, dtype=float32)]\n",
            "Batch 272 d_loss: 0.4219922423362732\n",
            "Batch 272 g_loss: [array(0.42199224, dtype=float32), array(0.42199224, dtype=float32), array(0.42199224, dtype=float32)]\n",
            "Batch 273 d_loss: 0.4225800335407257\n",
            "Batch 273 g_loss: [array(0.42258003, dtype=float32), array(0.42258003, dtype=float32), array(0.42258003, dtype=float32)]\n",
            "Batch 274 d_loss: 0.42317670583724976\n",
            "Batch 274 g_loss: [array(0.4231767, dtype=float32), array(0.4231767, dtype=float32), array(0.4231767, dtype=float32)]\n",
            "Batch 275 d_loss: 0.4237108528614044\n",
            "Batch 275 g_loss: [array(0.42371085, dtype=float32), array(0.42371085, dtype=float32), array(0.42371085, dtype=float32)]\n",
            "Batch 276 d_loss: 0.424487441778183\n",
            "Batch 276 g_loss: [array(0.42448744, dtype=float32), array(0.42448744, dtype=float32), array(0.42448744, dtype=float32)]\n",
            "Batch 277 d_loss: 0.42488566040992737\n",
            "Batch 277 g_loss: [array(0.42488566, dtype=float32), array(0.42488566, dtype=float32), array(0.42488566, dtype=float32)]\n",
            "Batch 278 d_loss: 0.42531484365463257\n",
            "Batch 278 g_loss: [array(0.42531484, dtype=float32), array(0.42531484, dtype=float32), array(0.42531484, dtype=float32)]\n",
            "Batch 279 d_loss: 0.4257012605667114\n",
            "Batch 279 g_loss: [array(0.42570126, dtype=float32), array(0.42570126, dtype=float32), array(0.42570126, dtype=float32)]\n",
            "Batch 280 d_loss: 0.4261631667613983\n",
            "Batch 280 g_loss: [array(0.42616317, dtype=float32), array(0.42616317, dtype=float32), array(0.42616317, dtype=float32)]\n",
            "Batch 281 d_loss: 0.42653709650039673\n",
            "Batch 281 g_loss: [array(0.4265371, dtype=float32), array(0.4265371, dtype=float32), array(0.4265371, dtype=float32)]\n",
            "Batch 282 d_loss: 0.4270175099372864\n",
            "Batch 282 g_loss: [array(0.4270175, dtype=float32), array(0.4270175, dtype=float32), array(0.4270175, dtype=float32)]\n",
            "Batch 283 d_loss: 0.42757701873779297\n",
            "Batch 283 g_loss: [array(0.42757702, dtype=float32), array(0.42757702, dtype=float32), array(0.42757702, dtype=float32)]\n",
            "Batch 284 d_loss: 0.42804160714149475\n",
            "Batch 284 g_loss: [array(0.4280416, dtype=float32), array(0.4280416, dtype=float32), array(0.4280416, dtype=float32)]\n",
            "Batch 285 d_loss: 0.42848923802375793\n",
            "Batch 285 g_loss: [array(0.42848924, dtype=float32), array(0.42848924, dtype=float32), array(0.42848924, dtype=float32)]\n",
            "Batch 286 d_loss: 0.4288535714149475\n",
            "Batch 286 g_loss: [array(0.42885357, dtype=float32), array(0.42885357, dtype=float32), array(0.42885357, dtype=float32)]\n",
            "Batch 287 d_loss: 0.42934906482696533\n",
            "Batch 287 g_loss: [array(0.42934906, dtype=float32), array(0.42934906, dtype=float32), array(0.42934906, dtype=float32)]\n",
            "Batch 288 d_loss: 0.42980366945266724\n",
            "Batch 288 g_loss: [array(0.42980367, dtype=float32), array(0.42980367, dtype=float32), array(0.42980367, dtype=float32)]\n",
            "Batch 289 d_loss: 0.4300963580608368\n",
            "Batch 289 g_loss: [array(0.43009636, dtype=float32), array(0.43009636, dtype=float32), array(0.43009636, dtype=float32)]\n",
            "Batch 290 d_loss: 0.4306342899799347\n",
            "Batch 290 g_loss: [array(0.4306343, dtype=float32), array(0.4306343, dtype=float32), array(0.4306343, dtype=float32)]\n",
            "Batch 291 d_loss: 0.4309966564178467\n",
            "Batch 291 g_loss: [array(0.43099666, dtype=float32), array(0.43099666, dtype=float32), array(0.43099666, dtype=float32)]\n",
            "Batch 292 d_loss: 0.43141984939575195\n",
            "Batch 292 g_loss: [array(0.43141985, dtype=float32), array(0.43141985, dtype=float32), array(0.43141985, dtype=float32)]\n",
            "Batch 293 d_loss: 0.4319319725036621\n",
            "Batch 293 g_loss: [array(0.43193197, dtype=float32), array(0.43193197, dtype=float32), array(0.43193197, dtype=float32)]\n",
            "Batch 294 d_loss: 0.4323044717311859\n",
            "Batch 294 g_loss: [array(0.43230447, dtype=float32), array(0.43230447, dtype=float32), array(0.43230447, dtype=float32)]\n",
            "Batch 295 d_loss: 0.43273085355758667\n",
            "Batch 295 g_loss: [array(0.43273085, dtype=float32), array(0.43273085, dtype=float32), array(0.43273085, dtype=float32)]\n",
            "Batch 296 d_loss: 0.4329664409160614\n",
            "Batch 296 g_loss: [array(0.43296644, dtype=float32), array(0.43296644, dtype=float32), array(0.43296644, dtype=float32)]\n",
            "Batch 297 d_loss: 0.4332660436630249\n",
            "Batch 297 g_loss: [array(0.43326604, dtype=float32), array(0.43326604, dtype=float32), array(0.43326604, dtype=float32)]\n",
            "Batch 298 d_loss: 0.43371453881263733\n",
            "Batch 298 g_loss: [array(0.43371454, dtype=float32), array(0.43371454, dtype=float32), array(0.43371454, dtype=float32)]\n",
            "Batch 299 d_loss: 0.4340861439704895\n",
            "Batch 299 g_loss: [array(0.43408614, dtype=float32), array(0.43408614, dtype=float32), array(0.43408614, dtype=float32)]\n",
            "Batch 300 d_loss: 0.4345190227031708\n",
            "Batch 300 g_loss: [array(0.43451902, dtype=float32), array(0.43451902, dtype=float32), array(0.43451902, dtype=float32)]\n",
            "Batch 301 d_loss: 0.4348166882991791\n",
            "Batch 301 g_loss: [array(0.4348167, dtype=float32), array(0.4348167, dtype=float32), array(0.4348167, dtype=float32)]\n",
            "Batch 302 d_loss: 0.4352250397205353\n",
            "Batch 302 g_loss: [array(0.43522504, dtype=float32), array(0.43522504, dtype=float32), array(0.43522504, dtype=float32)]\n",
            "Batch 303 d_loss: 0.43554672598838806\n",
            "Batch 303 g_loss: [array(0.43554673, dtype=float32), array(0.43554673, dtype=float32), array(0.43554673, dtype=float32)]\n",
            "Batch 304 d_loss: 0.43581292033195496\n",
            "Batch 304 g_loss: [array(0.43581292, dtype=float32), array(0.43581292, dtype=float32), array(0.43581292, dtype=float32)]\n",
            "Batch 305 d_loss: 0.4362345039844513\n",
            "Batch 305 g_loss: [array(0.4362345, dtype=float32), array(0.4362345, dtype=float32), array(0.4362345, dtype=float32)]\n",
            "Batch 306 d_loss: 0.4365796148777008\n",
            "Batch 306 g_loss: [array(0.4365796, dtype=float32), array(0.4365796, dtype=float32), array(0.4365796, dtype=float32)]\n",
            "Batch 307 d_loss: 0.43688029050827026\n",
            "Batch 307 g_loss: [array(0.4368803, dtype=float32), array(0.4368803, dtype=float32), array(0.4368803, dtype=float32)]\n",
            "Batch 308 d_loss: 0.43713828921318054\n",
            "Batch 308 g_loss: [array(0.4371383, dtype=float32), array(0.4371383, dtype=float32), array(0.4371383, dtype=float32)]\n",
            "Batch 309 d_loss: 0.43749457597732544\n",
            "Batch 309 g_loss: [array(0.43749458, dtype=float32), array(0.43749458, dtype=float32), array(0.43749458, dtype=float32)]\n",
            "Batch 310 d_loss: 0.43782833218574524\n",
            "Batch 310 g_loss: [array(0.43782833, dtype=float32), array(0.43782833, dtype=float32), array(0.43782833, dtype=float32)]\n",
            "Batch 311 d_loss: 0.4381394386291504\n",
            "Batch 311 g_loss: [array(0.43813944, dtype=float32), array(0.43813944, dtype=float32), array(0.43813944, dtype=float32)]\n",
            "Batch 312 d_loss: 0.438504695892334\n",
            "Batch 312 g_loss: [array(0.4385047, dtype=float32), array(0.4385047, dtype=float32), array(0.4385047, dtype=float32)]\n",
            "Batch 313 d_loss: 0.4386926293373108\n",
            "Batch 313 g_loss: [array(0.43869263, dtype=float32), array(0.43869263, dtype=float32), array(0.43869263, dtype=float32)]\n",
            "Batch 314 d_loss: 0.43891382217407227\n",
            "Batch 314 g_loss: [array(0.43891382, dtype=float32), array(0.43891382, dtype=float32), array(0.43891382, dtype=float32)]\n",
            "Batch 315 d_loss: 0.4391217827796936\n",
            "Batch 315 g_loss: [array(0.43912178, dtype=float32), array(0.43912178, dtype=float32), array(0.43912178, dtype=float32)]\n",
            "Batch 316 d_loss: 0.4394073486328125\n",
            "Batch 316 g_loss: [array(0.43940735, dtype=float32), array(0.43940735, dtype=float32), array(0.43940735, dtype=float32)]\n",
            "Batch 317 d_loss: 0.4396743178367615\n",
            "Batch 317 g_loss: [array(0.43967432, dtype=float32), array(0.43967432, dtype=float32), array(0.43967432, dtype=float32)]\n",
            "Batch 318 d_loss: 0.4399418830871582\n",
            "Batch 318 g_loss: [array(0.43994188, dtype=float32), array(0.43994188, dtype=float32), array(0.43994188, dtype=float32)]\n",
            "Batch 319 d_loss: 0.4403083920478821\n",
            "Batch 319 g_loss: [array(0.4403084, dtype=float32), array(0.4403084, dtype=float32), array(0.4403084, dtype=float32)]\n",
            "Batch 320 d_loss: 0.440547913312912\n",
            "Batch 320 g_loss: [array(0.4405479, dtype=float32), array(0.4405479, dtype=float32), array(0.4405479, dtype=float32)]\n",
            "Batch 321 d_loss: 0.44077059626579285\n",
            "Batch 321 g_loss: [array(0.4407706, dtype=float32), array(0.4407706, dtype=float32), array(0.4407706, dtype=float32)]\n",
            "Batch 322 d_loss: 0.4410090148448944\n",
            "Batch 322 g_loss: [array(0.441009, dtype=float32), array(0.441009, dtype=float32), array(0.441009, dtype=float32)]\n",
            "Batch 323 d_loss: 0.4412197470664978\n",
            "Batch 323 g_loss: [array(0.44121975, dtype=float32), array(0.44121975, dtype=float32), array(0.44121975, dtype=float32)]\n",
            "Batch 324 d_loss: 0.4414092004299164\n",
            "Batch 324 g_loss: [array(0.4414092, dtype=float32), array(0.4414092, dtype=float32), array(0.4414092, dtype=float32)]\n",
            "Batch 325 d_loss: 0.44152307510375977\n",
            "Batch 325 g_loss: [array(0.44152308, dtype=float32), array(0.44152308, dtype=float32), array(0.44152308, dtype=float32)]\n",
            "Batch 326 d_loss: 0.44170820713043213\n",
            "Batch 326 g_loss: [array(0.4417082, dtype=float32), array(0.4417082, dtype=float32), array(0.4417082, dtype=float32)]\n",
            "Batch 327 d_loss: 0.44189926981925964\n",
            "Batch 327 g_loss: [array(0.44189927, dtype=float32), array(0.44189927, dtype=float32), array(0.44189927, dtype=float32)]\n",
            "Batch 328 d_loss: 0.4419999420642853\n",
            "Batch 328 g_loss: [array(0.44199994, dtype=float32), array(0.44199994, dtype=float32), array(0.44199994, dtype=float32)]\n",
            "Batch 329 d_loss: 0.4421726167201996\n",
            "Batch 329 g_loss: [array(0.44217262, dtype=float32), array(0.44217262, dtype=float32), array(0.44217262, dtype=float32)]\n",
            "Batch 330 d_loss: 0.4422886371612549\n",
            "Batch 330 g_loss: [array(0.44228864, dtype=float32), array(0.44228864, dtype=float32), array(0.44228864, dtype=float32)]\n",
            "Batch 331 d_loss: 0.44237610697746277\n",
            "Batch 331 g_loss: [array(0.4423761, dtype=float32), array(0.4423761, dtype=float32), array(0.4423761, dtype=float32)]\n",
            "Batch 332 d_loss: 0.4424985647201538\n",
            "Batch 332 g_loss: [array(0.44249856, dtype=float32), array(0.44249856, dtype=float32), array(0.44249856, dtype=float32)]\n",
            "Batch 333 d_loss: 0.44267502427101135\n",
            "Batch 333 g_loss: [array(0.44267502, dtype=float32), array(0.44267502, dtype=float32), array(0.44267502, dtype=float32)]\n",
            "Batch 334 d_loss: 0.44280922412872314\n",
            "Batch 334 g_loss: [array(0.44280922, dtype=float32), array(0.44280922, dtype=float32), array(0.44280922, dtype=float32)]\n",
            "Batch 335 d_loss: 0.4428997039794922\n",
            "Batch 335 g_loss: [array(0.4428997, dtype=float32), array(0.4428997, dtype=float32), array(0.4428997, dtype=float32)]\n",
            "Batch 336 d_loss: 0.4430241286754608\n",
            "Batch 336 g_loss: [array(0.44302413, dtype=float32), array(0.44302413, dtype=float32), array(0.44302413, dtype=float32)]\n",
            "Batch 337 d_loss: 0.4431420564651489\n",
            "Batch 337 g_loss: [array(0.44314206, dtype=float32), array(0.44314206, dtype=float32), array(0.44314206, dtype=float32)]\n",
            "Batch 338 d_loss: 0.44325998425483704\n",
            "Batch 338 g_loss: [array(0.44325998, dtype=float32), array(0.44325998, dtype=float32), array(0.44325998, dtype=float32)]\n",
            "Batch 339 d_loss: 0.44345542788505554\n",
            "Batch 339 g_loss: [array(0.44345543, dtype=float32), array(0.44345543, dtype=float32), array(0.44345543, dtype=float32)]\n",
            "Batch 340 d_loss: 0.4435940384864807\n",
            "Batch 340 g_loss: [array(0.44359404, dtype=float32), array(0.44359404, dtype=float32), array(0.44359404, dtype=float32)]\n",
            "Batch 341 d_loss: 0.4437611997127533\n",
            "Batch 341 g_loss: [array(0.4437612, dtype=float32), array(0.4437612, dtype=float32), array(0.4437612, dtype=float32)]\n",
            "Batch 342 d_loss: 0.44379666447639465\n",
            "Batch 342 g_loss: [array(0.44379666, dtype=float32), array(0.44379666, dtype=float32), array(0.44379666, dtype=float32)]\n",
            "Batch 343 d_loss: 0.4439098834991455\n",
            "Batch 343 g_loss: [array(0.44390988, dtype=float32), array(0.44390988, dtype=float32), array(0.44390988, dtype=float32)]\n",
            "Batch 344 d_loss: 0.44398966431617737\n",
            "Batch 344 g_loss: [array(0.44398966, dtype=float32), array(0.44398966, dtype=float32), array(0.44398966, dtype=float32)]\n",
            "Batch 345 d_loss: 0.44404178857803345\n",
            "Batch 345 g_loss: [array(0.4440418, dtype=float32), array(0.4440418, dtype=float32), array(0.4440418, dtype=float32)]\n",
            "Batch 346 d_loss: 0.4441561698913574\n",
            "Batch 346 g_loss: [array(0.44415617, dtype=float32), array(0.44415617, dtype=float32), array(0.44415617, dtype=float32)]\n",
            "Batch 347 d_loss: 0.4442526400089264\n",
            "Batch 347 g_loss: [array(0.44425264, dtype=float32), array(0.44425264, dtype=float32), array(0.44425264, dtype=float32)]\n",
            "Batch 348 d_loss: 0.4442891478538513\n",
            "Batch 348 g_loss: [array(0.44428915, dtype=float32), array(0.44428915, dtype=float32), array(0.44428915, dtype=float32)]\n",
            "Batch 349 d_loss: 0.44438838958740234\n",
            "Batch 349 g_loss: [array(0.4443884, dtype=float32), array(0.4443884, dtype=float32), array(0.4443884, dtype=float32)]\n",
            "Batch 350 d_loss: 0.44443923234939575\n",
            "Batch 350 g_loss: [array(0.44443923, dtype=float32), array(0.44443923, dtype=float32), array(0.44443923, dtype=float32)]\n",
            "Batch 351 d_loss: 0.44453394412994385\n",
            "Batch 351 g_loss: [array(0.44453394, dtype=float32), array(0.44453394, dtype=float32), array(0.44453394, dtype=float32)]\n",
            "Batch 352 d_loss: 0.4446476101875305\n",
            "Batch 352 g_loss: [array(0.4446476, dtype=float32), array(0.4446476, dtype=float32), array(0.4446476, dtype=float32)]\n",
            "Batch 353 d_loss: 0.4446476697921753\n",
            "Batch 353 g_loss: [array(0.44464767, dtype=float32), array(0.44464767, dtype=float32), array(0.44464767, dtype=float32)]\n",
            "Batch 354 d_loss: 0.44476744532585144\n",
            "Batch 354 g_loss: [array(0.44476745, dtype=float32), array(0.44476745, dtype=float32), array(0.44476745, dtype=float32)]\n",
            "Batch 355 d_loss: 0.4448431134223938\n",
            "Batch 355 g_loss: [array(0.4448431, dtype=float32), array(0.4448431, dtype=float32), array(0.4448431, dtype=float32)]\n",
            "Batch 356 d_loss: 0.44495975971221924\n",
            "Batch 356 g_loss: [array(0.44495976, dtype=float32), array(0.44495976, dtype=float32), array(0.44495976, dtype=float32)]\n",
            "Batch 357 d_loss: 0.4449984133243561\n",
            "Batch 357 g_loss: [array(0.4449984, dtype=float32), array(0.4449984, dtype=float32), array(0.4449984, dtype=float32)]\n",
            "Batch 358 d_loss: 0.4450923204421997\n",
            "Batch 358 g_loss: [array(0.44509232, dtype=float32), array(0.44509232, dtype=float32), array(0.44509232, dtype=float32)]\n",
            "Batch 359 d_loss: 0.4451702833175659\n",
            "Batch 359 g_loss: [array(0.44517028, dtype=float32), array(0.44517028, dtype=float32), array(0.44517028, dtype=float32)]\n",
            "Batch 360 d_loss: 0.4452216327190399\n",
            "Batch 360 g_loss: [array(0.44522163, dtype=float32), array(0.44522163, dtype=float32), array(0.44522163, dtype=float32)]\n",
            "Batch 361 d_loss: 0.4452497065067291\n",
            "Batch 361 g_loss: [array(0.4452497, dtype=float32), array(0.4452497, dtype=float32), array(0.4452497, dtype=float32)]\n",
            "Batch 362 d_loss: 0.4452820122241974\n",
            "Batch 362 g_loss: [array(0.445282, dtype=float32), array(0.445282, dtype=float32), array(0.445282, dtype=float32)]\n",
            "Batch 363 d_loss: 0.4453119933605194\n",
            "Batch 363 g_loss: [array(0.445312, dtype=float32), array(0.445312, dtype=float32), array(0.445312, dtype=float32)]\n",
            "Batch 364 d_loss: 0.4453270137310028\n",
            "Batch 364 g_loss: [array(0.445327, dtype=float32), array(0.445327, dtype=float32), array(0.445327, dtype=float32)]\n",
            "Batch 365 d_loss: 0.4454675614833832\n",
            "Batch 365 g_loss: [array(0.44546756, dtype=float32), array(0.44546756, dtype=float32), array(0.44546756, dtype=float32)]\n",
            "Batch 366 d_loss: 0.44553419947624207\n",
            "Batch 366 g_loss: [array(0.4455342, dtype=float32), array(0.4455342, dtype=float32), array(0.4455342, dtype=float32)]\n",
            "Batch 367 d_loss: 0.44558262825012207\n",
            "Batch 367 g_loss: [array(0.44558263, dtype=float32), array(0.44558263, dtype=float32), array(0.44558263, dtype=float32)]\n",
            "Batch 368 d_loss: 0.445638507604599\n",
            "Batch 368 g_loss: [array(0.4456385, dtype=float32), array(0.4456385, dtype=float32), array(0.4456385, dtype=float32)]\n",
            "Batch 369 d_loss: 0.44555988907814026\n",
            "Batch 369 g_loss: [array(0.4455599, dtype=float32), array(0.4455599, dtype=float32), array(0.4455599, dtype=float32)]\n",
            "Batch 370 d_loss: 0.44565078616142273\n",
            "Batch 370 g_loss: [array(0.4456508, dtype=float32), array(0.4456508, dtype=float32), array(0.4456508, dtype=float32)]\n",
            "Batch 371 d_loss: 0.44572797417640686\n",
            "Batch 371 g_loss: [array(0.44572797, dtype=float32), array(0.44572797, dtype=float32), array(0.44572797, dtype=float32)]\n",
            "Batch 372 d_loss: 0.44571319222450256\n",
            "Batch 372 g_loss: [array(0.4457132, dtype=float32), array(0.4457132, dtype=float32), array(0.4457132, dtype=float32)]\n",
            "Batch 373 d_loss: 0.4457864463329315\n",
            "Batch 373 g_loss: [array(0.44578645, dtype=float32), array(0.44578645, dtype=float32), array(0.44578645, dtype=float32)]\n",
            "Batch 374 d_loss: 0.44576314091682434\n",
            "Batch 374 g_loss: [array(0.44576314, dtype=float32), array(0.44576314, dtype=float32), array(0.44576314, dtype=float32)]\n",
            "Batch 375 d_loss: 0.44578754901885986\n",
            "Batch 375 g_loss: [array(0.44578755, dtype=float32), array(0.44578755, dtype=float32), array(0.44578755, dtype=float32)]\n",
            "Batch 376 d_loss: 0.44586384296417236\n",
            "Batch 376 g_loss: [array(0.44586384, dtype=float32), array(0.44586384, dtype=float32), array(0.44586384, dtype=float32)]\n",
            "Batch 377 d_loss: 0.44585520029067993\n",
            "Batch 377 g_loss: [array(0.4458552, dtype=float32), array(0.4458552, dtype=float32), array(0.4458552, dtype=float32)]\n",
            "Batch 378 d_loss: 0.44581809639930725\n",
            "Batch 378 g_loss: [array(0.4458181, dtype=float32), array(0.4458181, dtype=float32), array(0.4458181, dtype=float32)]\n",
            "Batch 379 d_loss: 0.4458397328853607\n",
            "Batch 379 g_loss: [array(0.44583973, dtype=float32), array(0.44583973, dtype=float32), array(0.44583973, dtype=float32)]\n",
            "Batch 380 d_loss: 0.4457932412624359\n",
            "Batch 380 g_loss: [array(0.44579324, dtype=float32), array(0.44579324, dtype=float32), array(0.44579324, dtype=float32)]\n",
            "Batch 381 d_loss: 0.4458408057689667\n",
            "Batch 381 g_loss: [array(0.4458408, dtype=float32), array(0.4458408, dtype=float32), array(0.4458408, dtype=float32)]\n",
            "Batch 382 d_loss: 0.4458361864089966\n",
            "Batch 382 g_loss: [array(0.4458362, dtype=float32), array(0.4458362, dtype=float32), array(0.4458362, dtype=float32)]\n",
            "Batch 383 d_loss: 0.4458589553833008\n",
            "Batch 383 g_loss: [array(0.44585896, dtype=float32), array(0.44585896, dtype=float32), array(0.44585896, dtype=float32)]\n",
            "Batch 384 d_loss: 0.44585391879081726\n",
            "Batch 384 g_loss: [array(0.44585392, dtype=float32), array(0.44585392, dtype=float32), array(0.44585392, dtype=float32)]\n",
            "Batch 385 d_loss: 0.4457666575908661\n",
            "Batch 385 g_loss: [array(0.44576666, dtype=float32), array(0.44576666, dtype=float32), array(0.44576666, dtype=float32)]\n",
            "Batch 386 d_loss: 0.445728600025177\n",
            "Batch 386 g_loss: [array(0.4457286, dtype=float32), array(0.4457286, dtype=float32), array(0.4457286, dtype=float32)]\n",
            "Batch 387 d_loss: 0.4457123279571533\n",
            "Batch 387 g_loss: [array(0.44571233, dtype=float32), array(0.44571233, dtype=float32), array(0.44571233, dtype=float32)]\n",
            "Batch 388 d_loss: 0.4457830488681793\n",
            "Batch 388 g_loss: [array(0.44578305, dtype=float32), array(0.44578305, dtype=float32), array(0.44578305, dtype=float32)]\n",
            "Batch 389 d_loss: 0.4457009434700012\n",
            "Batch 389 g_loss: [array(0.44570094, dtype=float32), array(0.44570094, dtype=float32), array(0.44570094, dtype=float32)]\n",
            "Batch 390 d_loss: 0.44566258788108826\n",
            "Batch 390 g_loss: [array(0.4456626, dtype=float32), array(0.4456626, dtype=float32), array(0.4456626, dtype=float32)]\n",
            "Batch 391 d_loss: 0.4456876218318939\n",
            "Batch 391 g_loss: [array(0.44568762, dtype=float32), array(0.44568762, dtype=float32), array(0.44568762, dtype=float32)]\n",
            "Batch 392 d_loss: 0.4457082450389862\n",
            "Batch 392 g_loss: [array(0.44570825, dtype=float32), array(0.44570825, dtype=float32), array(0.44570825, dtype=float32)]\n",
            "Batch 393 d_loss: 0.4456900656223297\n",
            "Batch 393 g_loss: [array(0.44569007, dtype=float32), array(0.44569007, dtype=float32), array(0.44569007, dtype=float32)]\n",
            "Batch 394 d_loss: 0.44570401310920715\n",
            "Batch 394 g_loss: [array(0.445704, dtype=float32), array(0.445704, dtype=float32), array(0.445704, dtype=float32)]\n",
            "Batch 395 d_loss: 0.4456598162651062\n",
            "Batch 395 g_loss: [array(0.44565982, dtype=float32), array(0.44565982, dtype=float32), array(0.44565982, dtype=float32)]\n",
            "Batch 396 d_loss: 0.44563907384872437\n",
            "Batch 396 g_loss: [array(0.44563907, dtype=float32), array(0.44563907, dtype=float32), array(0.44563907, dtype=float32)]\n",
            "Batch 397 d_loss: 0.44568300247192383\n",
            "Batch 397 g_loss: [array(0.445683, dtype=float32), array(0.445683, dtype=float32), array(0.445683, dtype=float32)]\n",
            "Batch 398 d_loss: 0.445669949054718\n",
            "Batch 398 g_loss: [array(0.44566995, dtype=float32), array(0.44566995, dtype=float32), array(0.44566995, dtype=float32)]\n",
            "Batch 399 d_loss: 0.4456821382045746\n",
            "Batch 399 g_loss: [array(0.44568214, dtype=float32), array(0.44568214, dtype=float32), array(0.44568214, dtype=float32)]\n",
            "Batch 400 d_loss: 0.4456031322479248\n",
            "Batch 400 g_loss: [array(0.44560313, dtype=float32), array(0.44560313, dtype=float32), array(0.44560313, dtype=float32)]\n",
            "Batch 401 d_loss: 0.4455367624759674\n",
            "Batch 401 g_loss: [array(0.44553676, dtype=float32), array(0.44553676, dtype=float32), array(0.44553676, dtype=float32)]\n",
            "Batch 402 d_loss: 0.44547680020332336\n",
            "Batch 402 g_loss: [array(0.4454768, dtype=float32), array(0.4454768, dtype=float32), array(0.4454768, dtype=float32)]\n",
            "Batch 403 d_loss: 0.4453742504119873\n",
            "Batch 403 g_loss: [array(0.44537425, dtype=float32), array(0.44537425, dtype=float32), array(0.44537425, dtype=float32)]\n",
            "Batch 404 d_loss: 0.4453480541706085\n",
            "Batch 404 g_loss: [array(0.44534805, dtype=float32), array(0.44534805, dtype=float32), array(0.44534805, dtype=float32)]\n",
            "Batch 405 d_loss: 0.4452533423900604\n",
            "Batch 405 g_loss: [array(0.44525334, dtype=float32), array(0.44525334, dtype=float32), array(0.44525334, dtype=float32)]\n",
            "Batch 406 d_loss: 0.4452383518218994\n",
            "Batch 406 g_loss: [array(0.44523835, dtype=float32), array(0.44523835, dtype=float32), array(0.44523835, dtype=float32)]\n",
            "Batch 407 d_loss: 0.4452192187309265\n",
            "Batch 407 g_loss: [array(0.44521922, dtype=float32), array(0.44521922, dtype=float32), array(0.44521922, dtype=float32)]\n",
            "Batch 408 d_loss: 0.4451330602169037\n",
            "Batch 408 g_loss: [array(0.44513306, dtype=float32), array(0.44513306, dtype=float32), array(0.44513306, dtype=float32)]\n",
            "Batch 409 d_loss: 0.4450923502445221\n",
            "Batch 409 g_loss: [array(0.44509235, dtype=float32), array(0.44509235, dtype=float32), array(0.44509235, dtype=float32)]\n",
            "Batch 410 d_loss: 0.44502711296081543\n",
            "Batch 410 g_loss: [array(0.4450271, dtype=float32), array(0.4450271, dtype=float32), array(0.4450271, dtype=float32)]\n",
            "Batch 411 d_loss: 0.4450142979621887\n",
            "Batch 411 g_loss: [array(0.4450143, dtype=float32), array(0.4450143, dtype=float32), array(0.4450143, dtype=float32)]\n",
            "Batch 412 d_loss: 0.44489309191703796\n",
            "Batch 412 g_loss: [array(0.4448931, dtype=float32), array(0.4448931, dtype=float32), array(0.4448931, dtype=float32)]\n",
            "Batch 413 d_loss: 0.444842129945755\n",
            "Batch 413 g_loss: [array(0.44484213, dtype=float32), array(0.44484213, dtype=float32), array(0.44484213, dtype=float32)]\n",
            "Batch 414 d_loss: 0.4447959363460541\n",
            "Batch 414 g_loss: [array(0.44479594, dtype=float32), array(0.44479594, dtype=float32), array(0.44479594, dtype=float32)]\n",
            "Batch 415 d_loss: 0.44475144147872925\n",
            "Batch 415 g_loss: [array(0.44475144, dtype=float32), array(0.44475144, dtype=float32), array(0.44475144, dtype=float32)]\n",
            "Batch 416 d_loss: 0.44465893507003784\n",
            "Batch 416 g_loss: [array(0.44465894, dtype=float32), array(0.44465894, dtype=float32), array(0.44465894, dtype=float32)]\n",
            "Batch 417 d_loss: 0.444627046585083\n",
            "Batch 417 g_loss: [array(0.44462705, dtype=float32), array(0.44462705, dtype=float32), array(0.44462705, dtype=float32)]\n",
            "Batch 418 d_loss: 0.444519579410553\n",
            "Batch 418 g_loss: [array(0.44451958, dtype=float32), array(0.44451958, dtype=float32), array(0.44451958, dtype=float32)]\n",
            "Batch 419 d_loss: 0.44441285729408264\n",
            "Batch 419 g_loss: [array(0.44441286, dtype=float32), array(0.44441286, dtype=float32), array(0.44441286, dtype=float32)]\n",
            "Batch 420 d_loss: 0.4443453550338745\n",
            "Batch 420 g_loss: [array(0.44434536, dtype=float32), array(0.44434536, dtype=float32), array(0.44434536, dtype=float32)]\n",
            "Batch 421 d_loss: 0.4442368745803833\n",
            "Batch 421 g_loss: [array(0.44423687, dtype=float32), array(0.44423687, dtype=float32), array(0.44423687, dtype=float32)]\n",
            "Batch 422 d_loss: 0.4442007839679718\n",
            "Batch 422 g_loss: [array(0.44420078, dtype=float32), array(0.44420078, dtype=float32), array(0.44420078, dtype=float32)]\n",
            "Batch 423 d_loss: 0.44412490725517273\n",
            "Batch 423 g_loss: [array(0.4441249, dtype=float32), array(0.4441249, dtype=float32), array(0.4441249, dtype=float32)]\n",
            "Batch 424 d_loss: 0.4440179169178009\n",
            "Batch 424 g_loss: [array(0.44401792, dtype=float32), array(0.44401792, dtype=float32), array(0.44401792, dtype=float32)]\n",
            "Batch 425 d_loss: 0.44401815533638\n",
            "Batch 425 g_loss: [array(0.44401816, dtype=float32), array(0.44401816, dtype=float32), array(0.44401816, dtype=float32)]\n",
            "Batch 426 d_loss: 0.44394975900650024\n",
            "Batch 426 g_loss: [array(0.44394976, dtype=float32), array(0.44394976, dtype=float32), array(0.44394976, dtype=float32)]\n",
            "Batch 427 d_loss: 0.44392141699790955\n",
            "Batch 427 g_loss: [array(0.44392142, dtype=float32), array(0.44392142, dtype=float32), array(0.44392142, dtype=float32)]\n",
            "Batch 428 d_loss: 0.44389936327934265\n",
            "Batch 428 g_loss: [array(0.44389936, dtype=float32), array(0.44389936, dtype=float32), array(0.44389936, dtype=float32)]\n",
            "Batch 429 d_loss: 0.4438193440437317\n",
            "Batch 429 g_loss: [array(0.44381934, dtype=float32), array(0.44381934, dtype=float32), array(0.44381934, dtype=float32)]\n",
            "Batch 430 d_loss: 0.4438540041446686\n",
            "Batch 430 g_loss: [array(0.443854, dtype=float32), array(0.443854, dtype=float32), array(0.443854, dtype=float32)]\n",
            "Batch 431 d_loss: 0.44378870725631714\n",
            "Batch 431 g_loss: [array(0.4437887, dtype=float32), array(0.4437887, dtype=float32), array(0.4437887, dtype=float32)]\n",
            "Batch 432 d_loss: 0.443710058927536\n",
            "Batch 432 g_loss: [array(0.44371006, dtype=float32), array(0.44371006, dtype=float32), array(0.44371006, dtype=float32)]\n",
            "Batch 433 d_loss: 0.4436552822589874\n",
            "Batch 433 g_loss: [array(0.44365528, dtype=float32), array(0.44365528, dtype=float32), array(0.44365528, dtype=float32)]\n",
            "Batch 434 d_loss: 0.4435531795024872\n",
            "Batch 434 g_loss: [array(0.44355318, dtype=float32), array(0.44355318, dtype=float32), array(0.44355318, dtype=float32)]\n",
            "Batch 435 d_loss: 0.44351503252983093\n",
            "Batch 435 g_loss: [array(0.44351503, dtype=float32), array(0.44351503, dtype=float32), array(0.44351503, dtype=float32)]\n",
            "Batch 436 d_loss: 0.44349053502082825\n",
            "Batch 436 g_loss: [array(0.44349054, dtype=float32), array(0.44349054, dtype=float32), array(0.44349054, dtype=float32)]\n",
            "Batch 437 d_loss: 0.44342994689941406\n",
            "Batch 437 g_loss: [array(0.44342995, dtype=float32), array(0.44342995, dtype=float32), array(0.44342995, dtype=float32)]\n",
            "Batch 438 d_loss: 0.4433799386024475\n",
            "Batch 438 g_loss: [array(0.44337994, dtype=float32), array(0.44337994, dtype=float32), array(0.44337994, dtype=float32)]\n",
            "Batch 439 d_loss: 0.4433481693267822\n",
            "Batch 439 g_loss: [array(0.44334817, dtype=float32), array(0.44334817, dtype=float32), array(0.44334817, dtype=float32)]\n",
            "Batch 440 d_loss: 0.4432528018951416\n",
            "Batch 440 g_loss: [array(0.4432528, dtype=float32), array(0.4432528, dtype=float32), array(0.4432528, dtype=float32)]\n",
            "Batch 441 d_loss: 0.44317492842674255\n",
            "Batch 441 g_loss: [array(0.44317493, dtype=float32), array(0.44317493, dtype=float32), array(0.44317493, dtype=float32)]\n",
            "Batch 442 d_loss: 0.4430946409702301\n",
            "Batch 442 g_loss: [array(0.44309464, dtype=float32), array(0.44309464, dtype=float32), array(0.44309464, dtype=float32)]\n",
            "Batch 443 d_loss: 0.4430220425128937\n",
            "Batch 443 g_loss: [array(0.44302204, dtype=float32), array(0.44302204, dtype=float32), array(0.44302204, dtype=float32)]\n",
            "Batch 444 d_loss: 0.4429638683795929\n",
            "Batch 444 g_loss: [array(0.44296387, dtype=float32), array(0.44296387, dtype=float32), array(0.44296387, dtype=float32)]\n",
            "Batch 445 d_loss: 0.44292187690734863\n",
            "Batch 445 g_loss: [array(0.44292188, dtype=float32), array(0.44292188, dtype=float32), array(0.44292188, dtype=float32)]\n",
            "Batch 446 d_loss: 0.442865252494812\n",
            "Batch 446 g_loss: [array(0.44286525, dtype=float32), array(0.44286525, dtype=float32), array(0.44286525, dtype=float32)]\n",
            "Batch 447 d_loss: 0.44281092286109924\n",
            "Batch 447 g_loss: [array(0.44281092, dtype=float32), array(0.44281092, dtype=float32), array(0.44281092, dtype=float32)]\n",
            "Batch 448 d_loss: 0.4427218437194824\n",
            "Batch 448 g_loss: [array(0.44272184, dtype=float32), array(0.44272184, dtype=float32), array(0.44272184, dtype=float32)]\n",
            "Batch 449 d_loss: 0.44270074367523193\n",
            "Batch 449 g_loss: [array(0.44270074, dtype=float32), array(0.44270074, dtype=float32), array(0.44270074, dtype=float32)]\n",
            "Batch 450 d_loss: 0.44259902834892273\n",
            "Batch 450 g_loss: [array(0.44259903, dtype=float32), array(0.44259903, dtype=float32), array(0.44259903, dtype=float32)]\n",
            "Batch 451 d_loss: 0.44248658418655396\n",
            "Batch 451 g_loss: [array(0.44248658, dtype=float32), array(0.44248658, dtype=float32), array(0.44248658, dtype=float32)]\n",
            "Batch 452 d_loss: 0.4423951208591461\n",
            "Batch 452 g_loss: [array(0.44239512, dtype=float32), array(0.44239512, dtype=float32), array(0.44239512, dtype=float32)]\n",
            "Batch 453 d_loss: 0.44234099984169006\n",
            "Batch 453 g_loss: [array(0.442341, dtype=float32), array(0.442341, dtype=float32), array(0.442341, dtype=float32)]\n",
            "Batch 454 d_loss: 0.44227877259254456\n",
            "Batch 454 g_loss: [array(0.44227877, dtype=float32), array(0.44227877, dtype=float32), array(0.44227877, dtype=float32)]\n",
            "Batch 455 d_loss: 0.4422033429145813\n",
            "Batch 455 g_loss: [array(0.44220334, dtype=float32), array(0.44220334, dtype=float32), array(0.44220334, dtype=float32)]\n",
            "Batch 456 d_loss: 0.44213956594467163\n",
            "Batch 456 g_loss: [array(0.44213957, dtype=float32), array(0.44213957, dtype=float32), array(0.44213957, dtype=float32)]\n",
            "Batch 457 d_loss: 0.4420243203639984\n",
            "Batch 457 g_loss: [array(0.44202432, dtype=float32), array(0.44202432, dtype=float32), array(0.44202432, dtype=float32)]\n",
            "Batch 458 d_loss: 0.441966712474823\n",
            "Batch 458 g_loss: [array(0.4419667, dtype=float32), array(0.4419667, dtype=float32), array(0.4419667, dtype=float32)]\n",
            "Batch 459 d_loss: 0.4419291615486145\n",
            "Batch 459 g_loss: [array(0.44192916, dtype=float32), array(0.44192916, dtype=float32), array(0.44192916, dtype=float32)]\n",
            "Batch 460 d_loss: 0.44184648990631104\n",
            "Batch 460 g_loss: [array(0.4418465, dtype=float32), array(0.4418465, dtype=float32), array(0.4418465, dtype=float32)]\n",
            "Batch 461 d_loss: 0.4417993724346161\n",
            "Batch 461 g_loss: [array(0.44179937, dtype=float32), array(0.44179937, dtype=float32), array(0.44179937, dtype=float32)]\n",
            "Batch 462 d_loss: 0.4417336583137512\n",
            "Batch 462 g_loss: [array(0.44173366, dtype=float32), array(0.44173366, dtype=float32), array(0.44173366, dtype=float32)]\n",
            "Batch 463 d_loss: 0.4416981041431427\n",
            "Batch 463 g_loss: [array(0.4416981, dtype=float32), array(0.4416981, dtype=float32), array(0.4416981, dtype=float32)]\n",
            "Batch 464 d_loss: 0.4416285753250122\n",
            "Batch 464 g_loss: [array(0.44162858, dtype=float32), array(0.44162858, dtype=float32), array(0.44162858, dtype=float32)]\n",
            "Batch 465 d_loss: 0.4415234327316284\n",
            "Batch 465 g_loss: [array(0.44152343, dtype=float32), array(0.44152343, dtype=float32), array(0.44152343, dtype=float32)]\n",
            "Batch 466 d_loss: 0.4414469003677368\n",
            "Batch 466 g_loss: [array(0.4414469, dtype=float32), array(0.4414469, dtype=float32), array(0.4414469, dtype=float32)]\n",
            "Batch 467 d_loss: 0.4413983225822449\n",
            "Batch 467 g_loss: [array(0.44139832, dtype=float32), array(0.44139832, dtype=float32), array(0.44139832, dtype=float32)]\n",
            "Epoch is 1\n",
            "Batch 0 d_loss: 0.44133973121643066\n",
            "Batch 0 g_loss: [array(0.44133973, dtype=float32), array(0.44133973, dtype=float32), array(0.44133973, dtype=float32)]\n",
            "Batch 1 d_loss: 0.4412771761417389\n",
            "Batch 1 g_loss: [array(0.44127718, dtype=float32), array(0.44127718, dtype=float32), array(0.44127718, dtype=float32)]\n",
            "Batch 2 d_loss: 0.44120579957962036\n",
            "Batch 2 g_loss: [array(0.4412058, dtype=float32), array(0.4412058, dtype=float32), array(0.4412058, dtype=float32)]\n",
            "Batch 3 d_loss: 0.44112062454223633\n",
            "Batch 3 g_loss: [array(0.44112062, dtype=float32), array(0.44112062, dtype=float32), array(0.44112062, dtype=float32)]\n",
            "Batch 4 d_loss: 0.44100895524024963\n",
            "Batch 4 g_loss: [array(0.44100896, dtype=float32), array(0.44100896, dtype=float32), array(0.44100896, dtype=float32)]\n",
            "Batch 5 d_loss: 0.4409172236919403\n",
            "Batch 5 g_loss: [array(0.44091722, dtype=float32), array(0.44091722, dtype=float32), array(0.44091722, dtype=float32)]\n",
            "Batch 6 d_loss: 0.4408789575099945\n",
            "Batch 6 g_loss: [array(0.44087896, dtype=float32), array(0.44087896, dtype=float32), array(0.44087896, dtype=float32)]\n",
            "Batch 7 d_loss: 0.44079872965812683\n",
            "Batch 7 g_loss: [array(0.44079873, dtype=float32), array(0.44079873, dtype=float32), array(0.44079873, dtype=float32)]\n",
            "Batch 8 d_loss: 0.44070667028427124\n",
            "Batch 8 g_loss: [array(0.44070667, dtype=float32), array(0.44070667, dtype=float32), array(0.44070667, dtype=float32)]\n",
            "Batch 9 d_loss: 0.4406450390815735\n",
            "Batch 9 g_loss: [array(0.44064504, dtype=float32), array(0.44064504, dtype=float32), array(0.44064504, dtype=float32)]\n",
            "Batch 10 d_loss: 0.44057393074035645\n",
            "Batch 10 g_loss: [array(0.44057393, dtype=float32), array(0.44057393, dtype=float32), array(0.44057393, dtype=float32)]\n",
            "Batch 11 d_loss: 0.44049856066703796\n",
            "Batch 11 g_loss: [array(0.44049856, dtype=float32), array(0.44049856, dtype=float32), array(0.44049856, dtype=float32)]\n",
            "Batch 12 d_loss: 0.4404090642929077\n",
            "Batch 12 g_loss: [array(0.44040906, dtype=float32), array(0.44040906, dtype=float32), array(0.44040906, dtype=float32)]\n",
            "Batch 13 d_loss: 0.440321683883667\n",
            "Batch 13 g_loss: [array(0.44032168, dtype=float32), array(0.44032168, dtype=float32), array(0.44032168, dtype=float32)]\n",
            "Batch 14 d_loss: 0.4402027726173401\n",
            "Batch 14 g_loss: [array(0.44020277, dtype=float32), array(0.44020277, dtype=float32), array(0.44020277, dtype=float32)]\n",
            "Batch 15 d_loss: 0.44008713960647583\n",
            "Batch 15 g_loss: [array(0.44008714, dtype=float32), array(0.44008714, dtype=float32), array(0.44008714, dtype=float32)]\n",
            "Batch 16 d_loss: 0.43999648094177246\n",
            "Batch 16 g_loss: [array(0.43999648, dtype=float32), array(0.43999648, dtype=float32), array(0.43999648, dtype=float32)]\n",
            "Batch 17 d_loss: 0.4398933947086334\n",
            "Batch 17 g_loss: [array(0.4398934, dtype=float32), array(0.4398934, dtype=float32), array(0.4398934, dtype=float32)]\n",
            "Batch 18 d_loss: 0.43981531262397766\n",
            "Batch 18 g_loss: [array(0.4398153, dtype=float32), array(0.4398153, dtype=float32), array(0.4398153, dtype=float32)]\n",
            "Batch 19 d_loss: 0.43966400623321533\n",
            "Batch 19 g_loss: [array(0.439664, dtype=float32), array(0.439664, dtype=float32), array(0.439664, dtype=float32)]\n",
            "Batch 20 d_loss: 0.4395401179790497\n",
            "Batch 20 g_loss: [array(0.43954012, dtype=float32), array(0.43954012, dtype=float32), array(0.43954012, dtype=float32)]\n",
            "Batch 21 d_loss: 0.43946805596351624\n",
            "Batch 21 g_loss: [array(0.43946806, dtype=float32), array(0.43946806, dtype=float32), array(0.43946806, dtype=float32)]\n",
            "Batch 22 d_loss: 0.43935495615005493\n",
            "Batch 22 g_loss: [array(0.43935496, dtype=float32), array(0.43935496, dtype=float32), array(0.43935496, dtype=float32)]\n",
            "Batch 23 d_loss: 0.43924933671951294\n",
            "Batch 23 g_loss: [array(0.43924934, dtype=float32), array(0.43924934, dtype=float32), array(0.43924934, dtype=float32)]\n",
            "Batch 24 d_loss: 0.4391668736934662\n",
            "Batch 24 g_loss: [array(0.43916687, dtype=float32), array(0.43916687, dtype=float32), array(0.43916687, dtype=float32)]\n",
            "Batch 25 d_loss: 0.4391098916530609\n",
            "Batch 25 g_loss: [array(0.4391099, dtype=float32), array(0.4391099, dtype=float32), array(0.4391099, dtype=float32)]\n",
            "Batch 26 d_loss: 0.43898534774780273\n",
            "Batch 26 g_loss: [array(0.43898535, dtype=float32), array(0.43898535, dtype=float32), array(0.43898535, dtype=float32)]\n",
            "Batch 27 d_loss: 0.4388810396194458\n",
            "Batch 27 g_loss: [array(0.43888104, dtype=float32), array(0.43888104, dtype=float32), array(0.43888104, dtype=float32)]\n",
            "Batch 28 d_loss: 0.4387608468532562\n",
            "Batch 28 g_loss: [array(0.43876085, dtype=float32), array(0.43876085, dtype=float32), array(0.43876085, dtype=float32)]\n",
            "Batch 29 d_loss: 0.438627153635025\n",
            "Batch 29 g_loss: [array(0.43862715, dtype=float32), array(0.43862715, dtype=float32), array(0.43862715, dtype=float32)]\n",
            "Batch 30 d_loss: 0.43851831555366516\n",
            "Batch 30 g_loss: [array(0.43851832, dtype=float32), array(0.43851832, dtype=float32), array(0.43851832, dtype=float32)]\n",
            "Batch 31 d_loss: 0.43842801451683044\n",
            "Batch 31 g_loss: [array(0.438428, dtype=float32), array(0.438428, dtype=float32), array(0.438428, dtype=float32)]\n",
            "Batch 32 d_loss: 0.43835365772247314\n",
            "Batch 32 g_loss: [array(0.43835366, dtype=float32), array(0.43835366, dtype=float32), array(0.43835366, dtype=float32)]\n",
            "Batch 33 d_loss: 0.4382700026035309\n",
            "Batch 33 g_loss: [array(0.43827, dtype=float32), array(0.43827, dtype=float32), array(0.43827, dtype=float32)]\n",
            "Batch 34 d_loss: 0.43816086649894714\n",
            "Batch 34 g_loss: [array(0.43816087, dtype=float32), array(0.43816087, dtype=float32), array(0.43816087, dtype=float32)]\n",
            "Batch 35 d_loss: 0.4380432963371277\n",
            "Batch 35 g_loss: [array(0.4380433, dtype=float32), array(0.4380433, dtype=float32), array(0.4380433, dtype=float32)]\n",
            "Batch 36 d_loss: 0.43788838386535645\n",
            "Batch 36 g_loss: [array(0.43788838, dtype=float32), array(0.43788838, dtype=float32), array(0.43788838, dtype=float32)]\n",
            "Batch 37 d_loss: 0.43780088424682617\n",
            "Batch 37 g_loss: [array(0.43780088, dtype=float32), array(0.43780088, dtype=float32), array(0.43780088, dtype=float32)]\n",
            "Batch 38 d_loss: 0.4376968741416931\n",
            "Batch 38 g_loss: [array(0.43769687, dtype=float32), array(0.43769687, dtype=float32), array(0.43769687, dtype=float32)]\n",
            "Batch 40 d_loss: 0.4375230073928833\n",
            "Batch 40 g_loss: [array(0.437523, dtype=float32), array(0.437523, dtype=float32), array(0.437523, dtype=float32)]\n",
            "Batch 41 d_loss: 0.4374486804008484\n",
            "Batch 41 g_loss: [array(0.43744868, dtype=float32), array(0.43744868, dtype=float32), array(0.43744868, dtype=float32)]\n",
            "Batch 42 d_loss: 0.4373708963394165\n",
            "Batch 42 g_loss: [array(0.4373709, dtype=float32), array(0.4373709, dtype=float32), array(0.4373709, dtype=float32)]\n",
            "Batch 43 d_loss: 0.4372802972793579\n",
            "Batch 43 g_loss: [array(0.4372803, dtype=float32), array(0.4372803, dtype=float32), array(0.4372803, dtype=float32)]\n",
            "Batch 44 d_loss: 0.4371689260005951\n",
            "Batch 44 g_loss: [array(0.43716893, dtype=float32), array(0.43716893, dtype=float32), array(0.43716893, dtype=float32)]\n",
            "Batch 45 d_loss: 0.43703168630599976\n",
            "Batch 45 g_loss: [array(0.4370317, dtype=float32), array(0.4370317, dtype=float32), array(0.4370317, dtype=float32)]\n",
            "Batch 46 d_loss: 0.43692731857299805\n",
            "Batch 46 g_loss: [array(0.43692732, dtype=float32), array(0.43692732, dtype=float32), array(0.43692732, dtype=float32)]\n",
            "Batch 47 d_loss: 0.43685802817344666\n",
            "Batch 47 g_loss: [array(0.43685803, dtype=float32), array(0.43685803, dtype=float32), array(0.43685803, dtype=float32)]\n",
            "Batch 48 d_loss: 0.43675127625465393\n",
            "Batch 48 g_loss: [array(0.43675128, dtype=float32), array(0.43675128, dtype=float32), array(0.43675128, dtype=float32)]\n",
            "Batch 49 d_loss: 0.4366239905357361\n",
            "Batch 49 g_loss: [array(0.436624, dtype=float32), array(0.436624, dtype=float32), array(0.436624, dtype=float32)]\n",
            "Batch 50 d_loss: 0.4365423917770386\n",
            "Batch 50 g_loss: [array(0.4365424, dtype=float32), array(0.4365424, dtype=float32), array(0.4365424, dtype=float32)]\n",
            "Batch 51 d_loss: 0.43647173047065735\n",
            "Batch 51 g_loss: [array(0.43647173, dtype=float32), array(0.43647173, dtype=float32), array(0.43647173, dtype=float32)]\n",
            "Batch 52 d_loss: 0.43636733293533325\n",
            "Batch 52 g_loss: [array(0.43636733, dtype=float32), array(0.43636733, dtype=float32), array(0.43636733, dtype=float32)]\n",
            "Batch 53 d_loss: 0.4362974762916565\n",
            "Batch 53 g_loss: [array(0.43629748, dtype=float32), array(0.43629748, dtype=float32), array(0.43629748, dtype=float32)]\n",
            "Batch 54 d_loss: 0.43616750836372375\n",
            "Batch 54 g_loss: [array(0.4361675, dtype=float32), array(0.4361675, dtype=float32), array(0.4361675, dtype=float32)]\n",
            "Batch 55 d_loss: 0.436057984828949\n",
            "Batch 55 g_loss: [array(0.43605798, dtype=float32), array(0.43605798, dtype=float32), array(0.43605798, dtype=float32)]\n",
            "Batch 56 d_loss: 0.43594253063201904\n",
            "Batch 56 g_loss: [array(0.43594253, dtype=float32), array(0.43594253, dtype=float32), array(0.43594253, dtype=float32)]\n",
            "Batch 57 d_loss: 0.43588489294052124\n",
            "Batch 57 g_loss: [array(0.4358849, dtype=float32), array(0.4358849, dtype=float32), array(0.4358849, dtype=float32)]\n",
            "Batch 58 d_loss: 0.4357315003871918\n",
            "Batch 58 g_loss: [array(0.4357315, dtype=float32), array(0.4357315, dtype=float32), array(0.4357315, dtype=float32)]\n",
            "Batch 59 d_loss: 0.4356905221939087\n",
            "Batch 59 g_loss: [array(0.43569052, dtype=float32), array(0.43569052, dtype=float32), array(0.43569052, dtype=float32)]\n",
            "Batch 60 d_loss: 0.4356534481048584\n",
            "Batch 60 g_loss: [array(0.43565345, dtype=float32), array(0.43565345, dtype=float32), array(0.43565345, dtype=float32)]\n",
            "Batch 61 d_loss: 0.43557828664779663\n",
            "Batch 61 g_loss: [array(0.4355783, dtype=float32), array(0.4355783, dtype=float32), array(0.4355783, dtype=float32)]\n",
            "Batch 62 d_loss: 0.43553194403648376\n",
            "Batch 62 g_loss: [array(0.43553194, dtype=float32), array(0.43553194, dtype=float32), array(0.43553194, dtype=float32)]\n",
            "Batch 63 d_loss: 0.43548521399497986\n",
            "Batch 63 g_loss: [array(0.4354852, dtype=float32), array(0.4354852, dtype=float32), array(0.4354852, dtype=float32)]\n",
            "Batch 64 d_loss: 0.4354243874549866\n",
            "Batch 64 g_loss: [array(0.4354244, dtype=float32), array(0.4354244, dtype=float32), array(0.4354244, dtype=float32)]\n",
            "Batch 65 d_loss: 0.4353574812412262\n",
            "Batch 65 g_loss: [array(0.43535748, dtype=float32), array(0.43535748, dtype=float32), array(0.43535748, dtype=float32)]\n",
            "Batch 66 d_loss: 0.4353093206882477\n",
            "Batch 66 g_loss: [array(0.43530932, dtype=float32), array(0.43530932, dtype=float32), array(0.43530932, dtype=float32)]\n",
            "Batch 67 d_loss: 0.43525418639183044\n",
            "Batch 67 g_loss: [array(0.4352542, dtype=float32), array(0.4352542, dtype=float32), array(0.4352542, dtype=float32)]\n",
            "Batch 68 d_loss: 0.43523308634757996\n",
            "Batch 68 g_loss: [array(0.4352331, dtype=float32), array(0.4352331, dtype=float32), array(0.4352331, dtype=float32)]\n",
            "Batch 69 d_loss: 0.4352196753025055\n",
            "Batch 69 g_loss: [array(0.43521968, dtype=float32), array(0.43521968, dtype=float32), array(0.43521968, dtype=float32)]\n",
            "Batch 70 d_loss: 0.4351271688938141\n",
            "Batch 70 g_loss: [array(0.43512717, dtype=float32), array(0.43512717, dtype=float32), array(0.43512717, dtype=float32)]\n",
            "Batch 71 d_loss: 0.4351136088371277\n",
            "Batch 71 g_loss: [array(0.4351136, dtype=float32), array(0.4351136, dtype=float32), array(0.4351136, dtype=float32)]\n",
            "Batch 72 d_loss: 0.43508192896842957\n",
            "Batch 72 g_loss: [array(0.43508193, dtype=float32), array(0.43508193, dtype=float32), array(0.43508193, dtype=float32)]\n",
            "Batch 73 d_loss: 0.4350182116031647\n",
            "Batch 73 g_loss: [array(0.4350182, dtype=float32), array(0.4350182, dtype=float32), array(0.4350182, dtype=float32)]\n",
            "Batch 74 d_loss: 0.4349658787250519\n",
            "Batch 74 g_loss: [array(0.43496588, dtype=float32), array(0.43496588, dtype=float32), array(0.43496588, dtype=float32)]\n",
            "Batch 75 d_loss: 0.4349368214607239\n",
            "Batch 75 g_loss: [array(0.43493682, dtype=float32), array(0.43493682, dtype=float32), array(0.43493682, dtype=float32)]\n",
            "Batch 76 d_loss: 0.4349301755428314\n",
            "Batch 76 g_loss: [array(0.43493018, dtype=float32), array(0.43493018, dtype=float32), array(0.43493018, dtype=float32)]\n",
            "Batch 77 d_loss: 0.43486735224723816\n",
            "Batch 77 g_loss: [array(0.43486735, dtype=float32), array(0.43486735, dtype=float32), array(0.43486735, dtype=float32)]\n",
            "Batch 78 d_loss: 0.4348463714122772\n",
            "Batch 78 g_loss: [array(0.43484637, dtype=float32), array(0.43484637, dtype=float32), array(0.43484637, dtype=float32)]\n",
            "Batch 79 d_loss: 0.4348597228527069\n",
            "Batch 79 g_loss: [array(0.43485972, dtype=float32), array(0.43485972, dtype=float32), array(0.43485972, dtype=float32)]\n",
            "Batch 80 d_loss: 0.43485620617866516\n",
            "Batch 80 g_loss: [array(0.4348562, dtype=float32), array(0.4348562, dtype=float32), array(0.4348562, dtype=float32)]\n",
            "Batch 81 d_loss: 0.4348544180393219\n",
            "Batch 81 g_loss: [array(0.43485442, dtype=float32), array(0.43485442, dtype=float32), array(0.43485442, dtype=float32)]\n",
            "Batch 82 d_loss: 0.4348534643650055\n",
            "Batch 82 g_loss: [array(0.43485346, dtype=float32), array(0.43485346, dtype=float32), array(0.43485346, dtype=float32)]\n",
            "Batch 83 d_loss: 0.4348007142543793\n",
            "Batch 83 g_loss: [array(0.4348007, dtype=float32), array(0.4348007, dtype=float32), array(0.4348007, dtype=float32)]\n",
            "Batch 84 d_loss: 0.43480414152145386\n",
            "Batch 84 g_loss: [array(0.43480414, dtype=float32), array(0.43480414, dtype=float32), array(0.43480414, dtype=float32)]\n",
            "Batch 85 d_loss: 0.43480387330055237\n",
            "Batch 85 g_loss: [array(0.43480387, dtype=float32), array(0.43480387, dtype=float32), array(0.43480387, dtype=float32)]\n",
            "Batch 86 d_loss: 0.4348289966583252\n",
            "Batch 86 g_loss: [array(0.434829, dtype=float32), array(0.434829, dtype=float32), array(0.434829, dtype=float32)]\n",
            "Batch 87 d_loss: 0.43481236696243286\n",
            "Batch 87 g_loss: [array(0.43481237, dtype=float32), array(0.43481237, dtype=float32), array(0.43481237, dtype=float32)]\n",
            "Batch 88 d_loss: 0.43481844663619995\n",
            "Batch 88 g_loss: [array(0.43481845, dtype=float32), array(0.43481845, dtype=float32), array(0.43481845, dtype=float32)]\n",
            "Batch 89 d_loss: 0.4348410964012146\n",
            "Batch 89 g_loss: [array(0.4348411, dtype=float32), array(0.4348411, dtype=float32), array(0.4348411, dtype=float32)]\n",
            "Batch 90 d_loss: 0.4348088204860687\n",
            "Batch 90 g_loss: [array(0.43480882, dtype=float32), array(0.43480882, dtype=float32), array(0.43480882, dtype=float32)]\n",
            "Batch 91 d_loss: 0.43479713797569275\n",
            "Batch 91 g_loss: [array(0.43479714, dtype=float32), array(0.43479714, dtype=float32), array(0.43479714, dtype=float32)]\n",
            "Batch 92 d_loss: 0.4348462224006653\n",
            "Batch 92 g_loss: [array(0.43484622, dtype=float32), array(0.43484622, dtype=float32), array(0.43484622, dtype=float32)]\n",
            "Batch 93 d_loss: 0.4349115788936615\n",
            "Batch 93 g_loss: [array(0.43491158, dtype=float32), array(0.43491158, dtype=float32), array(0.43491158, dtype=float32)]\n",
            "Batch 94 d_loss: 0.43488168716430664\n",
            "Batch 94 g_loss: [array(0.4348817, dtype=float32), array(0.4348817, dtype=float32), array(0.4348817, dtype=float32)]\n",
            "Batch 95 d_loss: 0.43483203649520874\n",
            "Batch 95 g_loss: [array(0.43483204, dtype=float32), array(0.43483204, dtype=float32), array(0.43483204, dtype=float32)]\n",
            "Batch 96 d_loss: 0.4348331689834595\n",
            "Batch 96 g_loss: [array(0.43483317, dtype=float32), array(0.43483317, dtype=float32), array(0.43483317, dtype=float32)]\n",
            "Batch 97 d_loss: 0.4348253905773163\n",
            "Batch 97 g_loss: [array(0.4348254, dtype=float32), array(0.4348254, dtype=float32), array(0.4348254, dtype=float32)]\n",
            "Batch 98 d_loss: 0.4348028898239136\n",
            "Batch 98 g_loss: [array(0.4348029, dtype=float32), array(0.4348029, dtype=float32), array(0.4348029, dtype=float32)]\n",
            "Batch 99 d_loss: 0.4348126947879791\n",
            "Batch 99 g_loss: [array(0.4348127, dtype=float32), array(0.4348127, dtype=float32), array(0.4348127, dtype=float32)]\n",
            "Batch 100 d_loss: 0.4348648190498352\n",
            "Batch 100 g_loss: [array(0.43486482, dtype=float32), array(0.43486482, dtype=float32), array(0.43486482, dtype=float32)]\n",
            "Batch 101 d_loss: 0.43483924865722656\n",
            "Batch 101 g_loss: [array(0.43483925, dtype=float32), array(0.43483925, dtype=float32), array(0.43483925, dtype=float32)]\n",
            "Batch 102 d_loss: 0.4348861873149872\n",
            "Batch 102 g_loss: [array(0.4348862, dtype=float32), array(0.4348862, dtype=float32), array(0.4348862, dtype=float32)]\n",
            "Batch 103 d_loss: 0.4348635971546173\n",
            "Batch 103 g_loss: [array(0.4348636, dtype=float32), array(0.4348636, dtype=float32), array(0.4348636, dtype=float32)]\n",
            "Batch 104 d_loss: 0.43493178486824036\n",
            "Batch 104 g_loss: [array(0.43493178, dtype=float32), array(0.43493178, dtype=float32), array(0.43493178, dtype=float32)]\n",
            "Batch 105 d_loss: 0.4349919557571411\n",
            "Batch 105 g_loss: [array(0.43499196, dtype=float32), array(0.43499196, dtype=float32), array(0.43499196, dtype=float32)]\n",
            "Batch 106 d_loss: 0.43502143025398254\n",
            "Batch 106 g_loss: [array(0.43502143, dtype=float32), array(0.43502143, dtype=float32), array(0.43502143, dtype=float32)]\n",
            "Batch 107 d_loss: 0.43504390120506287\n",
            "Batch 107 g_loss: [array(0.4350439, dtype=float32), array(0.4350439, dtype=float32), array(0.4350439, dtype=float32)]\n",
            "Batch 108 d_loss: 0.4350702166557312\n",
            "Batch 108 g_loss: [array(0.43507022, dtype=float32), array(0.43507022, dtype=float32), array(0.43507022, dtype=float32)]\n",
            "Batch 109 d_loss: 0.4350561499595642\n",
            "Batch 109 g_loss: [array(0.43505615, dtype=float32), array(0.43505615, dtype=float32), array(0.43505615, dtype=float32)]\n",
            "Batch 110 d_loss: 0.435064435005188\n",
            "Batch 110 g_loss: [array(0.43506444, dtype=float32), array(0.43506444, dtype=float32), array(0.43506444, dtype=float32)]\n",
            "Batch 111 d_loss: 0.4351070821285248\n",
            "Batch 111 g_loss: [array(0.43510708, dtype=float32), array(0.43510708, dtype=float32), array(0.43510708, dtype=float32)]\n",
            "Batch 112 d_loss: 0.43513166904449463\n",
            "Batch 112 g_loss: [array(0.43513167, dtype=float32), array(0.43513167, dtype=float32), array(0.43513167, dtype=float32)]\n",
            "Batch 113 d_loss: 0.43513184785842896\n",
            "Batch 113 g_loss: [array(0.43513185, dtype=float32), array(0.43513185, dtype=float32), array(0.43513185, dtype=float32)]\n",
            "Batch 114 d_loss: 0.43518105149269104\n",
            "Batch 114 g_loss: [array(0.43518105, dtype=float32), array(0.43518105, dtype=float32), array(0.43518105, dtype=float32)]\n",
            "Batch 115 d_loss: 0.43520858883857727\n",
            "Batch 115 g_loss: [array(0.4352086, dtype=float32), array(0.4352086, dtype=float32), array(0.4352086, dtype=float32)]\n",
            "Batch 116 d_loss: 0.43522119522094727\n",
            "Batch 116 g_loss: [array(0.4352212, dtype=float32), array(0.4352212, dtype=float32), array(0.4352212, dtype=float32)]\n",
            "Batch 117 d_loss: 0.43526819348335266\n",
            "Batch 117 g_loss: [array(0.4352682, dtype=float32), array(0.4352682, dtype=float32), array(0.4352682, dtype=float32)]\n",
            "Batch 118 d_loss: 0.4353046715259552\n",
            "Batch 118 g_loss: [array(0.43530467, dtype=float32), array(0.43530467, dtype=float32), array(0.43530467, dtype=float32)]\n",
            "Batch 119 d_loss: 0.43529239296913147\n",
            "Batch 119 g_loss: [array(0.4352924, dtype=float32), array(0.4352924, dtype=float32), array(0.4352924, dtype=float32)]\n",
            "Batch 120 d_loss: 0.4353542923927307\n",
            "Batch 120 g_loss: [array(0.4353543, dtype=float32), array(0.4353543, dtype=float32), array(0.4353543, dtype=float32)]\n",
            "Batch 121 d_loss: 0.4353574216365814\n",
            "Batch 121 g_loss: [array(0.43535742, dtype=float32), array(0.43535742, dtype=float32), array(0.43535742, dtype=float32)]\n",
            "Batch 122 d_loss: 0.43534424901008606\n",
            "Batch 122 g_loss: [array(0.43534425, dtype=float32), array(0.43534425, dtype=float32), array(0.43534425, dtype=float32)]\n",
            "Batch 123 d_loss: 0.43531355261802673\n",
            "Batch 123 g_loss: [array(0.43531355, dtype=float32), array(0.43531355, dtype=float32), array(0.43531355, dtype=float32)]\n",
            "Batch 124 d_loss: 0.4353245496749878\n",
            "Batch 124 g_loss: [array(0.43532455, dtype=float32), array(0.43532455, dtype=float32), array(0.43532455, dtype=float32)]\n",
            "Batch 125 d_loss: 0.4353398382663727\n",
            "Batch 125 g_loss: [array(0.43533984, dtype=float32), array(0.43533984, dtype=float32), array(0.43533984, dtype=float32)]\n",
            "Batch 126 d_loss: 0.4353625774383545\n",
            "Batch 126 g_loss: [array(0.43536258, dtype=float32), array(0.43536258, dtype=float32), array(0.43536258, dtype=float32)]\n",
            "Batch 127 d_loss: 0.43536150455474854\n",
            "Batch 127 g_loss: [array(0.4353615, dtype=float32), array(0.4353615, dtype=float32), array(0.4353615, dtype=float32)]\n",
            "Batch 128 d_loss: 0.43530094623565674\n",
            "Batch 128 g_loss: [array(0.43530095, dtype=float32), array(0.43530095, dtype=float32), array(0.43530095, dtype=float32)]\n",
            "Batch 129 d_loss: 0.435307115316391\n",
            "Batch 129 g_loss: [array(0.43530712, dtype=float32), array(0.43530712, dtype=float32), array(0.43530712, dtype=float32)]\n",
            "Batch 130 d_loss: 0.4353479743003845\n",
            "Batch 130 g_loss: [array(0.43534797, dtype=float32), array(0.43534797, dtype=float32), array(0.43534797, dtype=float32)]\n",
            "Batch 131 d_loss: 0.43532776832580566\n",
            "Batch 131 g_loss: [array(0.43532777, dtype=float32), array(0.43532777, dtype=float32), array(0.43532777, dtype=float32)]\n",
            "Batch 132 d_loss: 0.4353196322917938\n",
            "Batch 132 g_loss: [array(0.43531963, dtype=float32), array(0.43531963, dtype=float32), array(0.43531963, dtype=float32)]\n",
            "Batch 133 d_loss: 0.4353102743625641\n",
            "Batch 133 g_loss: [array(0.43531027, dtype=float32), array(0.43531027, dtype=float32), array(0.43531027, dtype=float32)]\n",
            "Batch 134 d_loss: 0.43535247445106506\n",
            "Batch 134 g_loss: [array(0.43535247, dtype=float32), array(0.43535247, dtype=float32), array(0.43535247, dtype=float32)]\n",
            "Batch 135 d_loss: 0.4353674650192261\n",
            "Batch 135 g_loss: [array(0.43536747, dtype=float32), array(0.43536747, dtype=float32), array(0.43536747, dtype=float32)]\n",
            "Batch 136 d_loss: 0.43535348773002625\n",
            "Batch 136 g_loss: [array(0.4353535, dtype=float32), array(0.4353535, dtype=float32), array(0.4353535, dtype=float32)]\n",
            "Batch 137 d_loss: 0.43532654643058777\n",
            "Batch 137 g_loss: [array(0.43532655, dtype=float32), array(0.43532655, dtype=float32), array(0.43532655, dtype=float32)]\n",
            "Batch 138 d_loss: 0.43531325459480286\n",
            "Batch 138 g_loss: [array(0.43531325, dtype=float32), array(0.43531325, dtype=float32), array(0.43531325, dtype=float32)]\n",
            "Batch 139 d_loss: 0.4352676570415497\n",
            "Batch 139 g_loss: [array(0.43526766, dtype=float32), array(0.43526766, dtype=float32), array(0.43526766, dtype=float32)]\n",
            "Batch 140 d_loss: 0.4352262616157532\n",
            "Batch 140 g_loss: [array(0.43522626, dtype=float32), array(0.43522626, dtype=float32), array(0.43522626, dtype=float32)]\n",
            "Batch 141 d_loss: 0.4352125823497772\n",
            "Batch 141 g_loss: [array(0.43521258, dtype=float32), array(0.43521258, dtype=float32), array(0.43521258, dtype=float32)]\n",
            "Batch 142 d_loss: 0.43522220849990845\n",
            "Batch 142 g_loss: [array(0.4352222, dtype=float32), array(0.4352222, dtype=float32), array(0.4352222, dtype=float32)]\n",
            "Batch 143 d_loss: 0.4351814091205597\n",
            "Batch 143 g_loss: [array(0.4351814, dtype=float32), array(0.4351814, dtype=float32), array(0.4351814, dtype=float32)]\n",
            "Batch 144 d_loss: 0.4351624846458435\n",
            "Batch 144 g_loss: [array(0.43516248, dtype=float32), array(0.43516248, dtype=float32), array(0.43516248, dtype=float32)]\n",
            "Batch 145 d_loss: 0.4351644515991211\n",
            "Batch 145 g_loss: [array(0.43516445, dtype=float32), array(0.43516445, dtype=float32), array(0.43516445, dtype=float32)]\n",
            "Batch 146 d_loss: 0.43512359261512756\n",
            "Batch 146 g_loss: [array(0.4351236, dtype=float32), array(0.4351236, dtype=float32), array(0.4351236, dtype=float32)]\n",
            "Batch 147 d_loss: 0.4350939095020294\n",
            "Batch 147 g_loss: [array(0.4350939, dtype=float32), array(0.4350939, dtype=float32), array(0.4350939, dtype=float32)]\n",
            "Batch 148 d_loss: 0.4350748062133789\n",
            "Batch 148 g_loss: [array(0.4350748, dtype=float32), array(0.4350748, dtype=float32), array(0.4350748, dtype=float32)]\n",
            "Batch 149 d_loss: 0.43502485752105713\n",
            "Batch 149 g_loss: [array(0.43502486, dtype=float32), array(0.43502486, dtype=float32), array(0.43502486, dtype=float32)]\n",
            "Batch 150 d_loss: 0.4350014925003052\n",
            "Batch 150 g_loss: [array(0.4350015, dtype=float32), array(0.4350015, dtype=float32), array(0.4350015, dtype=float32)]\n",
            "Batch 151 d_loss: 0.4350375831127167\n",
            "Batch 151 g_loss: [array(0.43503758, dtype=float32), array(0.43503758, dtype=float32), array(0.43503758, dtype=float32)]\n",
            "Batch 152 d_loss: 0.4349942207336426\n",
            "Batch 152 g_loss: [array(0.43499422, dtype=float32), array(0.43499422, dtype=float32), array(0.43499422, dtype=float32)]\n",
            "Batch 153 d_loss: 0.43497806787490845\n",
            "Batch 153 g_loss: [array(0.43497807, dtype=float32), array(0.43497807, dtype=float32), array(0.43497807, dtype=float32)]\n",
            "Batch 154 d_loss: 0.4349823296070099\n",
            "Batch 154 g_loss: [array(0.43498233, dtype=float32), array(0.43498233, dtype=float32), array(0.43498233, dtype=float32)]\n",
            "Batch 155 d_loss: 0.43491700291633606\n",
            "Batch 155 g_loss: [array(0.434917, dtype=float32), array(0.434917, dtype=float32), array(0.434917, dtype=float32)]\n",
            "Batch 156 d_loss: 0.4348474144935608\n",
            "Batch 156 g_loss: [array(0.4348474, dtype=float32), array(0.4348474, dtype=float32), array(0.4348474, dtype=float32)]\n",
            "Batch 157 d_loss: 0.4347951114177704\n",
            "Batch 157 g_loss: [array(0.4347951, dtype=float32), array(0.4347951, dtype=float32), array(0.4347951, dtype=float32)]\n",
            "Batch 158 d_loss: 0.43481943011283875\n",
            "Batch 158 g_loss: [array(0.43481943, dtype=float32), array(0.43481943, dtype=float32), array(0.43481943, dtype=float32)]\n",
            "Batch 159 d_loss: 0.43478602170944214\n",
            "Batch 159 g_loss: [array(0.43478602, dtype=float32), array(0.43478602, dtype=float32), array(0.43478602, dtype=float32)]\n",
            "Batch 160 d_loss: 0.43479204177856445\n",
            "Batch 160 g_loss: [array(0.43479204, dtype=float32), array(0.43479204, dtype=float32), array(0.43479204, dtype=float32)]\n",
            "Batch 161 d_loss: 0.4347386956214905\n",
            "Batch 161 g_loss: [array(0.4347387, dtype=float32), array(0.4347387, dtype=float32), array(0.4347387, dtype=float32)]\n",
            "Batch 162 d_loss: 0.43468719720840454\n",
            "Batch 162 g_loss: [array(0.4346872, dtype=float32), array(0.4346872, dtype=float32), array(0.4346872, dtype=float32)]\n",
            "Batch 163 d_loss: 0.4346920847892761\n",
            "Batch 163 g_loss: [array(0.43469208, dtype=float32), array(0.43469208, dtype=float32), array(0.43469208, dtype=float32)]\n",
            "Batch 164 d_loss: 0.43468916416168213\n",
            "Batch 164 g_loss: [array(0.43468916, dtype=float32), array(0.43468916, dtype=float32), array(0.43468916, dtype=float32)]\n",
            "Batch 165 d_loss: 0.4346998333930969\n",
            "Batch 165 g_loss: [array(0.43469983, dtype=float32), array(0.43469983, dtype=float32), array(0.43469983, dtype=float32)]\n",
            "Batch 166 d_loss: 0.43472084403038025\n",
            "Batch 166 g_loss: [array(0.43472084, dtype=float32), array(0.43472084, dtype=float32), array(0.43472084, dtype=float32)]\n",
            "Batch 167 d_loss: 0.43469372391700745\n",
            "Batch 167 g_loss: [array(0.43469372, dtype=float32), array(0.43469372, dtype=float32), array(0.43469372, dtype=float32)]\n",
            "Batch 168 d_loss: 0.4347614645957947\n",
            "Batch 168 g_loss: [array(0.43476146, dtype=float32), array(0.43476146, dtype=float32), array(0.43476146, dtype=float32)]\n",
            "Batch 169 d_loss: 0.4347255229949951\n",
            "Batch 169 g_loss: [array(0.43472552, dtype=float32), array(0.43472552, dtype=float32), array(0.43472552, dtype=float32)]\n",
            "Batch 170 d_loss: 0.434702605009079\n",
            "Batch 170 g_loss: [array(0.4347026, dtype=float32), array(0.4347026, dtype=float32), array(0.4347026, dtype=float32)]\n",
            "Batch 171 d_loss: 0.4347167909145355\n",
            "Batch 171 g_loss: [array(0.4347168, dtype=float32), array(0.4347168, dtype=float32), array(0.4347168, dtype=float32)]\n",
            "Batch 172 d_loss: 0.4346945285797119\n",
            "Batch 172 g_loss: [array(0.43469453, dtype=float32), array(0.43469453, dtype=float32), array(0.43469453, dtype=float32)]\n",
            "Batch 173 d_loss: 0.43473902344703674\n",
            "Batch 173 g_loss: [array(0.43473902, dtype=float32), array(0.43473902, dtype=float32), array(0.43473902, dtype=float32)]\n",
            "Batch 174 d_loss: 0.43475431203842163\n",
            "Batch 174 g_loss: [array(0.4347543, dtype=float32), array(0.4347543, dtype=float32), array(0.4347543, dtype=float32)]\n",
            "Batch 175 d_loss: 0.4347662031650543\n",
            "Batch 175 g_loss: [array(0.4347662, dtype=float32), array(0.4347662, dtype=float32), array(0.4347662, dtype=float32)]\n",
            "Batch 176 d_loss: 0.434806227684021\n",
            "Batch 176 g_loss: [array(0.43480623, dtype=float32), array(0.43480623, dtype=float32), array(0.43480623, dtype=float32)]\n",
            "Batch 177 d_loss: 0.43484997749328613\n",
            "Batch 177 g_loss: [array(0.43484998, dtype=float32), array(0.43484998, dtype=float32), array(0.43484998, dtype=float32)]\n",
            "Batch 178 d_loss: 0.4348437488079071\n",
            "Batch 178 g_loss: [array(0.43484375, dtype=float32), array(0.43484375, dtype=float32), array(0.43484375, dtype=float32)]\n",
            "Batch 179 d_loss: 0.4348723888397217\n",
            "Batch 179 g_loss: [array(0.4348724, dtype=float32), array(0.4348724, dtype=float32), array(0.4348724, dtype=float32)]\n",
            "Batch 180 d_loss: 0.4348786771297455\n",
            "Batch 180 g_loss: [array(0.43487868, dtype=float32), array(0.43487868, dtype=float32), array(0.43487868, dtype=float32)]\n",
            "Batch 181 d_loss: 0.4348790943622589\n",
            "Batch 181 g_loss: [array(0.4348791, dtype=float32), array(0.4348791, dtype=float32), array(0.4348791, dtype=float32)]\n",
            "Batch 182 d_loss: 0.4348849952220917\n",
            "Batch 182 g_loss: [array(0.434885, dtype=float32), array(0.434885, dtype=float32), array(0.434885, dtype=float32)]\n",
            "Batch 183 d_loss: 0.4349221885204315\n",
            "Batch 183 g_loss: [array(0.4349222, dtype=float32), array(0.4349222, dtype=float32), array(0.4349222, dtype=float32)]\n",
            "Batch 184 d_loss: 0.4349139928817749\n",
            "Batch 184 g_loss: [array(0.434914, dtype=float32), array(0.434914, dtype=float32), array(0.434914, dtype=float32)]\n",
            "Batch 185 d_loss: 0.43494054675102234\n",
            "Batch 185 g_loss: [array(0.43494055, dtype=float32), array(0.43494055, dtype=float32), array(0.43494055, dtype=float32)]\n",
            "Batch 186 d_loss: 0.4349411427974701\n",
            "Batch 186 g_loss: [array(0.43494114, dtype=float32), array(0.43494114, dtype=float32), array(0.43494114, dtype=float32)]\n",
            "Batch 187 d_loss: 0.4349759817123413\n",
            "Batch 187 g_loss: [array(0.43497598, dtype=float32), array(0.43497598, dtype=float32), array(0.43497598, dtype=float32)]\n",
            "Batch 188 d_loss: 0.43495121598243713\n",
            "Batch 188 g_loss: [array(0.43495122, dtype=float32), array(0.43495122, dtype=float32), array(0.43495122, dtype=float32)]\n",
            "Batch 189 d_loss: 0.43500813841819763\n",
            "Batch 189 g_loss: [array(0.43500814, dtype=float32), array(0.43500814, dtype=float32), array(0.43500814, dtype=float32)]\n",
            "Batch 190 d_loss: 0.4350489675998688\n",
            "Batch 190 g_loss: [array(0.43504897, dtype=float32), array(0.43504897, dtype=float32), array(0.43504897, dtype=float32)]\n",
            "Batch 191 d_loss: 0.4350549876689911\n",
            "Batch 191 g_loss: [array(0.435055, dtype=float32), array(0.435055, dtype=float32), array(0.435055, dtype=float32)]\n",
            "Batch 192 d_loss: 0.4350839853286743\n",
            "Batch 192 g_loss: [array(0.435084, dtype=float32), array(0.435084, dtype=float32), array(0.435084, dtype=float32)]\n",
            "Batch 193 d_loss: 0.4350564777851105\n",
            "Batch 193 g_loss: [array(0.43505648, dtype=float32), array(0.43505648, dtype=float32), array(0.43505648, dtype=float32)]\n",
            "Batch 194 d_loss: 0.43513867259025574\n",
            "Batch 194 g_loss: [array(0.43513867, dtype=float32), array(0.43513867, dtype=float32), array(0.43513867, dtype=float32)]\n",
            "Batch 195 d_loss: 0.4351619482040405\n",
            "Batch 195 g_loss: [array(0.43516195, dtype=float32), array(0.43516195, dtype=float32), array(0.43516195, dtype=float32)]\n",
            "Batch 196 d_loss: 0.43520036339759827\n",
            "Batch 196 g_loss: [array(0.43520036, dtype=float32), array(0.43520036, dtype=float32), array(0.43520036, dtype=float32)]\n",
            "Batch 197 d_loss: 0.43522730469703674\n",
            "Batch 197 g_loss: [array(0.4352273, dtype=float32), array(0.4352273, dtype=float32), array(0.4352273, dtype=float32)]\n",
            "Batch 198 d_loss: 0.43527495861053467\n",
            "Batch 198 g_loss: [array(0.43527496, dtype=float32), array(0.43527496, dtype=float32), array(0.43527496, dtype=float32)]\n",
            "Batch 199 d_loss: 0.43539273738861084\n",
            "Batch 199 g_loss: [array(0.43539274, dtype=float32), array(0.43539274, dtype=float32), array(0.43539274, dtype=float32)]\n",
            "Batch 200 d_loss: 0.43549394607543945\n",
            "Batch 200 g_loss: [array(0.43549395, dtype=float32), array(0.43549395, dtype=float32), array(0.43549395, dtype=float32)]\n",
            "Batch 201 d_loss: 0.43553170561790466\n",
            "Batch 201 g_loss: [array(0.4355317, dtype=float32), array(0.4355317, dtype=float32), array(0.4355317, dtype=float32)]\n",
            "Batch 202 d_loss: 0.4355950355529785\n",
            "Batch 202 g_loss: [array(0.43559504, dtype=float32), array(0.43559504, dtype=float32), array(0.43559504, dtype=float32)]\n",
            "Batch 203 d_loss: 0.435650497674942\n",
            "Batch 203 g_loss: [array(0.4356505, dtype=float32), array(0.4356505, dtype=float32), array(0.4356505, dtype=float32)]\n",
            "Batch 204 d_loss: 0.4357336461544037\n",
            "Batch 204 g_loss: [array(0.43573365, dtype=float32), array(0.43573365, dtype=float32), array(0.43573365, dtype=float32)]\n",
            "Batch 205 d_loss: 0.4358188509941101\n",
            "Batch 205 g_loss: [array(0.43581885, dtype=float32), array(0.43581885, dtype=float32), array(0.43581885, dtype=float32)]\n",
            "Batch 206 d_loss: 0.43592119216918945\n",
            "Batch 206 g_loss: [array(0.4359212, dtype=float32), array(0.4359212, dtype=float32), array(0.4359212, dtype=float32)]\n",
            "Batch 207 d_loss: 0.43602627515792847\n",
            "Batch 207 g_loss: [array(0.43602628, dtype=float32), array(0.43602628, dtype=float32), array(0.43602628, dtype=float32)]\n",
            "Batch 208 d_loss: 0.43609118461608887\n",
            "Batch 208 g_loss: [array(0.43609118, dtype=float32), array(0.43609118, dtype=float32), array(0.43609118, dtype=float32)]\n",
            "Batch 209 d_loss: 0.4362351894378662\n",
            "Batch 209 g_loss: [array(0.4362352, dtype=float32), array(0.4362352, dtype=float32), array(0.4362352, dtype=float32)]\n",
            "Batch 210 d_loss: 0.4363008737564087\n",
            "Batch 210 g_loss: [array(0.43630087, dtype=float32), array(0.43630087, dtype=float32), array(0.43630087, dtype=float32)]\n",
            "Batch 211 d_loss: 0.43637025356292725\n",
            "Batch 211 g_loss: [array(0.43637025, dtype=float32), array(0.43637025, dtype=float32), array(0.43637025, dtype=float32)]\n",
            "Batch 212 d_loss: 0.4364742338657379\n",
            "Batch 212 g_loss: [array(0.43647423, dtype=float32), array(0.43647423, dtype=float32), array(0.43647423, dtype=float32)]\n",
            "Batch 213 d_loss: 0.43650996685028076\n",
            "Batch 213 g_loss: [array(0.43650997, dtype=float32), array(0.43650997, dtype=float32), array(0.43650997, dtype=float32)]\n",
            "Batch 214 d_loss: 0.43664082884788513\n",
            "Batch 214 g_loss: [array(0.43664083, dtype=float32), array(0.43664083, dtype=float32), array(0.43664083, dtype=float32)]\n",
            "Batch 215 d_loss: 0.4367450475692749\n",
            "Batch 215 g_loss: [array(0.43674505, dtype=float32), array(0.43674505, dtype=float32), array(0.43674505, dtype=float32)]\n",
            "Batch 216 d_loss: 0.4368572235107422\n",
            "Batch 216 g_loss: [array(0.43685722, dtype=float32), array(0.43685722, dtype=float32), array(0.43685722, dtype=float32)]\n",
            "Batch 217 d_loss: 0.43699193000793457\n",
            "Batch 217 g_loss: [array(0.43699193, dtype=float32), array(0.43699193, dtype=float32), array(0.43699193, dtype=float32)]\n",
            "Batch 218 d_loss: 0.43710002303123474\n",
            "Batch 218 g_loss: [array(0.43710002, dtype=float32), array(0.43710002, dtype=float32), array(0.43710002, dtype=float32)]\n",
            "Batch 219 d_loss: 0.4372197389602661\n",
            "Batch 219 g_loss: [array(0.43721974, dtype=float32), array(0.43721974, dtype=float32), array(0.43721974, dtype=float32)]\n",
            "Batch 220 d_loss: 0.43732133507728577\n",
            "Batch 220 g_loss: [array(0.43732134, dtype=float32), array(0.43732134, dtype=float32), array(0.43732134, dtype=float32)]\n",
            "Batch 221 d_loss: 0.4374680817127228\n",
            "Batch 221 g_loss: [array(0.43746808, dtype=float32), array(0.43746808, dtype=float32), array(0.43746808, dtype=float32)]\n",
            "Batch 222 d_loss: 0.4375116527080536\n",
            "Batch 222 g_loss: [array(0.43751165, dtype=float32), array(0.43751165, dtype=float32), array(0.43751165, dtype=float32)]\n",
            "Batch 223 d_loss: 0.43758371472358704\n",
            "Batch 223 g_loss: [array(0.4375837, dtype=float32), array(0.4375837, dtype=float32), array(0.4375837, dtype=float32)]\n",
            "Batch 224 d_loss: 0.43766310811042786\n",
            "Batch 224 g_loss: [array(0.4376631, dtype=float32), array(0.4376631, dtype=float32), array(0.4376631, dtype=float32)]\n",
            "Batch 225 d_loss: 0.4378102421760559\n",
            "Batch 225 g_loss: [array(0.43781024, dtype=float32), array(0.43781024, dtype=float32), array(0.43781024, dtype=float32)]\n",
            "Batch 226 d_loss: 0.43801748752593994\n",
            "Batch 226 g_loss: [array(0.4380175, dtype=float32), array(0.4380175, dtype=float32), array(0.4380175, dtype=float32)]\n",
            "Batch 227 d_loss: 0.4381546080112457\n",
            "Batch 227 g_loss: [array(0.4381546, dtype=float32), array(0.4381546, dtype=float32), array(0.4381546, dtype=float32)]\n",
            "Batch 228 d_loss: 0.43827375769615173\n",
            "Batch 228 g_loss: [array(0.43827376, dtype=float32), array(0.43827376, dtype=float32), array(0.43827376, dtype=float32)]\n",
            "Batch 229 d_loss: 0.43844059109687805\n",
            "Batch 229 g_loss: [array(0.4384406, dtype=float32), array(0.4384406, dtype=float32), array(0.4384406, dtype=float32)]\n",
            "Batch 230 d_loss: 0.43856754899024963\n",
            "Batch 230 g_loss: [array(0.43856755, dtype=float32), array(0.43856755, dtype=float32), array(0.43856755, dtype=float32)]\n",
            "Batch 231 d_loss: 0.4386884868144989\n",
            "Batch 231 g_loss: [array(0.4386885, dtype=float32), array(0.4386885, dtype=float32), array(0.4386885, dtype=float32)]\n",
            "Batch 232 d_loss: 0.4387759864330292\n",
            "Batch 232 g_loss: [array(0.438776, dtype=float32), array(0.438776, dtype=float32), array(0.438776, dtype=float32)]\n",
            "Batch 233 d_loss: 0.4389253258705139\n",
            "Batch 233 g_loss: [array(0.43892533, dtype=float32), array(0.43892533, dtype=float32), array(0.43892533, dtype=float32)]\n",
            "Batch 234 d_loss: 0.4390561878681183\n",
            "Batch 234 g_loss: [array(0.4390562, dtype=float32), array(0.4390562, dtype=float32), array(0.4390562, dtype=float32)]\n",
            "Batch 235 d_loss: 0.4391680657863617\n",
            "Batch 235 g_loss: [array(0.43916807, dtype=float32), array(0.43916807, dtype=float32), array(0.43916807, dtype=float32)]\n",
            "Batch 236 d_loss: 0.4393327534198761\n",
            "Batch 236 g_loss: [array(0.43933275, dtype=float32), array(0.43933275, dtype=float32), array(0.43933275, dtype=float32)]\n",
            "Batch 237 d_loss: 0.43946748971939087\n",
            "Batch 237 g_loss: [array(0.4394675, dtype=float32), array(0.4394675, dtype=float32), array(0.4394675, dtype=float32)]\n",
            "Batch 238 d_loss: 0.43961265683174133\n",
            "Batch 238 g_loss: [array(0.43961266, dtype=float32), array(0.43961266, dtype=float32), array(0.43961266, dtype=float32)]\n",
            "Batch 239 d_loss: 0.4398100674152374\n",
            "Batch 239 g_loss: [array(0.43981007, dtype=float32), array(0.43981007, dtype=float32), array(0.43981007, dtype=float32)]\n",
            "Batch 240 d_loss: 0.4399391710758209\n",
            "Batch 240 g_loss: [array(0.43993917, dtype=float32), array(0.43993917, dtype=float32), array(0.43993917, dtype=float32)]\n",
            "Batch 241 d_loss: 0.4401162266731262\n",
            "Batch 241 g_loss: [array(0.44011623, dtype=float32), array(0.44011623, dtype=float32), array(0.44011623, dtype=float32)]\n",
            "Batch 242 d_loss: 0.44031211733818054\n",
            "Batch 242 g_loss: [array(0.44031212, dtype=float32), array(0.44031212, dtype=float32), array(0.44031212, dtype=float32)]\n",
            "Batch 243 d_loss: 0.4405078589916229\n",
            "Batch 243 g_loss: [array(0.44050786, dtype=float32), array(0.44050786, dtype=float32), array(0.44050786, dtype=float32)]\n",
            "Batch 244 d_loss: 0.4406746029853821\n",
            "Batch 244 g_loss: [array(0.4406746, dtype=float32), array(0.4406746, dtype=float32), array(0.4406746, dtype=float32)]\n",
            "Batch 245 d_loss: 0.44086599349975586\n",
            "Batch 245 g_loss: [array(0.440866, dtype=float32), array(0.440866, dtype=float32), array(0.440866, dtype=float32)]\n",
            "Batch 246 d_loss: 0.4410891532897949\n",
            "Batch 246 g_loss: [array(0.44108915, dtype=float32), array(0.44108915, dtype=float32), array(0.44108915, dtype=float32)]\n",
            "Batch 247 d_loss: 0.4412649869918823\n",
            "Batch 247 g_loss: [array(0.441265, dtype=float32), array(0.441265, dtype=float32), array(0.441265, dtype=float32)]\n",
            "Batch 248 d_loss: 0.4413958787918091\n",
            "Batch 248 g_loss: [array(0.44139588, dtype=float32), array(0.44139588, dtype=float32), array(0.44139588, dtype=float32)]\n",
            "Batch 249 d_loss: 0.4415687024593353\n",
            "Batch 249 g_loss: [array(0.4415687, dtype=float32), array(0.4415687, dtype=float32), array(0.4415687, dtype=float32)]\n",
            "Batch 250 d_loss: 0.4417627453804016\n",
            "Batch 250 g_loss: [array(0.44176275, dtype=float32), array(0.44176275, dtype=float32), array(0.44176275, dtype=float32)]\n",
            "Batch 251 d_loss: 0.4419817626476288\n",
            "Batch 251 g_loss: [array(0.44198176, dtype=float32), array(0.44198176, dtype=float32), array(0.44198176, dtype=float32)]\n",
            "Batch 252 d_loss: 0.4421474039554596\n",
            "Batch 252 g_loss: [array(0.4421474, dtype=float32), array(0.4421474, dtype=float32), array(0.4421474, dtype=float32)]\n",
            "Batch 253 d_loss: 0.4423368275165558\n",
            "Batch 253 g_loss: [array(0.44233683, dtype=float32), array(0.44233683, dtype=float32), array(0.44233683, dtype=float32)]\n",
            "Batch 254 d_loss: 0.44255316257476807\n",
            "Batch 254 g_loss: [array(0.44255316, dtype=float32), array(0.44255316, dtype=float32), array(0.44255316, dtype=float32)]\n",
            "Batch 255 d_loss: 0.442762553691864\n",
            "Batch 255 g_loss: [array(0.44276255, dtype=float32), array(0.44276255, dtype=float32), array(0.44276255, dtype=float32)]\n",
            "Batch 256 d_loss: 0.4430016279220581\n",
            "Batch 256 g_loss: [array(0.44300163, dtype=float32), array(0.44300163, dtype=float32), array(0.44300163, dtype=float32)]\n",
            "Batch 257 d_loss: 0.44323793053627014\n",
            "Batch 257 g_loss: [array(0.44323793, dtype=float32), array(0.44323793, dtype=float32), array(0.44323793, dtype=float32)]\n",
            "Batch 258 d_loss: 0.4434141218662262\n",
            "Batch 258 g_loss: [array(0.44341412, dtype=float32), array(0.44341412, dtype=float32), array(0.44341412, dtype=float32)]\n",
            "Batch 259 d_loss: 0.44360649585723877\n",
            "Batch 259 g_loss: [array(0.4436065, dtype=float32), array(0.4436065, dtype=float32), array(0.4436065, dtype=float32)]\n",
            "Batch 260 d_loss: 0.44384023547172546\n",
            "Batch 260 g_loss: [array(0.44384024, dtype=float32), array(0.44384024, dtype=float32), array(0.44384024, dtype=float32)]\n",
            "Batch 261 d_loss: 0.4440131187438965\n",
            "Batch 261 g_loss: [array(0.44401312, dtype=float32), array(0.44401312, dtype=float32), array(0.44401312, dtype=float32)]\n",
            "Batch 262 d_loss: 0.4442024827003479\n",
            "Batch 262 g_loss: [array(0.44420248, dtype=float32), array(0.44420248, dtype=float32), array(0.44420248, dtype=float32)]\n",
            "Batch 263 d_loss: 0.4444285035133362\n",
            "Batch 263 g_loss: [array(0.4444285, dtype=float32), array(0.4444285, dtype=float32), array(0.4444285, dtype=float32)]\n",
            "Batch 264 d_loss: 0.44463589787483215\n",
            "Batch 264 g_loss: [array(0.4446359, dtype=float32), array(0.4446359, dtype=float32), array(0.4446359, dtype=float32)]\n",
            "Batch 265 d_loss: 0.444749116897583\n",
            "Batch 265 g_loss: [array(0.44474912, dtype=float32), array(0.44474912, dtype=float32), array(0.44474912, dtype=float32)]\n",
            "Batch 266 d_loss: 0.4448701739311218\n",
            "Batch 266 g_loss: [array(0.44487017, dtype=float32), array(0.44487017, dtype=float32), array(0.44487017, dtype=float32)]\n",
            "Batch 267 d_loss: 0.4450063705444336\n",
            "Batch 267 g_loss: [array(0.44500637, dtype=float32), array(0.44500637, dtype=float32), array(0.44500637, dtype=float32)]\n",
            "Batch 268 d_loss: 0.4451421797275543\n",
            "Batch 268 g_loss: [array(0.44514218, dtype=float32), array(0.44514218, dtype=float32), array(0.44514218, dtype=float32)]\n",
            "Batch 269 d_loss: 0.445355087518692\n",
            "Batch 269 g_loss: [array(0.4453551, dtype=float32), array(0.4453551, dtype=float32), array(0.4453551, dtype=float32)]\n",
            "Batch 270 d_loss: 0.4455602765083313\n",
            "Batch 270 g_loss: [array(0.44556028, dtype=float32), array(0.44556028, dtype=float32), array(0.44556028, dtype=float32)]\n",
            "Batch 271 d_loss: 0.4457412362098694\n",
            "Batch 271 g_loss: [array(0.44574124, dtype=float32), array(0.44574124, dtype=float32), array(0.44574124, dtype=float32)]\n",
            "Batch 272 d_loss: 0.44592735171318054\n",
            "Batch 272 g_loss: [array(0.44592735, dtype=float32), array(0.44592735, dtype=float32), array(0.44592735, dtype=float32)]\n",
            "Batch 273 d_loss: 0.44603896141052246\n",
            "Batch 273 g_loss: [array(0.44603896, dtype=float32), array(0.44603896, dtype=float32), array(0.44603896, dtype=float32)]\n",
            "Batch 274 d_loss: 0.4462040364742279\n",
            "Batch 274 g_loss: [array(0.44620404, dtype=float32), array(0.44620404, dtype=float32), array(0.44620404, dtype=float32)]\n",
            "Batch 275 d_loss: 0.44636163115501404\n",
            "Batch 275 g_loss: [array(0.44636163, dtype=float32), array(0.44636163, dtype=float32), array(0.44636163, dtype=float32)]\n",
            "Batch 276 d_loss: 0.4466113746166229\n",
            "Batch 276 g_loss: [array(0.44661137, dtype=float32), array(0.44661137, dtype=float32), array(0.44661137, dtype=float32)]\n",
            "Batch 277 d_loss: 0.44675010442733765\n",
            "Batch 277 g_loss: [array(0.4467501, dtype=float32), array(0.4467501, dtype=float32), array(0.4467501, dtype=float32)]\n",
            "Batch 278 d_loss: 0.4468916654586792\n",
            "Batch 278 g_loss: [array(0.44689167, dtype=float32), array(0.44689167, dtype=float32), array(0.44689167, dtype=float32)]\n",
            "Batch 279 d_loss: 0.44703710079193115\n",
            "Batch 279 g_loss: [array(0.4470371, dtype=float32), array(0.4470371, dtype=float32), array(0.4470371, dtype=float32)]\n",
            "Batch 280 d_loss: 0.44711950421333313\n",
            "Batch 280 g_loss: [array(0.4471195, dtype=float32), array(0.4471195, dtype=float32), array(0.4471195, dtype=float32)]\n",
            "Batch 281 d_loss: 0.44735774397850037\n",
            "Batch 281 g_loss: [array(0.44735774, dtype=float32), array(0.44735774, dtype=float32), array(0.44735774, dtype=float32)]\n",
            "Batch 282 d_loss: 0.4475718140602112\n",
            "Batch 282 g_loss: [array(0.4475718, dtype=float32), array(0.4475718, dtype=float32), array(0.4475718, dtype=float32)]\n",
            "Batch 283 d_loss: 0.4477482736110687\n",
            "Batch 283 g_loss: [array(0.44774827, dtype=float32), array(0.44774827, dtype=float32), array(0.44774827, dtype=float32)]\n",
            "Batch 284 d_loss: 0.4479351043701172\n",
            "Batch 284 g_loss: [array(0.4479351, dtype=float32), array(0.4479351, dtype=float32), array(0.4479351, dtype=float32)]\n",
            "Batch 285 d_loss: 0.4480631649494171\n",
            "Batch 285 g_loss: [array(0.44806316, dtype=float32), array(0.44806316, dtype=float32), array(0.44806316, dtype=float32)]\n",
            "Batch 286 d_loss: 0.4481741189956665\n",
            "Batch 286 g_loss: [array(0.44817412, dtype=float32), array(0.44817412, dtype=float32), array(0.44817412, dtype=float32)]\n",
            "Batch 287 d_loss: 0.4482651650905609\n",
            "Batch 287 g_loss: [array(0.44826517, dtype=float32), array(0.44826517, dtype=float32), array(0.44826517, dtype=float32)]\n",
            "Batch 288 d_loss: 0.448412150144577\n",
            "Batch 288 g_loss: [array(0.44841215, dtype=float32), array(0.44841215, dtype=float32), array(0.44841215, dtype=float32)]\n",
            "Batch 289 d_loss: 0.44851118326187134\n",
            "Batch 289 g_loss: [array(0.44851118, dtype=float32), array(0.44851118, dtype=float32), array(0.44851118, dtype=float32)]\n",
            "Batch 290 d_loss: 0.44863569736480713\n",
            "Batch 290 g_loss: [array(0.4486357, dtype=float32), array(0.4486357, dtype=float32), array(0.4486357, dtype=float32)]\n",
            "Batch 291 d_loss: 0.4487142860889435\n",
            "Batch 291 g_loss: [array(0.4487143, dtype=float32), array(0.4487143, dtype=float32), array(0.4487143, dtype=float32)]\n",
            "Batch 292 d_loss: 0.44878673553466797\n",
            "Batch 292 g_loss: [array(0.44878674, dtype=float32), array(0.44878674, dtype=float32), array(0.44878674, dtype=float32)]\n",
            "Batch 293 d_loss: 0.44887569546699524\n",
            "Batch 293 g_loss: [array(0.4488757, dtype=float32), array(0.4488757, dtype=float32), array(0.4488757, dtype=float32)]\n",
            "Batch 294 d_loss: 0.449007123708725\n",
            "Batch 294 g_loss: [array(0.44900712, dtype=float32), array(0.44900712, dtype=float32), array(0.44900712, dtype=float32)]\n",
            "Batch 295 d_loss: 0.4490836560726166\n",
            "Batch 295 g_loss: [array(0.44908366, dtype=float32), array(0.44908366, dtype=float32), array(0.44908366, dtype=float32)]\n",
            "Batch 296 d_loss: 0.4491736590862274\n",
            "Batch 296 g_loss: [array(0.44917366, dtype=float32), array(0.44917366, dtype=float32), array(0.44917366, dtype=float32)]\n",
            "Batch 297 d_loss: 0.44918978214263916\n",
            "Batch 297 g_loss: [array(0.44918978, dtype=float32), array(0.44918978, dtype=float32), array(0.44918978, dtype=float32)]\n",
            "Batch 298 d_loss: 0.4492536187171936\n",
            "Batch 298 g_loss: [array(0.44925362, dtype=float32), array(0.44925362, dtype=float32), array(0.44925362, dtype=float32)]\n",
            "Batch 299 d_loss: 0.44933903217315674\n",
            "Batch 299 g_loss: [array(0.44933903, dtype=float32), array(0.44933903, dtype=float32), array(0.44933903, dtype=float32)]\n",
            "Batch 300 d_loss: 0.44937992095947266\n",
            "Batch 300 g_loss: [array(0.44937992, dtype=float32), array(0.44937992, dtype=float32), array(0.44937992, dtype=float32)]\n",
            "Batch 301 d_loss: 0.44939324259757996\n",
            "Batch 301 g_loss: [array(0.44939324, dtype=float32), array(0.44939324, dtype=float32), array(0.44939324, dtype=float32)]\n",
            "Batch 302 d_loss: 0.44944289326667786\n",
            "Batch 302 g_loss: [array(0.4494429, dtype=float32), array(0.4494429, dtype=float32), array(0.4494429, dtype=float32)]\n",
            "Batch 303 d_loss: 0.4494677782058716\n",
            "Batch 303 g_loss: [array(0.44946778, dtype=float32), array(0.44946778, dtype=float32), array(0.44946778, dtype=float32)]\n",
            "Batch 304 d_loss: 0.4495207965373993\n",
            "Batch 304 g_loss: [array(0.4495208, dtype=float32), array(0.4495208, dtype=float32), array(0.4495208, dtype=float32)]\n",
            "Batch 305 d_loss: 0.4495677053928375\n",
            "Batch 305 g_loss: [array(0.4495677, dtype=float32), array(0.4495677, dtype=float32), array(0.4495677, dtype=float32)]\n",
            "Batch 306 d_loss: 0.4496344327926636\n",
            "Batch 306 g_loss: [array(0.44963443, dtype=float32), array(0.44963443, dtype=float32), array(0.44963443, dtype=float32)]\n",
            "Batch 307 d_loss: 0.449655145406723\n",
            "Batch 307 g_loss: [array(0.44965515, dtype=float32), array(0.44965515, dtype=float32), array(0.44965515, dtype=float32)]\n",
            "Batch 308 d_loss: 0.44966110587120056\n",
            "Batch 308 g_loss: [array(0.4496611, dtype=float32), array(0.4496611, dtype=float32), array(0.4496611, dtype=float32)]\n",
            "Batch 309 d_loss: 0.449672669172287\n",
            "Batch 309 g_loss: [array(0.44967267, dtype=float32), array(0.44967267, dtype=float32), array(0.44967267, dtype=float32)]\n",
            "Batch 310 d_loss: 0.4496857225894928\n",
            "Batch 310 g_loss: [array(0.44968572, dtype=float32), array(0.44968572, dtype=float32), array(0.44968572, dtype=float32)]\n",
            "Batch 311 d_loss: 0.449703186750412\n",
            "Batch 311 g_loss: [array(0.4497032, dtype=float32), array(0.4497032, dtype=float32), array(0.4497032, dtype=float32)]\n",
            "Batch 312 d_loss: 0.4497401714324951\n",
            "Batch 312 g_loss: [array(0.44974017, dtype=float32), array(0.44974017, dtype=float32), array(0.44974017, dtype=float32)]\n",
            "Batch 313 d_loss: 0.4497554898262024\n",
            "Batch 313 g_loss: [array(0.4497555, dtype=float32), array(0.4497555, dtype=float32), array(0.4497555, dtype=float32)]\n",
            "Batch 314 d_loss: 0.44973522424697876\n",
            "Batch 314 g_loss: [array(0.44973522, dtype=float32), array(0.44973522, dtype=float32), array(0.44973522, dtype=float32)]\n",
            "Batch 315 d_loss: 0.4497591257095337\n",
            "Batch 315 g_loss: [array(0.44975913, dtype=float32), array(0.44975913, dtype=float32), array(0.44975913, dtype=float32)]\n",
            "Batch 316 d_loss: 0.44974496960639954\n",
            "Batch 316 g_loss: [array(0.44974497, dtype=float32), array(0.44974497, dtype=float32), array(0.44974497, dtype=float32)]\n",
            "Batch 317 d_loss: 0.44973692297935486\n",
            "Batch 317 g_loss: [array(0.44973692, dtype=float32), array(0.44973692, dtype=float32), array(0.44973692, dtype=float32)]\n",
            "Batch 318 d_loss: 0.44972699880599976\n",
            "Batch 318 g_loss: [array(0.449727, dtype=float32), array(0.449727, dtype=float32), array(0.449727, dtype=float32)]\n",
            "Batch 319 d_loss: 0.4497607946395874\n",
            "Batch 319 g_loss: [array(0.4497608, dtype=float32), array(0.4497608, dtype=float32), array(0.4497608, dtype=float32)]\n",
            "Batch 320 d_loss: 0.4497545659542084\n",
            "Batch 320 g_loss: [array(0.44975457, dtype=float32), array(0.44975457, dtype=float32), array(0.44975457, dtype=float32)]\n",
            "Batch 321 d_loss: 0.4497213661670685\n",
            "Batch 321 g_loss: [array(0.44972137, dtype=float32), array(0.44972137, dtype=float32), array(0.44972137, dtype=float32)]\n",
            "Batch 322 d_loss: 0.44972261786460876\n",
            "Batch 322 g_loss: [array(0.44972262, dtype=float32), array(0.44972262, dtype=float32), array(0.44972262, dtype=float32)]\n",
            "Batch 323 d_loss: 0.4496637284755707\n",
            "Batch 323 g_loss: [array(0.44966373, dtype=float32), array(0.44966373, dtype=float32), array(0.44966373, dtype=float32)]\n",
            "Batch 324 d_loss: 0.4496293365955353\n",
            "Batch 324 g_loss: [array(0.44962934, dtype=float32), array(0.44962934, dtype=float32), array(0.44962934, dtype=float32)]\n",
            "Batch 325 d_loss: 0.4495796859264374\n",
            "Batch 325 g_loss: [array(0.4495797, dtype=float32), array(0.4495797, dtype=float32), array(0.4495797, dtype=float32)]\n",
            "Batch 326 d_loss: 0.44957607984542847\n",
            "Batch 326 g_loss: [array(0.44957608, dtype=float32), array(0.44957608, dtype=float32), array(0.44957608, dtype=float32)]\n",
            "Batch 327 d_loss: 0.44951388239860535\n",
            "Batch 327 g_loss: [array(0.44951388, dtype=float32), array(0.44951388, dtype=float32), array(0.44951388, dtype=float32)]\n",
            "Batch 328 d_loss: 0.4494551122188568\n",
            "Batch 328 g_loss: [array(0.4494551, dtype=float32), array(0.4494551, dtype=float32), array(0.4494551, dtype=float32)]\n",
            "Batch 329 d_loss: 0.4493902027606964\n",
            "Batch 329 g_loss: [array(0.4493902, dtype=float32), array(0.4493902, dtype=float32), array(0.4493902, dtype=float32)]\n",
            "Batch 330 d_loss: 0.44934001564979553\n",
            "Batch 330 g_loss: [array(0.44934002, dtype=float32), array(0.44934002, dtype=float32), array(0.44934002, dtype=float32)]\n",
            "Batch 331 d_loss: 0.44929444789886475\n",
            "Batch 331 g_loss: [array(0.44929445, dtype=float32), array(0.44929445, dtype=float32), array(0.44929445, dtype=float32)]\n",
            "Batch 332 d_loss: 0.44925326108932495\n",
            "Batch 332 g_loss: [array(0.44925326, dtype=float32), array(0.44925326, dtype=float32), array(0.44925326, dtype=float32)]\n",
            "Batch 333 d_loss: 0.4492112398147583\n",
            "Batch 333 g_loss: [array(0.44921124, dtype=float32), array(0.44921124, dtype=float32), array(0.44921124, dtype=float32)]\n",
            "Batch 334 d_loss: 0.4491555988788605\n",
            "Batch 334 g_loss: [array(0.4491556, dtype=float32), array(0.4491556, dtype=float32), array(0.4491556, dtype=float32)]\n",
            "Batch 335 d_loss: 0.44910213351249695\n",
            "Batch 335 g_loss: [array(0.44910213, dtype=float32), array(0.44910213, dtype=float32), array(0.44910213, dtype=float32)]\n",
            "Batch 336 d_loss: 0.4490635097026825\n",
            "Batch 336 g_loss: [array(0.4490635, dtype=float32), array(0.4490635, dtype=float32), array(0.4490635, dtype=float32)]\n",
            "Batch 337 d_loss: 0.4489928185939789\n",
            "Batch 337 g_loss: [array(0.44899282, dtype=float32), array(0.44899282, dtype=float32), array(0.44899282, dtype=float32)]\n",
            "Batch 338 d_loss: 0.4489608705043793\n",
            "Batch 338 g_loss: [array(0.44896087, dtype=float32), array(0.44896087, dtype=float32), array(0.44896087, dtype=float32)]\n",
            "Batch 339 d_loss: 0.4489647150039673\n",
            "Batch 339 g_loss: [array(0.44896472, dtype=float32), array(0.44896472, dtype=float32), array(0.44896472, dtype=float32)]\n",
            "Batch 340 d_loss: 0.448923259973526\n",
            "Batch 340 g_loss: [array(0.44892326, dtype=float32), array(0.44892326, dtype=float32), array(0.44892326, dtype=float32)]\n",
            "Batch 341 d_loss: 0.44889822602272034\n",
            "Batch 341 g_loss: [array(0.44889823, dtype=float32), array(0.44889823, dtype=float32), array(0.44889823, dtype=float32)]\n",
            "Batch 342 d_loss: 0.4488038718700409\n",
            "Batch 342 g_loss: [array(0.44880387, dtype=float32), array(0.44880387, dtype=float32), array(0.44880387, dtype=float32)]\n",
            "Batch 343 d_loss: 0.44873249530792236\n",
            "Batch 343 g_loss: [array(0.4487325, dtype=float32), array(0.4487325, dtype=float32), array(0.4487325, dtype=float32)]\n",
            "Batch 344 d_loss: 0.4486437439918518\n",
            "Batch 344 g_loss: [array(0.44864374, dtype=float32), array(0.44864374, dtype=float32), array(0.44864374, dtype=float32)]\n",
            "Batch 345 d_loss: 0.4485415518283844\n",
            "Batch 345 g_loss: [array(0.44854155, dtype=float32), array(0.44854155, dtype=float32), array(0.44854155, dtype=float32)]\n",
            "Batch 346 d_loss: 0.4484995901584625\n",
            "Batch 346 g_loss: [array(0.4484996, dtype=float32), array(0.4484996, dtype=float32), array(0.4484996, dtype=float32)]\n",
            "Batch 347 d_loss: 0.44849836826324463\n",
            "Batch 347 g_loss: [array(0.44849837, dtype=float32), array(0.44849837, dtype=float32), array(0.44849837, dtype=float32)]\n",
            "Batch 348 d_loss: 0.4484006464481354\n",
            "Batch 348 g_loss: [array(0.44840065, dtype=float32), array(0.44840065, dtype=float32), array(0.44840065, dtype=float32)]\n",
            "Batch 349 d_loss: 0.4483497738838196\n",
            "Batch 349 g_loss: [array(0.44834977, dtype=float32), array(0.44834977, dtype=float32), array(0.44834977, dtype=float32)]\n",
            "Batch 350 d_loss: 0.44832706451416016\n",
            "Batch 350 g_loss: [array(0.44832706, dtype=float32), array(0.44832706, dtype=float32), array(0.44832706, dtype=float32)]\n",
            "Batch 351 d_loss: 0.44826456904411316\n",
            "Batch 351 g_loss: [array(0.44826457, dtype=float32), array(0.44826457, dtype=float32), array(0.44826457, dtype=float32)]\n",
            "Batch 352 d_loss: 0.4482162892818451\n",
            "Batch 352 g_loss: [array(0.4482163, dtype=float32), array(0.4482163, dtype=float32), array(0.4482163, dtype=float32)]\n",
            "Batch 353 d_loss: 0.44814562797546387\n",
            "Batch 353 g_loss: [array(0.44814563, dtype=float32), array(0.44814563, dtype=float32), array(0.44814563, dtype=float32)]\n",
            "Batch 354 d_loss: 0.4480660557746887\n",
            "Batch 354 g_loss: [array(0.44806606, dtype=float32), array(0.44806606, dtype=float32), array(0.44806606, dtype=float32)]\n",
            "Batch 355 d_loss: 0.44800320267677307\n",
            "Batch 355 g_loss: [array(0.4480032, dtype=float32), array(0.4480032, dtype=float32), array(0.4480032, dtype=float32)]\n",
            "Batch 356 d_loss: 0.44797053933143616\n",
            "Batch 356 g_loss: [array(0.44797054, dtype=float32), array(0.44797054, dtype=float32), array(0.44797054, dtype=float32)]\n",
            "Batch 357 d_loss: 0.4479197561740875\n",
            "Batch 357 g_loss: [array(0.44791976, dtype=float32), array(0.44791976, dtype=float32), array(0.44791976, dtype=float32)]\n",
            "Batch 358 d_loss: 0.4478471279144287\n",
            "Batch 358 g_loss: [array(0.44784713, dtype=float32), array(0.44784713, dtype=float32), array(0.44784713, dtype=float32)]\n",
            "Batch 359 d_loss: 0.44775813817977905\n",
            "Batch 359 g_loss: [array(0.44775814, dtype=float32), array(0.44775814, dtype=float32), array(0.44775814, dtype=float32)]\n",
            "Batch 360 d_loss: 0.44771069288253784\n",
            "Batch 360 g_loss: [array(0.4477107, dtype=float32), array(0.4477107, dtype=float32), array(0.4477107, dtype=float32)]\n",
            "Batch 361 d_loss: 0.44763267040252686\n",
            "Batch 361 g_loss: [array(0.44763267, dtype=float32), array(0.44763267, dtype=float32), array(0.44763267, dtype=float32)]\n",
            "Batch 362 d_loss: 0.44754934310913086\n",
            "Batch 362 g_loss: [array(0.44754934, dtype=float32), array(0.44754934, dtype=float32), array(0.44754934, dtype=float32)]\n",
            "Batch 363 d_loss: 0.44742804765701294\n",
            "Batch 363 g_loss: [array(0.44742805, dtype=float32), array(0.44742805, dtype=float32), array(0.44742805, dtype=float32)]\n",
            "Batch 364 d_loss: 0.4473596215248108\n",
            "Batch 364 g_loss: [array(0.44735962, dtype=float32), array(0.44735962, dtype=float32), array(0.44735962, dtype=float32)]\n",
            "Batch 365 d_loss: 0.44730475544929504\n",
            "Batch 365 g_loss: [array(0.44730476, dtype=float32), array(0.44730476, dtype=float32), array(0.44730476, dtype=float32)]\n",
            "Batch 366 d_loss: 0.44722431898117065\n",
            "Batch 366 g_loss: [array(0.44722432, dtype=float32), array(0.44722432, dtype=float32), array(0.44722432, dtype=float32)]\n",
            "Batch 367 d_loss: 0.44712841510772705\n",
            "Batch 367 g_loss: [array(0.44712842, dtype=float32), array(0.44712842, dtype=float32), array(0.44712842, dtype=float32)]\n",
            "Batch 368 d_loss: 0.44702672958374023\n",
            "Batch 368 g_loss: [array(0.44702673, dtype=float32), array(0.44702673, dtype=float32), array(0.44702673, dtype=float32)]\n",
            "Batch 369 d_loss: 0.44691506028175354\n",
            "Batch 369 g_loss: [array(0.44691506, dtype=float32), array(0.44691506, dtype=float32), array(0.44691506, dtype=float32)]\n",
            "Batch 370 d_loss: 0.4468262791633606\n",
            "Batch 370 g_loss: [array(0.44682628, dtype=float32), array(0.44682628, dtype=float32), array(0.44682628, dtype=float32)]\n",
            "Batch 371 d_loss: 0.44672611355781555\n",
            "Batch 371 g_loss: [array(0.4467261, dtype=float32), array(0.4467261, dtype=float32), array(0.4467261, dtype=float32)]\n",
            "Batch 372 d_loss: 0.4466384947299957\n",
            "Batch 372 g_loss: [array(0.4466385, dtype=float32), array(0.4466385, dtype=float32), array(0.4466385, dtype=float32)]\n",
            "Batch 373 d_loss: 0.44658583402633667\n",
            "Batch 373 g_loss: [array(0.44658583, dtype=float32), array(0.44658583, dtype=float32), array(0.44658583, dtype=float32)]\n",
            "Batch 374 d_loss: 0.44650134444236755\n",
            "Batch 374 g_loss: [array(0.44650134, dtype=float32), array(0.44650134, dtype=float32), array(0.44650134, dtype=float32)]\n",
            "Batch 375 d_loss: 0.446397066116333\n",
            "Batch 375 g_loss: [array(0.44639707, dtype=float32), array(0.44639707, dtype=float32), array(0.44639707, dtype=float32)]\n",
            "Batch 376 d_loss: 0.44632264971733093\n",
            "Batch 376 g_loss: [array(0.44632265, dtype=float32), array(0.44632265, dtype=float32), array(0.44632265, dtype=float32)]\n",
            "Batch 377 d_loss: 0.4461803436279297\n",
            "Batch 377 g_loss: [array(0.44618034, dtype=float32), array(0.44618034, dtype=float32), array(0.44618034, dtype=float32)]\n",
            "Batch 378 d_loss: 0.44609692692756653\n",
            "Batch 378 g_loss: [array(0.44609693, dtype=float32), array(0.44609693, dtype=float32), array(0.44609693, dtype=float32)]\n"
          ]
        }
      ]
    }
  ]
}