{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtFaGkQe2uXS4qrksHe9uE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "317bb0f3f088474f8989cc2aa0b9d4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d34a7d48e9644eedbc9af5b2e5688bf9",
              "IPY_MODEL_b75ba3f350d949069894bbc59ad8cbbc",
              "IPY_MODEL_a71339296d7746ef845b2372139b7440"
            ],
            "layout": "IPY_MODEL_c82f52df500c4cd393b6234bc7bc6ca2"
          }
        },
        "d34a7d48e9644eedbc9af5b2e5688bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8e10af402d49f3ac721b3f5cd85bf1",
            "placeholder": "​",
            "style": "IPY_MODEL_61cbc9f0520f49699ac889134d765c1a",
            "value": "config.json: 100%"
          }
        },
        "b75ba3f350d949069894bbc59ad8cbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3c925bc5af44743af5bfbffbef51856",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fa968bccbb44f2f9b8f237cd0fcc561",
            "value": 570
          }
        },
        "a71339296d7746ef845b2372139b7440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2475789429c4053a86db38985c87168",
            "placeholder": "​",
            "style": "IPY_MODEL_d468b062b14847cd9c7554587a001afc",
            "value": " 570/570 [00:00&lt;00:00, 26.1kB/s]"
          }
        },
        "c82f52df500c4cd393b6234bc7bc6ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8e10af402d49f3ac721b3f5cd85bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61cbc9f0520f49699ac889134d765c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3c925bc5af44743af5bfbffbef51856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa968bccbb44f2f9b8f237cd0fcc561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2475789429c4053a86db38985c87168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d468b062b14847cd9c7554587a001afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "467d5989e5a249d0979ee060a1798f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc5ed3a4ea784aa7ac85bf008497dd17",
              "IPY_MODEL_6e3c7414f257419fbc2c53396715f2e0",
              "IPY_MODEL_4a89b331e3a14d638e0f7bd5f9157c5b"
            ],
            "layout": "IPY_MODEL_e771ffe07dca4823b46a9c10c7b11494"
          }
        },
        "bc5ed3a4ea784aa7ac85bf008497dd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfcce36308a04d10821d2842b7db104c",
            "placeholder": "​",
            "style": "IPY_MODEL_f570a045c0a44c92a2fa8524cff62c2d",
            "value": "model.safetensors: 100%"
          }
        },
        "6e3c7414f257419fbc2c53396715f2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd3e0cf640e24f0ab4fed3dbd9db6881",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4933574cf414e6185a97141e176259d",
            "value": 440449768
          }
        },
        "4a89b331e3a14d638e0f7bd5f9157c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b5e6e377bb41b69b0cccd3637b7673",
            "placeholder": "​",
            "style": "IPY_MODEL_5229451974c74b028a909c55dffc337d",
            "value": " 440M/440M [00:05&lt;00:00, 37.5MB/s]"
          }
        },
        "e771ffe07dca4823b46a9c10c7b11494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfcce36308a04d10821d2842b7db104c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f570a045c0a44c92a2fa8524cff62c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd3e0cf640e24f0ab4fed3dbd9db6881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4933574cf414e6185a97141e176259d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50b5e6e377bb41b69b0cccd3637b7673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5229451974c74b028a909c55dffc337d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a62670c55f21419a91fae267810f976b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ac1cf0f70bd4e339c6a19faa5bccd5d",
              "IPY_MODEL_58866b30f8a64185bbc46cdedcd629c7",
              "IPY_MODEL_42ba6f1913b243beb1b1bf61acadf9a0"
            ],
            "layout": "IPY_MODEL_ba55e1d9dfe44f4e9b722a66f1848179"
          }
        },
        "9ac1cf0f70bd4e339c6a19faa5bccd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc3c25ef0734ca49368642a935fa18b",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf0303335ec475ab2f743b8b0ca7b8a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "58866b30f8a64185bbc46cdedcd629c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c50c400a5cf4843bc6480f3c7c00ca5",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb5e9f4e157c4477942e751204ac82be",
            "value": 48
          }
        },
        "42ba6f1913b243beb1b1bf61acadf9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c054077560ad40ccbb7958fe1415d987",
            "placeholder": "​",
            "style": "IPY_MODEL_71e24a6bc941471fb76252bd012eab22",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.11kB/s]"
          }
        },
        "ba55e1d9dfe44f4e9b722a66f1848179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc3c25ef0734ca49368642a935fa18b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf0303335ec475ab2f743b8b0ca7b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c50c400a5cf4843bc6480f3c7c00ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb5e9f4e157c4477942e751204ac82be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c054077560ad40ccbb7958fe1415d987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e24a6bc941471fb76252bd012eab22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6710b832168a4729a7d50723e8a4d98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95d390840d5b489490dbd53c9f691f36",
              "IPY_MODEL_1920b78560254a308a2eaba25d3a6a91",
              "IPY_MODEL_d505fd7f05d0446faf6f025672db7b4d"
            ],
            "layout": "IPY_MODEL_50c89cc4c3c04c8c9edfd8be836572f5"
          }
        },
        "95d390840d5b489490dbd53c9f691f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f48b2f601e46e89cbb49ade41db2e0",
            "placeholder": "​",
            "style": "IPY_MODEL_2d28a6adf56943feadd8c9347a2f2d48",
            "value": "vocab.txt: 100%"
          }
        },
        "1920b78560254a308a2eaba25d3a6a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a10cd2557b4092a9399c6a5b18f9cf",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ae876108e414450ab46daeaa31ff80c",
            "value": 231508
          }
        },
        "d505fd7f05d0446faf6f025672db7b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45997e4ad10a4b1d81da86ad818d26a5",
            "placeholder": "​",
            "style": "IPY_MODEL_36dea56d44a84b1db916bb1b985e3e37",
            "value": " 232k/232k [00:00&lt;00:00, 4.32MB/s]"
          }
        },
        "50c89cc4c3c04c8c9edfd8be836572f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f48b2f601e46e89cbb49ade41db2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d28a6adf56943feadd8c9347a2f2d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07a10cd2557b4092a9399c6a5b18f9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ae876108e414450ab46daeaa31ff80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45997e4ad10a4b1d81da86ad818d26a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36dea56d44a84b1db916bb1b985e3e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b9176b846c842beac74fd609570a05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96cf37d99a584b989af8441c26fe2681",
              "IPY_MODEL_67520e6750d3490d9525cad56b8a4f6e",
              "IPY_MODEL_c3742f544a7f46548539e69c4e5d4751"
            ],
            "layout": "IPY_MODEL_4b93ed654eb44d4f822714864741555c"
          }
        },
        "96cf37d99a584b989af8441c26fe2681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f668b8fa6bfb4a1a9db5c35628ecd3dd",
            "placeholder": "​",
            "style": "IPY_MODEL_6c1b62ee4bc04962849d484e5f282230",
            "value": "tokenizer.json: 100%"
          }
        },
        "67520e6750d3490d9525cad56b8a4f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bccb7dbd73f423181e08b07493f7f24",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2a0518c34f14b939ef6b1748c36ef59",
            "value": 466062
          }
        },
        "c3742f544a7f46548539e69c4e5d4751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3343155d1094d869d65701e109ae2f2",
            "placeholder": "​",
            "style": "IPY_MODEL_40129302401f4cc689d2e54105a9af74",
            "value": " 466k/466k [00:00&lt;00:00, 3.45MB/s]"
          }
        },
        "4b93ed654eb44d4f822714864741555c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f668b8fa6bfb4a1a9db5c35628ecd3dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1b62ee4bc04962849d484e5f282230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bccb7dbd73f423181e08b07493f7f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a0518c34f14b939ef6b1748c36ef59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3343155d1094d869d65701e109ae2f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40129302401f4cc689d2e54105a9af74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/triantonugroho/Applied-Deep-Learning-Task/blob/main/MidtermTask/MidtermTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nama : Trianto Haryo Nugroho**\n",
        "\n",
        "**NPM : 2306288931**"
      ],
      "metadata": {
        "id": "EDXmVs_2Q9XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **In Google Colab, install the libraries necessary for running BERT models, including PyTorch and the Hugging Face Transformers library. Explain the roles of each library**\n",
        "\n",
        "  Install PyTorch and the Hugging Face Transformers library to work with pre-trained BERT models. Enable GPU acceleration in Google Colab to speed up sequence analysis tasks. Explain the use of these libraries for loading and running transformer models for tasks such as text classification or sequence analysis."
      ],
      "metadata": {
        "id": "_DM1kRy-RQ13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To work with pre-trained BERT models in Google Colab, you’ll need to install two main libraries: PyTorch and Hugging Face's Transformers. Here’s how to install them and what each library does:\n",
        "\n"
      ],
      "metadata": {
        "id": "TQVZkzjYUmbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Enable GPU Acceleration in Google Colab**\n",
        "\n",
        "* Go to Runtime > Change runtime type > Hardware accelerator and select GPU. This step leverages Google Colab’s T4 GPU runtime (which you already have enabled) to accelerate computations, making model training and inference faster.\n",
        "\n",
        "**Step 2: Install Required Libraries**\n",
        "\n",
        "Run the following commands in a Colab cell to install PyTorch and Transformers:\n",
        "\n"
      ],
      "metadata": {
        "id": "SVoC5eUHUp50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BYIwPA0Q49_",
        "outputId": "2bc4edc7-aa21-4e9e-ff27-76f6702329da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Library Overview**\n",
        "\n",
        "1. **PyTorch**\n",
        "\n",
        "* **Role:** PyTorch is a deep learning framework that provides a flexible,    efficient way to work with neural networks, particularly with tensors and autograd. It is the foundation upon which Transformers (and other neural network models) are built and trained.\n",
        "* **Why Needed:** BERT models are deep neural networks with millions of parameters, so using PyTorch enables efficient tensor computation and seamless integration with GPU resources in Colab. PyTorch provides the underlying infrastructure for processing data, calculating gradients, and optimizing model parameters during training.\n",
        "\n",
        "2. **Transformers (by Hugging Face)**\n",
        "\n",
        "* **Role:** This library provides tools to load, fine-tune, and deploy pre-trained transformer models, including BERT, for various natural language processing tasks.\n",
        "* **Why Needed:** Transformers makes it easy to use BERT and other models for tasks like text classification, sequence labeling, or sentiment analysis. The library also simplifies loading pre-trained weights, tokenizing input sequences, and managing configurations specific to transformer models, which are complex architectures.\n",
        "\n",
        "**Using the Libraries for Text Classification or Sequence Analysis**\n",
        "\n",
        "Once installed, you can use the Hugging Face Transformers library to load a BERT model for tasks like text classification by following these steps:\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5KeAWsDU-I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the Pre-trained Model:\n",
        "\n"
      ],
      "metadata": {
        "id": "IrVPhHLWVk63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "317bb0f3f088474f8989cc2aa0b9d4fe",
            "d34a7d48e9644eedbc9af5b2e5688bf9",
            "b75ba3f350d949069894bbc59ad8cbbc",
            "a71339296d7746ef845b2372139b7440",
            "c82f52df500c4cd393b6234bc7bc6ca2",
            "aa8e10af402d49f3ac721b3f5cd85bf1",
            "61cbc9f0520f49699ac889134d765c1a",
            "a3c925bc5af44743af5bfbffbef51856",
            "3fa968bccbb44f2f9b8f237cd0fcc561",
            "e2475789429c4053a86db38985c87168",
            "d468b062b14847cd9c7554587a001afc",
            "467d5989e5a249d0979ee060a1798f18",
            "bc5ed3a4ea784aa7ac85bf008497dd17",
            "6e3c7414f257419fbc2c53396715f2e0",
            "4a89b331e3a14d638e0f7bd5f9157c5b",
            "e771ffe07dca4823b46a9c10c7b11494",
            "cfcce36308a04d10821d2842b7db104c",
            "f570a045c0a44c92a2fa8524cff62c2d",
            "cd3e0cf640e24f0ab4fed3dbd9db6881",
            "d4933574cf414e6185a97141e176259d",
            "50b5e6e377bb41b69b0cccd3637b7673",
            "5229451974c74b028a909c55dffc337d",
            "a62670c55f21419a91fae267810f976b",
            "9ac1cf0f70bd4e339c6a19faa5bccd5d",
            "58866b30f8a64185bbc46cdedcd629c7",
            "42ba6f1913b243beb1b1bf61acadf9a0",
            "ba55e1d9dfe44f4e9b722a66f1848179",
            "afc3c25ef0734ca49368642a935fa18b",
            "7cf0303335ec475ab2f743b8b0ca7b8a",
            "0c50c400a5cf4843bc6480f3c7c00ca5",
            "bb5e9f4e157c4477942e751204ac82be",
            "c054077560ad40ccbb7958fe1415d987",
            "71e24a6bc941471fb76252bd012eab22",
            "6710b832168a4729a7d50723e8a4d98d",
            "95d390840d5b489490dbd53c9f691f36",
            "1920b78560254a308a2eaba25d3a6a91",
            "d505fd7f05d0446faf6f025672db7b4d",
            "50c89cc4c3c04c8c9edfd8be836572f5",
            "a7f48b2f601e46e89cbb49ade41db2e0",
            "2d28a6adf56943feadd8c9347a2f2d48",
            "07a10cd2557b4092a9399c6a5b18f9cf",
            "9ae876108e414450ab46daeaa31ff80c",
            "45997e4ad10a4b1d81da86ad818d26a5",
            "36dea56d44a84b1db916bb1b985e3e37",
            "5b9176b846c842beac74fd609570a05c",
            "96cf37d99a584b989af8441c26fe2681",
            "67520e6750d3490d9525cad56b8a4f6e",
            "c3742f544a7f46548539e69c4e5d4751",
            "4b93ed654eb44d4f822714864741555c",
            "f668b8fa6bfb4a1a9db5c35628ecd3dd",
            "6c1b62ee4bc04962849d484e5f282230",
            "2bccb7dbd73f423181e08b07493f7f24",
            "e2a0518c34f14b939ef6b1748c36ef59",
            "d3343155d1094d869d65701e109ae2f2",
            "40129302401f4cc689d2e54105a9af74"
          ]
        },
        "id": "2l8Xf8s2VqRk",
        "outputId": "ecfa5482-aa23-4c6d-d523-0e38c99cf194"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "317bb0f3f088474f8989cc2aa0b9d4fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "467d5989e5a249d0979ee060a1798f18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a62670c55f21419a91fae267810f976b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6710b832168a4729a7d50723e8a4d98d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b9176b846c842beac74fd609570a05c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preprocess Input Text: Tokenize input text sequences and convert them into tensor formats:\n",
        "\n"
      ],
      "metadata": {
        "id": "2Vb9PM4nVw6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"In recent years, there has been a growing interest in artificial intelligence and machine learning as these technologies continue to evolve rapidly, influencing various industries and reshaping the way we approach complex problems in fields like healthcare, finance, and education.\", return_tensors=\"pt\", truncation=True, max_length=512)\n"
      ],
      "metadata": {
        "id": "x57AoqVZVyQK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Make Predictions: Use the model to predict by passing the inputs to the model:\n",
        "\n"
      ],
      "metadata": {
        "id": "iJUtx-N9WDSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "print(logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pqAG0qMWG-a",
        "outputId": "81ba07c0-25aa-4c7d-b21f-ec02cfb1ab36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3428, 0.1984]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "# Get the predicted class (the one with the highest probability)\n",
        "predicted_class = torch.argmax(probabilities, dim=-1)\n",
        "\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probabilities)\n",
        "print(\"Predicted class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdhTqbPBW2-F",
        "outputId": "4c30b901-4f74-418f-e87a-8b7ef0f3230f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([[0.3428, 0.1984]], grad_fn=<AddmmBackward0>)\n",
            "Probabilities: tensor([[0.5360, 0.4640]], grad_fn=<SoftmaxBackward0>)\n",
            "Predicted class: tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Logits:** tensor([[-0.6297, -0.1298]]) — These are the raw scores output by the model for each class.\n",
        "* **Probabilities:** tensor([[0.3776, 0.6224]]) — After applying the softmax function, you get probabilities of about 37.8% for the first class and 62.2% for the second class.\n",
        "* **Predicted Class:** tensor([1]) — Since the probability for the second class (index 1) is higher, the model’s prediction is class 1.\n",
        "\n",
        "This means the model is more confident in the second class, with a probability of 62.2%. You can now interpret the model’s decision in terms of class probabilities and make more informed analyses or decisions based on these results.\n",
        "\n"
      ],
      "metadata": {
        "id": "qDwQRe_NXI_v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XOGrlmxcbqK-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this setup, you’re ready to run BERT-based tasks efficiently in Google Colab, utilizing the power of pre-trained transformers for NLP applications."
      ],
      "metadata": {
        "id": "QO6wxujoWPbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Load a pre-trained BERT model from the Hugging Face model hub and explain how BERT processes input data**\n",
        "\n",
        "  Load a pre-trained BERT model (e.g., bert-base-uncased) from the Hugging Face model hub. Explain how BERT tokenizes input data, uses self-attention mechanisms to process it, and outputs predictions based on sequence analysis. Describe how this process works for tasks like text classification or behavior prediction.\n"
      ],
      "metadata": {
        "id": "nohCTA-iXSLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load a pre-trained BERT model from the Hugging Face model hub, you can use bert-base-uncased, a popular version of BERT that’s case-insensitive. Here’s how to load the model and a breakdown of how BERT processes input data for tasks like text classification.\n",
        "\n",
        "**Step 1: Load the Pre-trained Model**\n",
        "\n",
        "First, install the necessary libraries if you haven’t already, then load the model and tokenizer.\n",
        "\n"
      ],
      "metadata": {
        "id": "2_lva60mXfXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDc8uvvIXaBM",
        "outputId": "34c7cc27-262c-46a3-c6eb-42098de56f5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How BERT Processes Input Data**\n",
        "\n",
        "**Tokenization**\n",
        "\n",
        "* **Subword Tokenization:** BERT uses a WordPiece tokenizer, which breaks down words into smaller subword units to handle unknown words and spelling variations better. For example, “unhappiness” might be split into “un,” “happi,” and “##ness.” This helps BERT manage diverse vocabulary while keeping the vocabulary size manageable.\n",
        "\n",
        "* **Adding Special Tokens:** BERT requires two special tokens for input: [CLS] (classification token) at the beginning and [SEP] (separator token) at the end of each input. [CLS] is particularly important in tasks like classification, as its final hidden state is used for the prediction.\n",
        "\n",
        "* **Token IDs and Attention Masks:** The tokenizer converts tokens into token IDs, which are numeric representations that BERT can process. It also creates an attention mask, where 1s indicate real tokens and 0s represent padding tokens.\n"
      ],
      "metadata": {
        "id": "XVwz5PbYXo5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input text\n",
        "input_text = \"In recent years, AI has transformed various industries.\"\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Print tokenized output\n",
        "print(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v5iV1FJXq_-",
        "outputId": "333f8a93-452c-4805-e7cf-d217ba6e9a8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1999, 3522, 2086, 1010, 9932, 2038, 8590, 2536, 6088, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self-Attention Mechanism**\n",
        "\n",
        "* **Attention Layers:** BERT has multiple self-attention layers that allow it to focus on different parts of the input sequence at each layer. This means each word (or token) in a sentence can “pay attention” to other words to understand context.\n",
        "* **Multi-Head Attention:** Each attention layer has multiple heads, so BERT can capture various aspects of context simultaneously. For instance, one head may focus on identifying subjects and verbs, while another may focus on the sentiment conveyed in the text.\n",
        "* **Encoding Context:** Through self-attention, BERT learns the context of each word relative to others. For example, in “bank,” BERT can distinguish if it’s a financial institution or the side of a river by considering nearby words in the sentence.\n",
        "\n",
        "**Output and Prediction**\n",
        "\n",
        "* **Hidden States and CLS Token:** BERT generates a hidden state vector for each token at each layer. For classification tasks, we primarily use the final hidden state of the [CLS] token, which contains information from the entire sequence.\n",
        "* **Final Layer for Prediction:** In text classification tasks, this [CLS] token’s vector goes through a fully connected layer that maps it to the output classes."
      ],
      "metadata": {
        "id": "XhSgy0UGYaHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run input through the model to get logits\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zm7QXz_ZEDn",
        "outputId": "5732d155-5a5e-42f1-a029-66d37cdee8ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4177,  0.0702]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output tensor([[0.0877, 0.0611]], grad_fn=<AddmmBackward0>) represents the logits for a binary classification task, showing raw prediction scores for each of the two classes. Here’s how to interpret it and convert it into meaningful probabilities:\n",
        "\n",
        "**Step 1: Interpret the Logits**\n",
        "\n",
        "* These logits (0.0877 and 0.0611) are unnormalized scores. The first value (0.0877) corresponds to the model’s score for the first class, and the second value (0.0611) is for the second class.\n",
        "* Generally, higher logits indicate a stronger confidence in a class, but these raw scores are not immediately interpretable as probabilities.\n",
        "\n",
        "**Step 2: Convert Logits to Probabilities**\n",
        "\n",
        "To make sense of these logits, you need to apply the softmax function, which converts them into a probability distribution across the classes:"
      ],
      "metadata": {
        "id": "5neU-1bpZ4P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Apply softmax to logits to get probabilities\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "print(\"Probabilities:\", probabilities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tMf9yuSZzFe",
        "outputId": "ff2da556-bd15-422d-8f58-3765bd2f3bdc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities: tensor([[0.3804, 0.6196]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The probabilities output tensor([[0.5067, 0.4933]]) indicates the following:\n",
        "\n",
        "* Class 0 Probability: 50.67%\n",
        "* Class 1 Probability: 49.33%\n",
        "\n",
        "In this case, the model is slightly more confident in Class 0, but the difference is very small. With a probability of 50.67% for Class 0 and 49.33% for Class 1, the model’s confidence is almost evenly split between the two classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "rQsu8pbyaJE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Prediction**\n",
        "\n",
        "To get the predicted class based on these probabilities:\n",
        "\n"
      ],
      "metadata": {
        "id": "A2bo76LBaOi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "print(\"Predicted class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VjQd202aXOE",
        "outputId": "818c20e6-0e9f-419b-9b0d-add9cbe1541e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation of Class 0**\n",
        "\n",
        "* **Context:** Depending on your specific application, Class 0 might represent a certain sentiment (e.g., positive), a behavior (e.g., \"yes\" or \"approve\"), or another categorical label.\n",
        "* **Confidence Level:** While Class 0 is the predicted class, the probabilities being close (around 50%) suggest that the model isn’t highly confident in its prediction. This could indicate that the input text is somewhat ambiguous or that the model needs more training data or fine-tuning for better differentiation between the two classes."
      ],
      "metadata": {
        "id": "4jjYBGRSax9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**\n",
        "\n",
        "In this case, because Class 0 has a slightly higher probability (50.67%), the model would predict Class 0. However, since the probabilities are close, the prediction isn’t very confident. This might suggest that the input is ambiguous, or the model doesn’t strongly favor one class over the other for this particular input.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GeRZcH6xadr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Steps**\n",
        "\n",
        "* **Evaluate Model Performance:** If you have a labeled dataset, you can evaluate how well the model performs across multiple samples.\n",
        "* **Further Fine-Tuning:** If this is a classification task with specific classes, consider fine-tuning the model on your dataset to improve its predictive accuracy.\n",
        "* **Review Ambiguous Cases:** Analyze inputs where the model’s confidence is low (i.e., probabilities close to each other) to better understand the model's limitations and improve its training data."
      ],
      "metadata": {
        "id": "4hvQDmRMbJDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Prepare input data for BERT by tokenizing and converting it into a format compatible with the model**\n",
        "\n",
        "  Use the BERT tokenizer to convert the input data into tokens, then format the tokens into tensors that can be processed by the BERT model. Explain the significance of padding and attention masks, and how BERT's attention mechanism works when processing sequences of data.\n"
      ],
      "metadata": {
        "id": "_GYSigC1ah3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare input data for BERT, you need to follow a series of steps that involve tokenization and formatting the tokens into tensors compatible with the model. Here's how to do this, along with an explanation of padding, attention masks, and the attention mechanism in BERT.\n",
        "\n"
      ],
      "metadata": {
        "id": "3lG2AWh4Zp11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Tokenization**\n",
        "\n",
        "Using the BERT tokenizer, you convert your input text into tokens, which are then mapped to token IDs.\n",
        "\n"
      ],
      "metadata": {
        "id": "-_CByK-HconT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Example input text\n",
        "input_text = \"In recent years, AI has transformed various industries.\"\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Print the tokenized output\n",
        "print(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc321_rKcs0W",
        "outputId": "17b7a093-8be4-4310-f9a5-71715724ac4d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1999, 3522, 2086, 1010, 9932, 2038, 8590, 2536, 6088, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output of Tokenization**\n",
        "\n",
        "The inputs dictionary typically contains:\n",
        "* input_ids: Numeric IDs for each token in the text.\n",
        "* attention_mask: A mask indicating which tokens are padding.\n",
        "\n",
        "**Step 2: Formatting Tokens into Tensors**\n",
        "\n",
        "The token IDs and attention masks are already formatted into tensors by using return_tensors=\"pt\" (PyTorch). This makes them ready to be fed into the BERT model.\n",
        "\n",
        "**Significance of Padding**\n",
        "\n",
        "* **Padding:** In NLP, sentences often have different lengths. BERT requires inputs of a fixed length, so shorter sentences are padded to match the longest sentence in the batch.\n",
        "* **Purpose:** Padding tokens are usually filled with a special token ID (e.g., 0) and are ignored by the model during processing. Padding ensures that all input sequences have the same length without affecting the actual data.\n",
        "\n",
        "**Example of Padding**\n",
        "\n",
        "If you have two sentences:\n",
        "\n",
        "1. \"Hello\"\n",
        "2. \"Hello, how are you?\"\n",
        "\n",
        "After padding, they might look like:\n",
        "\n",
        "* \"Hello [PAD] [PAD]\"\n",
        "* \"Hello, how are you?\"\n",
        "\n",
        "**Attention Masks**\n",
        "\n",
        "* **Attention Masks:** These are binary tensors indicating which tokens are real input (1) and which are padding (0). They allow the model to focus on relevant tokens while ignoring padding.\n",
        "* **Significance:** When the model processes the sequence, the attention mechanism uses these masks to differentiate between real tokens and padding. This helps ensure that padding tokens do not influence the model's attention calculations.\n",
        "\n",
        "**BERT's Attention Mechanism**\n",
        "\n",
        "* **Self-Attention:** BERT uses a self-attention mechanism that allows each token in the sequence to attend to every other token. This means that for each token, the model learns to weigh the relevance of all other tokens in the context of the sequence.\n",
        "* **Multi-Head Attention:** BERT employs multi-head attention, which allows the model to jointly attend to information from different representation subspaces at different positions. This enables the model to capture various relationships and contexts within the input data.\n",
        "\n",
        "**Example of Attention Mechanism**\n",
        "When processing the sentence \"AI has transformed various industries\":\n",
        "\n",
        "* Each token, like \"AI\", will attend to all other tokens (e.g., \"has\", \"transformed\", \"various\", \"industries\") to understand their contextual relationship.\n",
        "* For instance, it might determine that \"AI\" and \"transformed\" are closely related, while \"various\" is less relevant.\n",
        "\n",
        "**Feeding Data into the Model**\n",
        "\n",
        "Finally, once the input data is tokenized and formatted, you can feed it into the BERT model:\n",
        "\n"
      ],
      "metadata": {
        "id": "J-Zteh_WcyGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load a pre-trained BERT model for classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Pass the tokenized inputs through the model\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "\n",
        "# Print logits\n",
        "print(logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afn1mNnvd0EA",
        "outputId": "5e5cf09c-4fdb-4cfd-b636-6147f4bd6348"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0298,  0.3111]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "By following these steps, you effectively prepare input data for BERT, ensuring that the model can accurately process and analyze your text data. The importance of padding and attention masks cannot be overstated, as they play crucial roles in how BERT understands and interprets sequences."
      ],
      "metadata": {
        "id": "am4T2-Byd6xA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Use BERT for sequence classification or behavior prediction based on input data**\n",
        "\n",
        "  Feed the preprocessed input sequence into the BERT model for classification or analysis. If analyzing object movements (from YOLO), explain how the sequential data representing movements can be processed by BERT to predict actions such as walking, running, or stationary.\n"
      ],
      "metadata": {
        "id": "qyM-N_0pd-V1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using BERT for sequence classification involves feeding preprocessed input sequences into the model to classify or predict specific outcomes. This can also extend to tasks like predicting behaviors based on sequential data, such as movements detected from a YOLO (You Only Look Once) object detection model. Below, I’ll explain how to use BERT for sequence classification and how it can be adapted for analyzing sequential movement data.\n",
        "\n",
        "**Step 1: Using BERT for Sequence Classification**\n",
        "\n",
        "Once you have your input text tokenized and formatted as tensors, you can feed it into a BERT model for classification tasks. Here’s a brief overview of the process:\n",
        "\n",
        "**Example: Sequence Classification**\n"
      ],
      "metadata": {
        "id": "OqeKOXA6eOad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'inputs' contains the tokenized input data\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "\n",
        "# Convert logits to probabilities\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "# Determine the predicted class\n",
        "predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "print(\"Predicted class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUzkq8HbeUZC",
        "outputId": "f82e43d2-cdce-4b96-bb4f-8d3651a0ec90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example:\n",
        "\n",
        "* logits: The raw scores for each class.\n",
        "* probabilities: The softmax probabilities for class interpretation.\n",
        "* predicted_class: The class with the highest probability.\n",
        "\n",
        "**Step 2: Analyzing Object Movements for Behavior Prediction**\n",
        "\n",
        "When dealing with sequential data such as object movements, the approach can be slightly different but can still leverage the architecture of BERT by adapting how you represent your data.\n",
        "\n",
        "**Object Movement Data Representation**\n",
        "\n",
        "1. **Sequential Input:** Movement data from a YOLO model usually comes in the form of bounding box coordinates over time, along with class labels for the detected objects (e.g., person, car).\n",
        "For example, each frame might provide information like: {\"frame\": 1, \"class\": \"person\", \"bbox\": [x1, y1, x2, y2], \"velocity\": v}.\n",
        "2. **Transforming Data for BERT:** You can represent this sequential data in a format suitable for BERT:\n",
        "* **Concatenation of Movement Features:** Combine movement features into a sentence-like format. For instance, you might convert {\"frame\": 1, \"class\": \"person\", \"velocity\": v} into a sentence: \"Frame 1: Person is moving with velocity v\".\n",
        "* **Sequence of Actions:** Create a sequence of sentences that describe the actions over time, which can then be tokenized similarly to textual data.\n",
        "\n",
        "**Example Input for Movement Data**\n",
        "\n",
        "Assuming we have multiple frames for a single movement:"
      ],
      "metadata": {
        "id": "IeLUQe60eZiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movement_sequences = [\n",
        "    \"Frame 1: Person is walking with velocity 1.5 m/s.\",\n",
        "    \"Frame 2: Person is walking with velocity 1.6 m/s.\",\n",
        "    \"Frame 3: Person is running with velocity 3.0 m/s.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "c1bytk4he3IX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Tokenizing and Feeding into BERT**\n",
        "\n",
        "You would then tokenize this sequence using the BERT tokenizer:\n",
        "\n"
      ],
      "metadata": {
        "id": "cTVWJD9mfEXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the entire sequence of movements\n",
        "inputs = tokenizer(movement_sequences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Feed the inputs to the BERT model\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n"
      ],
      "metadata": {
        "id": "4uaDyAoJfIzb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Predicting Actions**\n",
        "\n",
        "Finally, you can interpret the logits to classify the sequence of movements into distinct behaviors (e.g., walking, running, stationary):\n",
        "\n"
      ],
      "metadata": {
        "id": "i-whBpwmfMOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Assuming you have already obtained logits from the model\n",
        "# Example logits for three classes (walking, running, stationary)\n",
        "logits = torch.tensor([[0.5, 1.0, -0.5], [1.5, 0.5, -1.0], [0.0, 0.0, 0.0]])\n",
        "\n",
        "# Step 1: Apply softmax to convert logits to probabilities\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "# Step 2: Print the logits and probabilities for interpretation\n",
        "print(\"Logits:\\n\", logits)\n",
        "print(\"Probabilities:\\n\", probabilities)\n",
        "\n",
        "# Step 3: Identify the predicted class(es)\n",
        "predicted_classes = torch.argmax(probabilities, dim=-1)\n",
        "print(\"Predicted classes:\", predicted_classes)\n",
        "\n",
        "# Step 4: Convert to human-readable behavior names\n",
        "behavior_mapping = {0: \"walking\", 1: \"running\", 2: \"stationary\"}  # Example mapping\n",
        "predicted_behaviors = [behavior_mapping[int(predicted_class)] for predicted_class in predicted_classes]\n",
        "\n",
        "print(\"Predicted behaviors for each input:\", predicted_behaviors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xws17GKfPet",
        "outputId": "89410349-4618-4a7b-c5c3-1da8b37041cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits:\n",
            " tensor([[ 0.5000,  1.0000, -0.5000],\n",
            "        [ 1.5000,  0.5000, -1.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000]])\n",
            "Probabilities:\n",
            " tensor([[0.3315, 0.5465, 0.1220],\n",
            "        [0.6897, 0.2537, 0.0566],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "Predicted classes: tensor([1, 0, 0])\n",
            "Predicted behaviors for each input: ['running', 'walking', 'walking']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your output provides a clear and insightful interpretation of the logits, probabilities, predicted classes, and predicted behaviors for the movement classification task. Here's a breakdown of what each part of the output indicates:\n",
        "\n",
        "**Breakdown of Results**\n",
        "1. **Logits:**\n",
        "\n",
        "tensor([[ 0.5000,  1.0000, -0.5000],\n",
        "        [ 1.5000,  0.5000, -1.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000]])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rVtDnhVGhh19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor([[ 0.5000,  1.0000, -0.5000],\n",
        "        [ 1.5000,  0.5000, -1.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000]])"
      ],
      "metadata": {
        "id": "1W3fiqtDqWPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Each row corresponds to the raw output scores for a sequence of movements, with three values representing the scores for walking, running, and stationary, respectively.\n",
        "* The logits can be interpreted as follows:\n",
        "  * First Input: Scores suggest a preference for running (1.0000) over walking (0.5000) and stationary (-0.5000).\n",
        "  * Second Input: Strong preference for running (1.5000) compared to walking (0.5000) and stationary (-1.0000).\n",
        "  * Third Input: The scores are neutral (0.0000 for all classes), indicating uncertainty or lack of clear classification.\n"
      ],
      "metadata": {
        "id": "1GhqjBL6hvah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Probabilities:**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WYq8XpTqh9Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor([[0.3315, 0.5465, 0.1220],\n",
        "        [0.6897, 0.2537, 0.0566],\n",
        "        [0.3333, 0.3333, 0.3333]])"
      ],
      "metadata": {
        "id": "qdHUPHvNqauc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* These values represent the likelihood of each class after applying the softmax function to the logits.\n",
        "\n",
        "* Interpretation:\n",
        "\n",
        " * First Input: 33.15% for walking, 54.65% for running (indicating a strong prediction), and 12.20% for stationary.\n",
        " * Second Input: 68.97% for running, showing the model's confidence, 25.37% for walking, and only 5.66% for stationary.\n",
        " * Third Input: The probabilities are evenly distributed among the three classes (33.33% each), indicating ambiguity and no clear preference.\n"
      ],
      "metadata": {
        "id": "vaJft8aoiBji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Predicted Classes:**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qBCmVqL3iUMm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uqcmrByaqgvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor([1, 0, 0])"
      ],
      "metadata": {
        "id": "0EewTjueqc-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These indices represent the predicted class for each input based on the maximum probability:\n",
        "* Input 1: Class 1 (Running)\n",
        "* Input 2: Class 0 (Walking)\n",
        "* Input 3: Class 0 (Walking)\n"
      ],
      "metadata": {
        "id": "fQPVn8VQiZEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Predicted Behaviors:**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FsaP7aH0ieWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Predicted behaviors for each input: ['running', 'walking', 'walking']\n"
      ],
      "metadata": {
        "id": "kGTiE5xXqhpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This human-readable format allows for easy interpretation of the predicted classes:\n",
        " * Input 1 is classified as Running.\n",
        " * Inputs 2 and 3 are classified as Walking.\n"
      ],
      "metadata": {
        "id": "a7yACMI6ikoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "The model effectively identifies and distinguishes between the three behaviors based on the sequences provided.\n",
        "\n",
        "* **Behavior Prediction:** The predictions indicate that the model is more confident about distinguishing running from walking in the first two inputs, while the third input lacks clarity, which may require further analysis or additional training data to improve predictions.\n",
        "\n",
        "* **Next Steps:**\n",
        "\n",
        " * **Evaluate Performance:** If you have labeled data, compare these predictions against the true labels to assess the model’s accuracy.\n",
        " * **Analyze Ambiguous Cases:** Investigate the input data for cases where the model outputs evenly distributed probabilities to understand the features leading to such predictions.\n",
        " * **Fine-Tuning:** Consider further training or fine-tuning the model if the results aren’t satisfactory, especially focusing on the ambiguous predictions.\n"
      ],
      "metadata": {
        "id": "NBtaTiMJisPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Fine-tune the BERT model for custom sequence analysis tasks in Google Colab\n",
        "Discuss the process of fine-tuning BERT on a custom dataset for a specific sequence analysis task.**\n",
        "\n",
        "  Provide guidance on setting up the training loop, adjusting hyperparameters, and using pre-trained weights to reduce training time. Fine-tuning allows BERT to be adapted to specific tasks beyond general-purpose language understanding.\n"
      ],
      "metadata": {
        "id": "E6dYUzQ3i8e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning a pre-trained BERT model for custom sequence analysis tasks in Google Colab involves several key steps, including setting up the environment, preparing your dataset, configuring the training loop, and adjusting hyperparameters. Below is a detailed guide on how to accomplish this effectively.\n",
        "\n",
        "**1. Setting Up the Environment**\n",
        "\n",
        "First, ensure you have the necessary libraries installed. In Google Colab, you can install PyTorch and the Hugging Face Transformers library using the following code:\n",
        "\n"
      ],
      "metadata": {
        "id": "h7jTBEsfjc4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "4Gc57Z6cqkOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lzrucj2r8sk",
        "outputId": "f36865f3-6a34-48ef-dd63-858c70ea087f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Creating a synthetic labeled dataset for sequence analysis tasks**\n",
        "\n",
        "  I can be a useful way to simulate real-world scenarios when actual data is limited. Below is a step-by-step guide on how to generate a synthetic dataset, specifically for a binary classification task, using Python.\n",
        "\n"
      ],
      "metadata": {
        "id": "YBVyfJS0lFDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Import Necessary Libraries**\n",
        "\n",
        "First, ensure you have the necessary libraries for data manipulation. You can use libraries like pandas and numpy.\n",
        "\n"
      ],
      "metadata": {
        "id": "CJZDzGP-lG1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "metadata": {
        "id": "5ICEdx7gqmyo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Define Parameters**\n",
        "\n",
        "Decide on the parameters for your synthetic dataset, such as the number of samples and the structure of your labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "f_FmOC8nlOc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of samples\n",
        "num_samples = 1000\n",
        "\n",
        "# Define possible labels (e.g., positive and negative sentiments)\n",
        "labels = ['positive', 'negative']\n"
      ],
      "metadata": {
        "id": "MZ9xBT_Fqobp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Generate Synthetic Text Data**\n",
        "\n",
        "For this example, we'll generate simple sentences that are either positive or negative based on their labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "iHfVa-3Vla5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate synthetic text data\n",
        "def generate_synthetic_data(num_samples):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        if random.choice(labels) == 'positive':\n",
        "            data.append(f\"This is a great product! I'm very happy with it.\")\n",
        "        else:\n",
        "            data.append(f\"This is a terrible product! I'm very disappointed.\")\n",
        "    return data\n",
        "\n",
        "# Generate the dataset\n",
        "synthetic_texts = generate_synthetic_data(num_samples)\n"
      ],
      "metadata": {
        "id": "RCbVpQgTqrJP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Create the DataFrame**\n",
        "\n",
        "Now, create a DataFrame to hold your synthetic dataset, including both the text and the corresponding labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "71lK9tcxlgGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame\n",
        "df_synthetic = pd.DataFrame({\n",
        "    'text': synthetic_texts,\n",
        "    'label': [random.choice(labels) for _ in range(num_samples)]  # Randomly assign labels\n",
        "})\n",
        "\n",
        "# Ensure that labels are consistent with the text (optional, for more realism)\n",
        "# This approach ensures the label matches the text sentiment\n",
        "df_synthetic['label'] = df_synthetic['text'].apply(\n",
        "    lambda x: 'positive' if 'great' in x or 'happy' in x else 'negative'\n",
        ")\n",
        "\n",
        "# Show the first few rows of the synthetic dataset\n",
        "print(df_synthetic.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tXxxo9AlmRW",
        "outputId": "517ee3fc-ac28-4312-9d6b-03eee49bed37"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text     label\n",
            "0  This is a terrible product! I'm very disappoin...  negative\n",
            "1  This is a terrible product! I'm very disappoin...  negative\n",
            "2  This is a terrible product! I'm very disappoin...  negative\n",
            "3   This is a great product! I'm very happy with it.  positive\n",
            "4   This is a great product! I'm very happy with it.  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Saving the Dataset**\n",
        "\n",
        "You can save the synthetic dataset to a CSV file for later use.\n",
        "\n"
      ],
      "metadata": {
        "id": "BzTprA9Clr_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to a CSV file\n",
        "df_synthetic.to_csv('synthetic_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "40fMFrAwluJE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of the Code**\n",
        "\n",
        "* **Random Data Generation:** The generate_synthetic_data function creates text samples based on predefined patterns for positive and negative sentiments.\n",
        "* **Label Consistency:** We ensure the labels correspond to the generated text sentiment by checking for specific keywords.\n",
        "* **DataFrame Creation:** The synthetic texts and labels are stored in a Pandas DataFrame for easy manipulation and analysis.\n",
        "* **Saving to CSV:** The final DataFrame is saved to a CSV file for future use in training or testing machine learning models."
      ],
      "metadata": {
        "id": "E0ct1Igvl5i_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Preparing Your Dataset**\n",
        "\n",
        "  You need a labeled dataset for your specific sequence analysis task (e.g., text classification, sentiment analysis). Ensure your dataset is in a format compatible with BERT, typically as a CSV or a DataFrame with at least two columns: one for the text input and one for the labels.\n",
        "\n",
        "  Example Data Preparation\n",
        "  Assuming you have a CSV file named synthetic_dataset.csv:\n",
        "\n"
      ],
      "metadata": {
        "id": "hDoxyx2cmD9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('synthetic_dataset.csv')\n",
        "\n",
        "# Example structure:\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OteRBNwXmjiZ",
        "outputId": "83a4c603-6142-4fd7-fe37-f581e468dc2d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  This is a terrible product! I'm very disappoin...  negative\n",
              "1  This is a terrible product! I'm very disappoin...  negative\n",
              "2  This is a terrible product! I'm very disappoin...  negative\n",
              "3   This is a great product! I'm very happy with it.  positive\n",
              "4   This is a great product! I'm very happy with it.  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e8b071d-33f7-4d85-98ad-9f1ec8282282\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a terrible product! I'm very disappoin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a terrible product! I'm very disappoin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a terrible product! I'm very disappoin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is a great product! I'm very happy with it.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is a great product! I'm very happy with it.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e8b071d-33f7-4d85-98ad-9f1ec8282282')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e8b071d-33f7-4d85-98ad-9f1ec8282282 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e8b071d-33f7-4d85-98ad-9f1ec8282282');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-786bbd3c-3963-48cd-bfd4-4cc89a1dac9c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-786bbd3c-3963-48cd-bfd4-4cc89a1dac9c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-786bbd3c-3963-48cd-bfd4-4cc89a1dac9c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"This is a great product! I'm very happy with it.\",\n          \"This is a terrible product! I'm very disappointed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Tokenization**\n",
        "\n",
        "  Use the BERT tokenizer to prepare your text data. This step converts raw text into tokens that BERT can process.\n",
        "\n"
      ],
      "metadata": {
        "id": "jqnQh-ecmvb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Apply tokenization\n",
        "tokens = tokenize_data(df['text'].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erokQCKam0dl",
        "outputId": "aeaa2894-dcde-4278-a221-206b3e099581"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Setting Up the Model**\n",
        "\n",
        "  Load a pre-trained BERT model for sequence classification. You can use the BertForSequenceClassification class from the Transformers library.\n",
        "\n"
      ],
      "metadata": {
        "id": "olkLiDtMm6TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.to(device)  # Move model to the GPU\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpIDMrknsJa0",
        "outputId": "14d969f8-c515-4c62-b074-e4e7ccb75176"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Your Dataset and DataLoader: Ensure your dataset returns the inputs and labels in the correct format. For instance:\n",
        "\n"
      ],
      "metadata": {
        "id": "2boNtrHKsYQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and return the inputs and labels\n",
        "        encoding = tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
        "        return {key: val.squeeze(0) for key, val in encoding.items()}, torch.tensor(self.labels[idx])\n",
        "\n",
        "# Example synthetic data\n",
        "texts = [\"This is a positive example.\", \"This is a negative example.\"]\n",
        "labels = [1, 0]  # Binary labels\n",
        "\n",
        "dataset = CustomDataset(texts, labels)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "5TG6mbb2sb0B"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Preparing for Training**\n",
        "\n",
        "  Set up the training loop and define the optimizer, loss function, and metrics for evaluation.\n",
        "\n"
      ],
      "metadata": {
        "id": "4bjLw565nK1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "        # Move inputs and labels to the appropriate device\n",
        "        inputs = {key: val.to(device) for key, val in batch[0].items()}\n",
        "        labels = batch[1].to(device)  # Move labels to the correct device\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} completed with loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Zyd38hnOz_",
        "outputId": "22d0e050-732e-4ee5-f7c8-9b44f0c9a231"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 completed with loss: 0.07344101369380951\n",
            "Epoch 2/5 completed with loss: 0.09307775646448135\n",
            "Epoch 3/5 completed with loss: 0.06925931572914124\n",
            "Epoch 4/5 completed with loss: 0.062434881925582886\n",
            "Epoch 5/5 completed with loss: 0.08364790678024292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Adjusting Hyperparameters**\n",
        "\n",
        "You may need to experiment with hyperparameters such as:\n",
        "\n",
        "Learning Rate: A common starting point is 2e-5 to 5e-5.\n",
        "Batch Size: Depending on your GPU memory, typically between 8 and 32.\n",
        "Epochs: Start with 3 to 5 and monitor performance."
      ],
      "metadata": {
        "id": "AUDTMVfdtXdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjusting hyperparameters is a crucial step in fine-tuning models like BERT to achieve optimal performance for your specific tasks. Here’s a more detailed look at the hyperparameters you might want to experiment with, along with guidance on how to implement those adjustments in your training process.\n",
        "\n"
      ],
      "metadata": {
        "id": "jYWMXCupuses"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Hyperparameters to Adjust**\n",
        "\n",
        "1. **Learning Rate:**\n",
        "\n",
        "* **Description:** The learning rate determines how much to change the model weights during training. A learning rate that is too high can cause the model to converge too quickly to a suboptimal solution, while a learning rate that is too low can result in a long training time or getting stuck.\n",
        "* **Typical Values:** Start with values between 2e-5 and 5e-5. You might also want to try 1e-4 or 5e-6, depending on the stability of your training.\n",
        "Implementation: Adjust the learning rate in your optimizer setup.\n"
      ],
      "metadata": {
        "id": "FGr4WQesutlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5)  # Adjust the learning rate here\n"
      ],
      "metadata": {
        "id": "qcp6e9Deu9iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Batch Size:**\n",
        "\n",
        "* **Description:** The batch size is the number of training examples utilized in one iteration. A larger batch size may lead to more stable gradients but requires more memory. Smaller batch sizes can provide a regularizing effect and help the model generalize better.\n",
        "\n",
        "* **Typical Values:** Experiment with batch sizes of 8, 16, and 32. The ideal size depends on your GPU memory capacity; you might need to adjust it based on out-of-memory errors.\n",
        "Implementation: Change the batch_size parameter in your DataLoader.\n"
      ],
      "metadata": {
        "id": "F3OWLXXmu-On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)  # Adjust the batch size here\n"
      ],
      "metadata": {
        "id": "BrMNC5OBvIhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Number of Epochs:**\n",
        "\n",
        "Description: The number of epochs is how many times the learning algorithm will work through the entire training dataset. Monitor the training and validation performance to avoid overfitting.\n",
        "Typical Values: Starting with 3 to 5 epochs is common; you can adjust based on the model's performance on the validation set.\n",
        "Implementation: Change the loop that runs your training process.\n"
      ],
      "metadata": {
        "id": "xFyJsS7AvJHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5  # Adjust the number of epochs here\n"
      ],
      "metadata": {
        "id": "5p8JsqgivS6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 2e-5\n",
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "\n",
        "# Create DataLoader with adjusted batch size\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize the optimizer with the specified learning rate\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "        # Move inputs and labels to the appropriate device\n",
        "        inputs = {key: val.to(device) for key, val in batch[0].items()}\n",
        "        labels = batch[1].to(device)  # Move labels to the correct device\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} completed with loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ThvvJH2tj32",
        "outputId": "67b49955-8821-46ac-e1c3-54127b5c8f3d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 completed with loss: 0.04969153553247452\n",
            "Epoch 2/5 completed with loss: 0.053664106875658035\n",
            "Epoch 3/5 completed with loss: 0.030963215976953506\n",
            "Epoch 4/5 completed with loss: 0.044982269406318665\n",
            "Epoch 5/5 completed with loss: 0.030314911156892776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monitoring Performance**\n",
        "\n",
        "To effectively monitor the performance of your adjustments:\n",
        "\n",
        "* **Validation Set:** Keep a separate validation set and evaluate the model's performance after each epoch.\n",
        "* **Learning Rate Scheduler:** Consider using a learning rate scheduler (like get_linear_schedule_with_warmup from Hugging Face) to adjust the learning rate dynamically during training.\n",
        "* **Early Stopping:** Implement early stopping based on validation loss to prevent overfitting.\n"
      ],
      "metadata": {
        "id": "dYEzvW22vyxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monitoring the performance of your model during training is crucial for ensuring that it learns effectively and avoids overfitting. Here’s how to implement these monitoring techniques in your BERT fine-tuning process:\n",
        "\n"
      ],
      "metadata": {
        "id": "BR7b90k3wKDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Validation Set**\n",
        "\n",
        "To monitor how well your model is generalizing, always keep a separate validation set that is not used during training. After each epoch, evaluate the model on this validation set and keep track of the validation loss and metrics (like accuracy).\n",
        "\n",
        "Implementation Example:\n",
        "\n"
      ],
      "metadata": {
        "id": "T1MDdXYJwLYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TXhaq2ZLwGS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G_Zlv7MivTe4"
      }
    }
  ]
}