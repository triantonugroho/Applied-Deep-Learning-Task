{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/triantonugroho/Applied-Deep-Learning-Task/blob/TaskWeek4/TaskWeek4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nama : Trianto Haryo Nugroho**\n",
        "\n",
        "**NPM : 2306288931**"
      ],
      "metadata": {
        "id": "YSY7A0YS7hi0"
      },
      "id": "YSY7A0YS7hi0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Modern Convolutional Neural Networks** #\n"
      ],
      "metadata": {
        "id": "Ff-vrABnwxu0"
      },
      "id": "Ff-vrABnwxu0"
    },
    {
      "cell_type": "markdown",
      "id": "c522d716",
      "metadata": {
        "id": "c522d716"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "270c2008",
      "metadata": {
        "id": "270c2008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b9aadb4-b3ad-43f1-9ade-32b9b2839b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
            "Collecting jupyter==1.0.0 (from d2l)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.23.5 (from d2l)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==3.7.2 (from d2l)\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from d2l)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests==2.31.0 (from d2l)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas==2.0.3 (from d2l)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.10.1 (from d2l)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m906.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l)\n",
            "  Downloading qtconsole-5.6.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (10.4.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.18.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.3.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.1.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (4.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.2.2)\n",
            "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: requests, qtpy, pyparsing, numpy, matplotlib-inline, jedi, scipy, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.4\n",
            "    Uninstalling pyparsing-3.1.4:\n",
            "      Successfully uninstalled pyparsing-3.1.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.18.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.1 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.6.0 qtpy-2.4.1 requests-2.31.0 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              },
              "id": "fbe8c7dce50c4704acfe36ec853195ee"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.0 pandas==2.1.4 requests==2.32.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN7T2Vgspw8n",
        "outputId": "b8f25ccc-0b75-4807-ae06-0e6584bb40e5"
      },
      "id": "MN7T2Vgspw8n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.0\n",
            "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.1.4\n",
            "  Using cached pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting requests==2.32.3\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.4) (1.16.0)\n",
            "Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Installing collected packages: requests, numpy, pandas\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "d2l 1.0.3 requires numpy==1.23.5, but you have numpy 1.26.0 which is incompatible.\n",
            "d2l 1.0.3 requires pandas==2.0.3, but you have pandas 2.1.4 which is incompatible.\n",
            "d2l 1.0.3 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0 pandas-2.1.4 requests-2.32.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations bigframes chex jax jaxlib mizani pandas-stubs plotnine xarray\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-cW3R06p3IX",
        "outputId": "4fe81687-ddfe-4e1d-8031-67e9d0ce3cbf"
      },
      "id": "6-cW3R06p3IX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.15)\n",
            "Requirement already satisfied: bigframes in /usr/local/lib/python3.10/dist-packages (1.18.0)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.10/dist-packages (0.1.86)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: mizani in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: pandas-stubs in /usr/local/lib/python3.10/dist-packages (2.1.4.231227)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.10/dist-packages (0.13.6)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2024.9.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.0)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore>=0.0.15 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.16)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: cloudpickle>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2023.3.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2024.6.1)\n",
            "Requirement already satisfied: gcsfs>=2023.3.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2024.6.1)\n",
            "Requirement already satisfied: geopandas>=0.12.2 in /usr/local/lib/python3.10/dist-packages (from bigframes) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-bigtable>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.26.0)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.4 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.23.1)\n",
            "Requirement already satisfied: google-cloud-bigquery>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-functions>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (1.16.5)\n",
            "Requirement already satisfied: google-cloud-bigquery-connection>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (1.15.5)\n",
            "Requirement already satisfied: google-cloud-iam>=2.12.1 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-resource-manager>=1.10.3 in /usr/local/lib/python3.10/dist-packages (from bigframes) (1.12.5)\n",
            "Requirement already satisfied: google-cloud-storage>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.8.0)\n",
            "Requirement already satisfied: ibis-framework<=9.2.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (9.2.0)\n",
            "Requirement already satisfied: jellyfish>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from bigframes) (1.1.0)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.1.4)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from bigframes) (14.0.2)\n",
            "Requirement already satisfied: pydata-google-auth>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from bigframes) (1.8.2)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from bigframes) (1.5.2)\n",
            "Requirement already satisfied: sqlalchemy<3.0dev,>=1.4 in /usr/local/lib/python3.10/dist-packages (from bigframes) (2.0.35)\n",
            "Requirement already satisfied: sqlglot<25.2,>=23.6.3 in /usr/local/lib/python3.10/dist-packages (from bigframes) (25.1.0)\n",
            "Requirement already satisfied: tabulate>=0.9 in /usr/local/lib/python3.10/dist-packages (from bigframes) (0.9.0)\n",
            "Requirement already satisfied: ipywidgets>=7.7.1 in /usr/local/lib/python3.10/dist-packages (from bigframes) (7.7.1)\n",
            "Requirement already satisfied: humanize>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from bigframes) (4.10.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from bigframes) (3.7.2)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex) (4.12.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.10/dist-packages (from pandas-stubs) (2024.2.0.20240913)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from plotnine) (0.14.3)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from xarray) (24.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2023.3.0->bigframes) (3.10.5)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2023.3.0->bigframes) (4.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2023.3.0->bigframes) (1.2.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12.2->bigframes) (0.9.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12.2->bigframes) (3.6.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12.2->bigframes) (2.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.15.0->bigframes) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.15.0->bigframes) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.15.0->bigframes) (4.9)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery>=3.16.0->google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery>=3.16.0->google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery>=3.16.0->google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery>=3.16.0->google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (2.8.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes) (3.20.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes) (0.13.1)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (2.26.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (1.64.1)\n",
            "Requirement already satisfied: db-dtypes<2.0.0dev,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (1.3.0)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.4->bigframes) (1.48.2)\n",
            "Requirement already satisfied: atpublic<5,>=2.3 in /usr/local/lib/python3.10/dist-packages (from ibis-framework<=9.2.0,>=9.0.0->ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (4.1.0)\n",
            "Requirement already satisfied: parsy<3,>=2 in /usr/local/lib/python3.10/dist-packages (from ibis-framework<=9.2.0,>=9.0.0->ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (2.1)\n",
            "Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from ibis-framework<=9.2.0,>=9.0.0->ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (2024.2)\n",
            "Requirement already satisfied: rich<14,>=12.4.4 in /usr/local/lib/python3.10/dist-packages (from ibis-framework<=9.2.0,>=9.0.0->ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (13.8.1)\n",
            "Requirement already satisfied: pyarrow-hotfix<1,>=0.4 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (0.6)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes) (3.6.9)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->bigframes) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->bigframes) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->bigframes) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->bigframes) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->bigframes) (10.4.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->bigframes) (3.0.9)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->bigframes) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pydata-google-auth>=1.8.2->bigframes) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes) (2024.8.30)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->bigframes) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->bigframes) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0dev,>=1.4->bigframes) (3.1.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.0->plotnine) (0.5.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes) (4.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery>=3.16.0->google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (1.65.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs>=2023.3.0->bigframes) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=3.16.0->google-cloud-bigquery[bqstorage,pandas]>=3.16.0->bigframes) (1.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes) (6.3.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (0.19.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (4.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.14.0->plotnine) (1.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.15.0->bigframes) (0.6.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=12.4.4->ibis-framework<=9.2.0,>=9.0.0->ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (3.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=12.4.4->ibis-framework<=9.2.0,>=9.0.0->ibis-framework[bigquery]<=9.2.0,>=9.0.0->bigframes) (0.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.7.1->bigframes) (0.2.13)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2023.3.0->bigframes) (3.2.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "id": "T5ybdEPPp5eI"
      },
      "id": "T5ybdEPPp5eI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c3ed4012",
      "metadata": {
        "origin_pos": 1,
        "id": "c3ed4012"
      },
      "source": [
        "## **8.1 Deep Convolutional Neural Networks (AlexNet)**\n",
        ":label:`sec_alexnet`\n",
        "\n",
        "\n",
        "Although CNNs were well known\n",
        "in the computer vision and machine learning communities\n",
        "following the introduction of LeNet :cite:`LeCun.Jackel.Bottou.ea.1995`,\n",
        "they did not immediately dominate the field.\n",
        "Although LeNet achieved good results on early small datasets,\n",
        "the performance and feasibility of training CNNs\n",
        "on larger, more realistic datasets had yet to be established.\n",
        "In fact, for much of the intervening time between the early 1990s\n",
        "and the watershed results of 2012 :cite:`Krizhevsky.Sutskever.Hinton.2012`,\n",
        "neural networks were often surpassed by other machine learning methods,\n",
        "such as kernel methods :cite:`Scholkopf.Smola.2002`, ensemble methods :cite:`Freund.Schapire.ea.1996`,\n",
        "and structured estimation :cite:`Taskar.Guestrin.Koller.2004`.\n",
        "\n",
        "For computer vision, this comparison is perhaps not entirely accurate.\n",
        "That is, although the inputs to convolutional networks\n",
        "consist of raw or lightly-processed (e.g., by centering) pixel values, practitioners would never feed raw pixels into traditional models.\n",
        "Instead, typical computer vision pipelines\n",
        "consisted of manually engineering feature extraction pipelines, such as SIFT :cite:`Lowe.2004`, SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`, and bags of visual words :cite:`Sivic.Zisserman.2003`.\n",
        "Rather than *learning* the features, the features were *crafted*.\n",
        "Most of the progress came from having more clever ideas for feature extraction on the one hand and deep insight into geometry :cite:`Hartley.Zisserman.2000` on the other. The learning algorithm was often considered an afterthought.\n",
        "\n",
        "Although some neural network accelerators were available in the 1990s,\n",
        "they were not yet sufficiently powerful to make\n",
        "deep multichannel, multilayer CNNs\n",
        "with a large number of parameters. For instance, NVIDIA's GeForce 256 from 1999\n",
        "was able to process at most 480 million floating-point operations, such as additions and multiplications, per second (MFLOPS), without any meaningful\n",
        "programming framework for operations beyond games. Today's accelerators are able to perform in excess of 1000 TFLOPs per device.\n",
        "Moreover, datasets were still relatively small: OCR on 60,000 low-resolution $28 \\times 28$ pixel images was considered a highly challenging task.\n",
        "Added to these obstacles, key tricks for training neural networks\n",
        "including parameter initialization heuristics :cite:`Glorot.Bengio.2010`,\n",
        "clever variants of stochastic gradient descent :cite:`Kingma.Ba.2014`,\n",
        "non-squashing activation functions :cite:`Nair.Hinton.2010`,\n",
        "and effective regularization techniques :cite:`Srivastava.Hinton.Krizhevsky.ea.2014` were still missing.\n",
        "\n",
        "Thus, rather than training *end-to-end* (pixel to classification) systems,\n",
        "classical pipelines looked more like this:\n",
        "\n",
        "1. Obtain an interesting dataset. In the early days, these datasets required expensive sensors. For instance, the [Apple QuickTake 100](https://en.wikipedia.org/wiki/Apple_QuickTake) of 1994 sported a whopping 0.3 megapixel (VGA) resolution, capable of storing up to 8 images, all for the price of \\$1000.\n",
        "1. Preprocess the dataset with hand-crafted features based on some knowledge of optics, geometry, other analytic tools, and occasionally on the serendipitous discoveries by lucky graduate students.\n",
        "1. Feed the data through a standard set of feature extractors such as the SIFT (scale-invariant feature transform) :cite:`Lowe.2004`, the SURF (speeded up robust features) :cite:`Bay.Tuytelaars.Van-Gool.2006`, or any number of other hand-tuned pipelines. OpenCV still provides SIFT extractors to this day!\n",
        "1. Dump the resulting representations into your favorite classifier, likely a linear model or kernel method, to train a classifier.\n",
        "\n",
        "If you spoke to machine learning researchers,\n",
        "they would reply that machine learning was both important and beautiful.\n",
        "Elegant theories proved the properties of various classifiers :cite:`boucheron2005theory` and convex\n",
        "optimization :cite:`Boyd.Vandenberghe.2004` had become the mainstay for obtaining them.\n",
        "The field of machine learning was thriving, rigorous, and eminently useful. However,\n",
        "if you spoke to a computer vision researcher,\n",
        "you would hear a very different story.\n",
        "The dirty truth of image recognition, they would tell you,\n",
        "is that features, geometry :cite:`Hartley.Zisserman.2000,hartley2009global`, and engineering,\n",
        "rather than novel learning algorithms, drove progress.\n",
        "Computer vision researchers justifiably believed\n",
        "that a slightly bigger or cleaner dataset\n",
        "or a slightly improved feature-extraction pipeline\n",
        "mattered far more to the final accuracy than any learning algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "07938be6",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "3"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:33.339125Z",
          "iopub.status.busy": "2023-08-18T19:43:33.338612Z",
          "iopub.status.idle": "2023-08-18T19:43:36.248351Z",
          "shell.execute_reply": "2023-08-18T19:43:36.247404Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "07938be6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3425d857",
      "metadata": {
        "origin_pos": 6,
        "id": "3425d857"
      },
      "source": [
        "## 8.1.1. Representation Learning\n",
        "\n",
        "Another way to cast the state of affairs is that\n",
        "the most important part of the pipeline was the representation.\n",
        "And up until 2012 the representation was calculated mostly mechanically.\n",
        "In fact, engineering a new set of feature functions, improving results, and writing up the method\n",
        "all featured prominently in papers.\n",
        "SIFT :cite:`Lowe.2004`,\n",
        "SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`,\n",
        "HOG (histograms of oriented gradient) :cite:`Dalal.Triggs.2005`,\n",
        "bags of visual words :cite:`Sivic.Zisserman.2003`,\n",
        "and similar feature extractors ruled the roost.\n",
        "\n",
        "Another group of researchers,\n",
        "including Yann LeCun, Geoff Hinton, Yoshua Bengio,\n",
        "Andrew Ng, Shun-ichi Amari, and Juergen Schmidhuber,\n",
        "had different plans.\n",
        "They believed that features themselves ought to be learned.\n",
        "Moreover, they believed that to be reasonably complex,\n",
        "the features ought to be hierarchically composed\n",
        "with multiple jointly learned layers, each with learnable parameters.\n",
        "In the case of an image, the lowest layers might come\n",
        "to detect edges, colors, and textures, by analogy with how the visual system in animals\n",
        "processes its input. In particular, the automatic design of visual features such as those obtained\n",
        "by sparse coding :cite:`olshausen1996emergence` remained an open challenge until the advent of modern CNNs.\n",
        "It was not until :citet:`Dean.Corrado.Monga.ea.2012,le2013building` that the idea of generating features\n",
        "from image data automatically gained significant traction.\n",
        "\n",
        "The first modern CNN :cite:`Krizhevsky.Sutskever.Hinton.2012`, named\n",
        "*AlexNet* after one of its inventors, Alex Krizhevsky, is largely an evolutionary improvement\n",
        "over LeNet. It achieved excellent performance in the 2012 ImageNet challenge.\n",
        "\n",
        "![Image filters learned by the first layer of AlexNet. Reproduction courtesy of :citet:`Krizhevsky.Sutskever.Hinton.2012`.](https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/img/filters.png?raw=1)\n",
        ":width:`400px`\n",
        ":label:`fig_filters`\n",
        "\n",
        "Interestingly, in the lowest layers of the network,\n",
        "the model learned feature extractors that resembled some traditional filters.\n",
        ":numref:`fig_filters`\n",
        "shows lower-level image descriptors.\n",
        "Higher layers in the network might build upon these representations\n",
        "to represent larger structures, like eyes, noses, blades of grass, and so on.\n",
        "Even higher layers might represent whole objects\n",
        "like people, airplanes, dogs, or frisbees.\n",
        "Ultimately, the final hidden state learns a compact representation\n",
        "of the image that summarizes its contents\n",
        "such that data belonging to different categories can be easily separated.\n",
        "\n",
        "AlexNet (2012) and its precursor LeNet (1995) share many architectural elements. This begs the question: why did it take so long?\n",
        "A key difference was that, over the previous two decades, the amount of data and the computing power available had increased significantly. As such AlexNet was much larger: it was trained on much more data, and on much faster GPUs compared to the CPUs available in 1995.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.1.1. Missing Ingredient: Data\n",
        "\n",
        "Deep models with many layers require large amounts of data\n",
        "in order to enter the regime\n",
        "where they significantly outperform traditional methods\n",
        "based on convex optimizations (e.g., linear and kernel methods).\n",
        "However, given the limited storage capacity of computers,\n",
        "the relative expense of (imaging) sensors,\n",
        "and the comparatively tighter research budgets in the 1990s,\n",
        "most research relied on tiny datasets.\n",
        "Numerous papers relied on the UCI collection of datasets,\n",
        "many of which contained only hundreds or (a few) thousands of images\n",
        "captured in low resolution and often with an artificially clean background.\n",
        "\n",
        "In 2009, the ImageNet dataset was released :cite:`Deng.Dong.Socher.ea.2009`,\n",
        "challenging researchers to learn models from 1 million examples,\n",
        "1000 each from 1000 distinct categories of objects. The categories themselves\n",
        "were based on the most popular noun nodes in WordNet :cite:`Miller.1995`.\n",
        "The ImageNet team used Google Image Search to prefilter large candidate sets\n",
        "for each category and employed\n",
        "the Amazon Mechanical Turk crowdsourcing pipeline\n",
        "to confirm for each image whether it belonged to the associated category.\n",
        "This scale was unprecedented, exceeding others by over an order of magnitude\n",
        "(e.g., CIFAR-100 has 60,000 images). Another aspect was that the images were at\n",
        "relatively high resolution of $224 \\times 224$ pixels, unlike the 80 million-sized\n",
        "TinyImages dataset :cite:`Torralba.Fergus.Freeman.2008`, consisting of $32 \\times 32$ pixel thumbnails.\n",
        "This allowed for the formation of higher-level features.\n",
        "The associated competition, dubbed the ImageNet Large Scale Visual Recognition\n",
        "Challenge :cite:`russakovsky2015imagenet`,\n",
        "pushed computer vision and machine learning research forward,\n",
        "challenging researchers to identify which models performed best\n",
        "at a greater scale than academics had previously considered. The largest vision datasets, such as LAION-5B\n",
        ":cite:`schuhmann2022laion` contain billions of images with additional metadata.\n",
        "\n"
      ],
      "metadata": {
        "id": "MqpVN2qJya6-"
      },
      "id": "MqpVN2qJya6-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.1.2. Missing Ingredient: Hardware\n",
        "\n",
        "Deep learning models are voracious consumers of compute cycles.\n",
        "Training can take hundreds of epochs, and each iteration\n",
        "requires passing data through many layers of computationally expensive\n",
        "linear algebra operations.\n",
        "This is one of the main reasons why in the 1990s and early 2000s,\n",
        "simple algorithms based on the more-efficiently optimized\n",
        "convex objectives were preferred.\n",
        "\n",
        "*Graphical processing units* (GPUs) proved to be a game changer\n",
        "in making deep learning feasible.\n",
        "These chips had earlier been developed for accelerating\n",
        "graphics processing to benefit computer games.\n",
        "In particular, they were optimized for high throughput $4 \\times 4$\n",
        "matrix--vector products, which are needed for many computer graphics tasks.\n",
        "Fortunately, the math is strikingly similar\n",
        "to that required for calculating convolutional layers.\n",
        "Around that time, NVIDIA and ATI had begun optimizing GPUs\n",
        "for general computing operations :cite:`Fernando.2004`,\n",
        "going as far as to market them as *general-purpose GPUs* (GPGPUs).\n",
        "\n",
        "To provide some intuition, consider the cores of a modern microprocessor\n",
        "(CPU).\n",
        "Each of the cores is fairly powerful running at a high clock frequency\n",
        "and sporting large caches (up to several megabytes of L3).\n",
        "Each core is well-suited to executing a wide range of instructions,\n",
        "with branch predictors, a deep pipeline, specialized execution units,\n",
        "speculative execution,\n",
        "and many other bells and whistles\n",
        "that enable it to run a large variety of programs with sophisticated control flow.\n",
        "This apparent strength, however, is also its Achilles heel:\n",
        "general-purpose cores are very expensive to build. They excel at general-purpose\n",
        "code with lots of control flow.\n",
        "This requires lots of chip area, not just for the\n",
        "actual ALU (arithmetic logical unit) where computation happens, but also for\n",
        "all the aforementioned bells and whistles, plus\n",
        "memory interfaces, caching logic between cores,\n",
        "high-speed interconnects, and so on. CPUs are\n",
        "comparatively bad at any single task when compared with dedicated hardware.\n",
        "Modern laptops have 4--8 cores,\n",
        "and even high-end servers rarely exceed 64 cores per socket,\n",
        "simply because it is not cost-effective.\n",
        "\n",
        "By comparison, GPUs can consist of thousands of small processing elements (NIVIDA's latest Ampere chips have up to 6912 CUDA cores), often grouped into larger groups (NVIDIA calls them warps).\n",
        "The details differ somewhat between NVIDIA, AMD, ARM and other chip vendors. While each core is relatively weak,\n",
        "running at about 1GHz clock frequency,\n",
        "it is the total number of such cores that makes GPUs orders of magnitude faster than CPUs.\n",
        "For instance, NVIDIA's recent Ampere A100 GPU offers over 300 TFLOPs per chip for specialized 16-bit precision (BFLOAT16) matrix-matrix multiplications, and up to 20 TFLOPs for more general-purpose floating point operations (FP32).\n",
        "At the same time, floating point performance of CPUs rarely exceeds 1 TFLOPs. For instance, Amazon's Graviton 3  reaches 2 TFLOPs peak performance for 16-bit precision operations, a number similar to the GPU performance of Apple's M1 processor.\n",
        "\n",
        "There are many reasons why GPUs are much faster than CPUs in terms of FLOPs.\n",
        "First, power consumption tends to grow *quadratically* with clock frequency.\n",
        "Hence, for the power budget of a CPU core that runs four times faster (a typical number),\n",
        "you can use 16 GPU cores at $\\frac{1}{4}$ the speed,\n",
        "which yields $16 \\times \\frac{1}{4} = 4$ times the performance.\n",
        "Second, GPU cores are much simpler\n",
        "(in fact, for a long time they were not even *able*\n",
        "to execute general-purpose code),\n",
        "which makes them more energy efficient. For instance, (i) they tend not to support speculative evaluation, (ii) it typically is not possible to program each processing element individually, and (iii) the caches per core tend to be much smaller.\n",
        "Last, many operations in deep learning require high memory bandwidth.\n",
        "Again, GPUs shine here with buses that are at least 10 times as wide as many CPUs.\n",
        "\n",
        "Back to 2012. A major breakthrough came\n",
        "when Alex Krizhevsky and Ilya Sutskever\n",
        "implemented a deep CNN\n",
        "that could run on GPUs.\n",
        "They realized that the computational bottlenecks in CNNs,\n",
        "convolutions and matrix multiplications,\n",
        "are all operations that could be parallelized in hardware.\n",
        "Using two NVIDIA GTX 580s with 3GB of memory, either of which was capable of 1.5 TFLOPs (still a challenge for most CPUs a decade later),\n",
        "they implemented fast convolutions.\n",
        "The [cuda-convnet](https://code.google.com/archive/p/cuda-convnet/) code\n",
        "was good enough that for several years\n",
        "it was the industry standard and powered\n",
        "the first couple of years of the deep learning boom.\n",
        "\n"
      ],
      "metadata": {
        "id": "HDPMPWnRyevl"
      },
      "id": "HDPMPWnRyevl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1.2. AlexNet\n",
        "\n",
        "AlexNet, which employed an 8-layer CNN,\n",
        "won the ImageNet Large Scale Visual Recognition Challenge 2012\n",
        "by a large margin :cite:`Russakovsky.Deng.Huang.ea.2013`.\n",
        "This network showed, for the first time,\n",
        "that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision.\n",
        "\n",
        "The architectures of AlexNet and LeNet are strikingly similar,\n",
        "as :numref:`fig_alexnet` illustrates.\n",
        "Note that we provide a slightly streamlined version of AlexNet\n",
        "removing some of the design quirks that were needed in 2012\n",
        "to make the model fit on two small GPUs.\n",
        "\n",
        "![From LeNet (left) to AlexNet (right).](http://d2l.ai/_images/alexnet.svg)\n",
        ":label:`fig_alexnet`\n",
        "\n",
        "There are also significant differences between AlexNet and LeNet.\n",
        "First, AlexNet is much deeper than the comparatively small LeNet-5.\n",
        "AlexNet consists of eight layers: five convolutional layers,\n",
        "two fully connected hidden layers, and one fully connected output layer.\n",
        "Second, AlexNet used the ReLU instead of the sigmoid\n",
        "as its activation function. Let's delve into the details below.\n",
        "\n"
      ],
      "metadata": {
        "id": "3r9kVKcZyisM"
      },
      "id": "3r9kVKcZyisM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.2.1. Architecture\n",
        "\n",
        "In AlexNet's first layer, the convolution window shape is $11\\times11$.\n",
        "Since the images in ImageNet are eight times taller and wider\n",
        "than the MNIST images,\n",
        "objects in ImageNet data tend to occupy more pixels with more visual detail.\n",
        "Consequently, a larger convolution window is needed to capture the object.\n",
        "The convolution window shape in the second layer\n",
        "is reduced to $5\\times5$, followed by $3\\times3$.\n",
        "In addition, after the first, second, and fifth convolutional layers,\n",
        "the network adds max-pooling layers\n",
        "with a window shape of $3\\times3$ and a stride of 2.\n",
        "Moreover, AlexNet has ten times more convolution channels than LeNet.\n",
        "\n",
        "After the final convolutional layer, there are two huge fully connected layers\n",
        "with 4096 outputs.\n",
        "These layers require nearly 1GB model parameters.\n",
        "Because of the limited memory in early GPUs,\n",
        "the original AlexNet used a dual data stream design,\n",
        "so that each of their two GPUs could be responsible\n",
        "for storing and computing only its half of the model.\n",
        "Fortunately, GPU memory is comparatively abundant now,\n",
        "so we rarely need to break up models across GPUs these days\n",
        "(our version of the AlexNet model deviates\n",
        "from the original paper in this aspect).\n",
        "\n"
      ],
      "metadata": {
        "id": "sRUnUbRtylbF"
      },
      "id": "sRUnUbRtylbF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.2.2. Activation Functions\n",
        "\n",
        "Furthermore, AlexNet changed the sigmoid activation function to a simpler ReLU activation function. On the one hand, the computation of the ReLU activation function is simpler. For example, it does not have the exponentiation operation found in the sigmoid activation function.\n",
        " On the other hand, the ReLU activation function makes model training easier when using different parameter initialization methods. This is because, when the output of the sigmoid activation function is very close to 0 or 1, the gradient of these regions is almost 0, so that backpropagation cannot continue to update some of the model parameters. By contrast, the gradient of the ReLU activation function in the positive interval is always 1 (:numref:`subsec_activation-functions`). Therefore, if the model parameters are not properly initialized, the sigmoid function may obtain a gradient of almost 0 in the positive interval, meaning that the model cannot be effectively trained.\n",
        "\n"
      ],
      "metadata": {
        "id": "KS6fkwYeyn4M"
      },
      "id": "KS6fkwYeyn4M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.2.3. Capacity Control and Preprocessing\n",
        "\n",
        "AlexNet controls the model complexity of the fully connected layer\n",
        "by dropout (:numref:`sec_dropout`),\n",
        "while LeNet only uses weight decay.\n",
        "To augment the data even further, the training loop of AlexNet\n",
        "added a great deal of image augmentation,\n",
        "such as flipping, clipping, and color changes.\n",
        "This makes the model more robust and the larger sample size effectively reduces overfitting.\n",
        "See :citet:`Buslaev.Iglovikov.Khvedchenya.ea.2020` for an in-depth review of such preprocessing steps."
      ],
      "metadata": {
        "id": "mfxwj3BeypvE"
      },
      "id": "mfxwj3BeypvE"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "29feac8e",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:36.252627Z",
          "iopub.status.busy": "2023-08-18T19:43:36.251926Z",
          "iopub.status.idle": "2023-08-18T19:43:36.259662Z",
          "shell.execute_reply": "2023-08-18T19:43:36.258841Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "29feac8e"
      },
      "outputs": [],
      "source": [
        "class AlexNet(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
        "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
        "            nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
        "            nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e725f1",
      "metadata": {
        "origin_pos": 9,
        "id": "59e725f1"
      },
      "source": [
        "We [**construct a single-channel data example**] with both height and width of 224 (**to observe the output shape of each layer**). It matches the AlexNet architecture in :numref:`fig_alexnet`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3d5c2c0a",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:36.262984Z",
          "iopub.status.busy": "2023-08-18T19:43:36.262447Z",
          "iopub.status.idle": "2023-08-18T19:43:36.786362Z",
          "shell.execute_reply": "2023-08-18T19:43:36.785437Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "3d5c2c0a",
        "outputId": "4ac2034e-54d5-4a66-d767-e207f3ba77f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
            "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
            "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
            "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
            "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
            "Flatten output shape:\t torch.Size([1, 6400])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "AlexNet().layer_summary((1, 1, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "193ba4c7",
      "metadata": {
        "origin_pos": 13,
        "id": "193ba4c7"
      },
      "source": [
        "## 8.1.3. Training\n",
        "\n",
        "Although AlexNet was trained on ImageNet in :citet:`Krizhevsky.Sutskever.Hinton.2012`,\n",
        "we use Fashion-MNIST here\n",
        "since training an ImageNet model to convergence could take hours or days\n",
        "even on a modern GPU.\n",
        "One of the problems with applying AlexNet directly on [**Fashion-MNIST**]\n",
        "is that its (**images have lower resolution**) ($28 \\times 28$ pixels)\n",
        "(**than ImageNet images.**)\n",
        "To make things work, (**we upsample them to $224 \\times 224$**).\n",
        "This is generally not a smart practice, as it simply increases the computational\n",
        "complexity without adding information. Nonetheless, we do it here to be faithful to the AlexNet architecture.\n",
        "We perform this resizing with the `resize` argument in the `d2l.FashionMNIST` constructor.\n",
        "\n",
        "Now, we can [**start training AlexNet.**]\n",
        "Compared to LeNet in :numref:`sec_lenet`,\n",
        "the main change here is the use of a smaller learning rate\n",
        "and much slower training due to the deeper and wider network,\n",
        "the higher image resolution, and the more costly convolutions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "acd6a3e0",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:36.789914Z",
          "iopub.status.busy": "2023-08-18T19:43:36.789357Z",
          "iopub.status.idle": "2023-08-18T19:46:37.458518Z",
          "shell.execute_reply": "2023-08-18T19:46:37.457483Z"
        },
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "id": "acd6a3e0",
        "outputId": "c2089ec5-3f8d-460c-d71d-c04fc3e4e846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T03:33:38.107115</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m6614e0aacb\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m6614e0aacb\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m6614e0aacb\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m6614e0aacb\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m6614e0aacb\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m6614e0aacb\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m6614e0aacb\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m1f00d39918\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m1f00d39918\" x=\"30.103125\" y=\"118.223964\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 122.023182) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m1f00d39918\" x=\"30.103125\" y=\"89.166254\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 92.965473) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m1f00d39918\" x=\"30.103125\" y=\"60.108545\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 63.907764) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m1f00d39918\" x=\"30.103125\" y=\"31.050836\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 34.850055) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 13.803648 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 13.803648 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 13.803648 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 13.803648 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \nL 200.605438 119.215219 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \nL 200.605438 119.215219 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \nL 205.873125 119.958722 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \nL 200.605438 119.215219 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \nL 205.873125 119.958722 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \nL 205.873125 99.143348 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \nL 200.605438 119.215219 \nL 210.349618 119.748831 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \nL 205.873125 119.958722 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \nL 205.873125 99.143348 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \nL 200.605438 119.215219 \nL 210.349618 119.748831 \nL 220.093797 121.110087 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \nL 205.873125 119.958722 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \nL 205.873125 99.143348 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \nL 200.605438 119.215219 \nL 210.349618 119.748831 \nL 220.093797 121.110087 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \nL 205.873125 119.958722 \nL 225.403125 120.206279 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \nL 205.873125 99.143348 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.630369 \nL 54.442752 14.701834 \nL 64.186931 70.055541 \nL 73.93111 89.565034 \nL 83.675289 95.342506 \nL 93.419468 98.921127 \nL 103.163647 102.560425 \nL 112.907826 104.972887 \nL 122.652006 108.118017 \nL 132.396185 109.897287 \nL 142.140364 112.294408 \nL 151.884543 113.768756 \nL 161.628722 115.299407 \nL 171.372901 115.852932 \nL 181.11708 117.716646 \nL 190.861259 118.413445 \nL 200.605438 119.215219 \nL 210.349618 119.748831 \nL 220.093797 121.110087 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 13.803648 \nL 69.163125 87.382384 \nL 88.693125 98.398636 \nL 108.223125 104.661426 \nL 127.753125 109.805281 \nL 147.283125 113.311848 \nL 166.813125 116.285187 \nL 186.343125 118.087246 \nL 205.873125 119.958722 \nL 225.403125 120.206279 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 111.976786 \nL 88.693125 108.344572 \nL 108.223125 105.626159 \nL 127.753125 103.206599 \nL 147.283125 101.936474 \nL 166.813125 100.695085 \nL 186.343125 100.246805 \nL 205.873125 99.143348 \nL 225.403125 99.344499 \n\" clip-path=\"url(#pa248321ab3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa248321ab3\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = AlexNet(lr=0.01)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9c33357",
      "metadata": {
        "origin_pos": 16,
        "id": "f9c33357"
      },
      "source": [
        "## 8.1.4. Discussion\n",
        "\n",
        "AlexNet's structure bears a striking resemblance to LeNet, with a number of critical improvements, both for accuracy (dropout) and for ease of training (ReLU). What is equally striking is the amount of progress that has been made in terms of deep learning tooling. What was several months of work in 2012 can now be accomplished in a dozen lines of code using any modern framework.\n",
        "\n",
        "Reviewing the architecture, we see that AlexNet has an Achilles heel when it comes to efficiency: the last two hidden layers require matrices of size $6400 \\times 4096$ and $4096 \\times 4096$, respectively. This corresponds to 164 MB of memory and 81 MFLOPs of computation, both of which are a nontrivial outlay, especially on smaller devices, such as mobile phones. This is one of the reasons why AlexNet has been surpassed by much more effective architectures that we will cover in the following sections. Nonetheless, it is a key step from shallow to deep networks that are used nowadays. Note that even though the number of parameters exceeds by far the amount of training data in our experiments (the last two layers have more than 40 million parameters, trained on a datasets of 60 thousand images), there is hardly any overfitting: training and validation loss are virtually identical throughout training. This is due to the improved regularization, such as dropout, inherent in modern deep network designs.\n",
        "\n",
        "Although it seems that there are only a few more lines in AlexNet's implementation than in LeNet's, it took the academic community many years to embrace this conceptual change and take advantage of its excellent experimental results. This was also due to the lack of efficient computational tools. At the time neither DistBelief :cite:`Dean.Corrado.Monga.ea.2012` nor Caffe :cite:`Jia.Shelhamer.Donahue.ea.2014` existed, and Theano :cite:`Bergstra.Breuleux.Bastien.ea.2010` still lacked many distinguishing features. It was the availability of TensorFlow :cite:`Abadi.Barham.Chen.ea.2016` that dramatically changed the situation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1.5. Exercises\n",
        "\n",
        "1. Following up on the discussion above, analyze the computational properties of AlexNet.\n",
        "    1. Compute the memory footprint for convolutions and fully connected layers, respectively. Which one dominates?\n",
        "    1. Calculate the computational cost for the convolutions and the fully connected layers.\n",
        "    1. How does the memory (read and write bandwidth, latency, size) affect computation? Is there any difference in its effects for training and inference?\n",
        "1. You are a chip designer and need to trade off computation and memory bandwidth. For example, a faster chip requires more power and possibly a larger chip area. More memory bandwidth requires more pins and control logic, thus also more area. How do you optimize?\n",
        "1. Why do engineers no longer report performance benchmarks on AlexNet?\n",
        "1. Try increasing the number of epochs when training AlexNet. Compared with LeNet, how do the results differ? Why?\n",
        "1. AlexNet may be too complex for the Fashion-MNIST dataset, in particular due to the low resolution of the initial images.\n",
        "    1. Try simplifying the model to make the training faster, while ensuring that the accuracy does not drop significantly.\n",
        "    1. Design a better model that works directly on $28 \\times 28$ images.\n",
        "1. Modify the batch size, and observe the changes in throughput (images/s), accuracy, and GPU memory.\n",
        "1. Apply dropout and ReLU to LeNet-5. Does it improve? Can you improve things further by preprocessing to take advantage of the invariances inherent in the images?\n",
        "1. Can you make AlexNet overfit? Which feature do you need to remove or change to break training?"
      ],
      "metadata": {
        "id": "QrOC0rndyQTV"
      },
      "id": "QrOC0rndyQTV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "c5egn6HTsmO3"
      },
      "id": "c5egn6HTsmO3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1. Memory Footprint for AlexNet's Convolutions and Fully Connected Layers\n",
        "In AlexNet, the memory footprint can be split between the convolutional layers and fully connected (FC) layers. Here's a high-level overview:**\n",
        "\n",
        "**Convolutional Layers:** The memory footprint for convolutions is determined by:\n",
        "* The number of filters\n",
        "* The size of the input feature maps\n",
        "* The size of the convolution kernels\n",
        "* Stride and padding\n",
        "* The number of input and output channels.\n",
        "To calculate the memory footprint for a convolutional layer:\n",
        "Memory\n",
        "=\n",
        "Number of filters\n",
        "×\n",
        "Filter size\n",
        "×\n",
        "Input channels\n",
        "+\n",
        "Output feature map size\n",
        "Memory=Number of filters×Filter size×Input channels+Output feature map size\n",
        "\n",
        "For instance, the first convolutional layer of AlexNet has 96 filters of size\n",
        "11\n",
        "×\n",
        "11\n",
        "×\n",
        "3\n",
        "11×11×3. The input size is\n",
        "227\n",
        "×\n",
        "227\n",
        "×\n",
        "3\n",
        "227×227×3, and it outputs\n",
        "55\n",
        "×\n",
        "55\n",
        "×\n",
        "96\n",
        "55×55×96.\n",
        "\n",
        "**Fully Connected Layers:** Fully connected layers in AlexNet, particularly the last three, are memory-intensive due to the dense connections between neurons. Each fully connected layer can be represented as a matrix multiplication operation. The memory footprint depends on the number of neurons in the layer and the size of the input vector.\n",
        "For instance, the first fully connected layer in AlexNet has\n",
        "9216\n",
        "×\n",
        "4096\n",
        "9216×4096 weights, while the second has\n",
        "4096\n",
        "×\n",
        "4096\n",
        "4096×4096 weights, and the final output layer has\n",
        "4096\n",
        "×\n",
        "1000\n",
        "4096×1000.\n",
        "\n",
        "**1.3. Which One Dominates?**\n",
        "Typically, the **fully connected layers** dominate the memory footprint in AlexNet due to their large weight matrices. The convolutional layers dominate computation (in terms of floating-point operations), but the FC layers require more memory to store the parameters.\n",
        "\n",
        "**How Does Memory Affect Computation?**\n",
        "Memory affects computation in terms of read/write bandwidth, latency, and size. For convolutional layers, the effect of memory is mainly in terms of reading/writing feature maps and parameters. FC layers suffer more from memory bottlenecks due to the need to load large weight matrices into memory.\n",
        "\n",
        "* **Training vs. Inference:** In training, both forward and backward passes need memory and computation, making the memory bandwidth more critical. Inference only requires forward passes, making memory less of a bottleneck, but still important for large models.\n",
        "\n",
        "**2. Optimizing for Computation and Memory Bandwidth**\n",
        "As a chip designer, you need to balance between computation and memory bandwidth. To optimize:\n",
        "\n",
        "* Reduce memory traffic by keeping data on-chip as much as possible, through tiling or data reuse.\n",
        "* Trade-off chip area: A larger chip area could accommodate more compute cores and on-chip memory, but it will increase power consumption and cost.\n",
        "* Efficient parallelism: Parallelize operations to hide memory latency"
      ],
      "metadata": {
        "id": "c__QGkg0tJw3"
      },
      "id": "c__QGkg0tJw3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Why Engineers No Longer Report Performance Benchmarks on AlexNet?**\n",
        "\n",
        "AlexNet is outdated, and modern networks like ResNet, EfficientNet, and Vision Transformers (ViTs) have far better accuracy and efficiency. AlexNet's architecture, designed in 2012, was revolutionary for its time but is now too simple and inefficient. Modern benchmarks focus on more challenging tasks with higher resolutions and more complex datasets (e.g., ImageNet, COCO).\n",
        "\n",
        "**4. Comparison of AlexNet vs. LeNet Training over Multiple Epochs\n",
        "When increasing the number of epochs for training:**\n",
        "\n",
        "* **AlexNet:** Being a deeper and more complex network, AlexNet tends to converge more slowly on simpler datasets like MNIST or Fashion-MNIST. This can lead to overfitting when the model is overly complex for the dataset.\n",
        "* **LeNet:** This is a simpler model and tends to converge faster on small datasets like MNIST. Due to its lower capacity, it is less prone to overfitting when trained over more epochs.\n",
        "AlexNet, with its large capacity, will often require techniques like regularization (e.g., dropout) to prevent overfitting when trained on small datasets.\n",
        "\n",
        "**5. Simplifying AlexNet for Fashion-MNIST**\n",
        "\n",
        "* **Simplifying the Model:** Given that Fashion-MNIST images are\n",
        "28\n",
        "×\n",
        "28\n",
        "28×28, AlexNet’s complex architecture is overkill. One can simplify AlexNet by:\n",
        "\n",
        "* **Reducing the number of convolutional layers or filters.**\n",
        "Removing the fully connected layers and replacing them with global average pooling.\n",
        "Using smaller kernel sizes for the convolutions.\n",
        "\n",
        "* **A Better Model:** You can design a better model for\n",
        "28\n",
        "×\n",
        "28\n",
        "28×28 images:\n",
        "\n",
        "* Convolutional layers: Use 3 or 4 convolutional layers with fewer filters (e.g., 32, 64, 128).\n",
        "  * Pooling layers: Use max-pooling to reduce spatial resolution.\n",
        "  * Fully connected layers: One or two FC layers before the output.\n",
        "  * Use techniques like batch normalization and dropout to improve generalization.\n"
      ],
      "metadata": {
        "id": "ciUa2xXZvctl"
      },
      "id": "ciUa2xXZvctl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Effect of Batch Size on Throughput, Accuracy, and Memory**\n",
        "\n",
        "* **Throughput (images/s):** Increasing batch size generally increases throughput up to a certain point, as it allows better utilization of the GPU.\n",
        "* **Accuracy:** Larger batch sizes can lead to faster convergence but may lead to worse generalization due to noisier gradients.\n",
        "* **Memory:** Increasing batch size increases GPU memory usage since more images are processed simultaneously."
      ],
      "metadata": {
        "id": "5qumh23wwIgp"
      },
      "id": "5qumh23wwIgp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Applying Dropout and ReLU to LeNet-5**\n",
        "\n",
        "* **Improvement with Dropout:** Adding dropout can improve generalization by preventing overfitting, especially in the fully connected layers.\n",
        "* **Improvement with ReLU:** ReLU can accelerate training by mitigating the vanishing gradient problem and providing faster convergence.\n",
        "* **Further Improvements:** Preprocessing the images by leveraging invariances, such as translation, scaling, and rotation, can help the model focus on features more robust to distortions.\n"
      ],
      "metadata": {
        "id": "i9hz0tEDwRq6"
      },
      "id": "i9hz0tEDwRq6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Overfitting AlexNet**\n",
        "\n",
        "You can make AlexNet overfit by removing regularization techniques, such as:\n",
        "\n",
        "* **Dropout:** Removing dropout will increase the model's likelihood to overfit, as it reduces regularization.\n",
        "* **Data augmentation:** Using a small or simplified dataset without data augmentation will also cause overfitting.\n",
        "* **Batch normalization:** Disabling batch normalization may lead to poor generalization, especially during training.\n",
        "\n",
        "By doing this, AlexNet will memorize the training data instead of learning generalizable patterns, leading to overfitting."
      ],
      "metadata": {
        "id": "wIUBkfIiwda3"
      },
      "id": "wIUBkfIiwda3"
    },
    {
      "cell_type": "markdown",
      "id": "3e825ff7",
      "metadata": {
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "id": "3e825ff7"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/76)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "36b56088"
      },
      "source": [
        "# 8.2. Networks Using Blocks (VGG)\n",
        ":label:`sec_vgg`\n",
        "\n",
        "While AlexNet offered empirical evidence that deep CNNs\n",
        "can achieve good results, it did not provide a general template\n",
        "to guide subsequent researchers in designing new networks.\n",
        "In the following sections, we will introduce several heuristic concepts\n",
        "commonly used to design deep networks.\n",
        "\n",
        "Progress in this field mirrors that of VLSI (very large scale integration)\n",
        "in chip design\n",
        "where engineers moved from placing transistors\n",
        "to logical elements to logic blocks :cite:`Mead.1980`.\n",
        "Similarly, the design of neural network architectures\n",
        "has grown progressively more abstract,\n",
        "with researchers moving from thinking in terms of\n",
        "individual neurons to whole layers,\n",
        "and now to blocks, repeating patterns of layers. A decade later, this has now\n",
        "progressed to researchers using entire trained models to repurpose them for different,\n",
        "albeit related, tasks. Such large pretrained models are typically called\n",
        "*foundation models* :cite:`bommasani2021opportunities`.\n",
        "\n",
        "Back to network design. The idea of using blocks first emerged from the\n",
        "Visual Geometry Group (VGG) at Oxford University,\n",
        "in their eponymously-named *VGG* network :cite:`Simonyan.Zisserman.2014`.\n",
        "It is easy to implement these repeated structures in code\n",
        "with any modern deep learning framework by using loops and subroutines.\n"
      ],
      "id": "36b56088"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:56:46.393555Z",
          "iopub.status.busy": "2023-08-18T19:56:46.392607Z",
          "iopub.status.idle": "2023-08-18T19:56:49.756697Z",
          "shell.execute_reply": "2023-08-18T19:56:49.755534Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "89467a5c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "id": "89467a5c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "7c884009"
      },
      "source": [
        "## 8.2.1. (**VGG Blocks**)\n",
        ":label:`subsec_vgg-blocks`\n",
        "\n",
        "The basic building block of CNNs\n",
        "is a sequence of the following:\n",
        "(i) a convolutional layer\n",
        "with padding to maintain the resolution,\n",
        "(ii) a nonlinearity such as a ReLU,\n",
        "(iii) a pooling layer such\n",
        "as max-pooling to reduce the resolution. One of the problems with\n",
        "this approach is that the spatial resolution decreases quite rapidly. In particular,\n",
        "this imposes a hard limit of $\\log_2 d$ convolutional layers on the network before all\n",
        "dimensions ($d$) are used up. For instance, in the case of ImageNet, it would be impossible to have\n",
        "more than 8 convolutional layers in this way.\n",
        "\n",
        "The key idea of :citet:`Simonyan.Zisserman.2014` was to use *multiple* convolutions in between downsampling\n",
        "via max-pooling in the form of a block. They were primarily interested in whether deep or\n",
        "wide networks perform better. For instance, the successive application of two $3 \\times 3$ convolutions\n",
        "touches the same pixels as a single $5 \\times 5$ convolution does. At the same time, the latter uses approximately\n",
        "as many parameters ($25 \\cdot c^2$) as three $3 \\times 3$ convolutions do ($3 \\cdot 9 \\cdot c^2$).\n",
        "In a rather detailed analysis they showed that deep and narrow networks significantly outperform their shallow counterparts. This set deep learning on a quest for ever deeper networks with over 100 layers for typical applications.\n",
        "Stacking $3 \\times 3$ convolutions\n",
        "has become a gold standard in later deep networks (a design decision only to be revisited recently by\n",
        ":citet:`liu2022convnet`). Consequently, fast implementations for small convolutions have become a staple on GPUs :cite:`lavin2016fast`.\n",
        "\n",
        "Back to VGG: a VGG block consists of a *sequence* of convolutions with $3\\times3$ kernels with padding of 1\n",
        "(keeping height and width) followed by a $2 \\times 2$ max-pooling layer with stride of 2\n",
        "(halving height and width after each block).\n",
        "In the code below, we define a function called `vgg_block`\n",
        "to implement one VGG block.\n",
        "\n",
        "The function below takes two arguments,\n",
        "corresponding to the number of convolutional layers `num_convs`\n",
        "and the number of output channels `num_channels`.\n"
      ],
      "id": "7c884009"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "3"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:56:49.762934Z",
          "iopub.status.busy": "2023-08-18T19:56:49.761989Z",
          "iopub.status.idle": "2023-08-18T19:56:49.770418Z",
          "shell.execute_reply": "2023-08-18T19:56:49.769006Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "7a35971a"
      },
      "outputs": [],
      "source": [
        "def vgg_block(num_convs, out_channels):\n",
        "    layers = []\n",
        "    for _ in range(num_convs):\n",
        "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "    return nn.Sequential(*layers)"
      ],
      "id": "7a35971a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "6c267659"
      },
      "source": [
        "## 8.2.2. [**VGG Network**]\n",
        ":label:`subsec_vgg-network`\n",
        "\n",
        "Like AlexNet and LeNet,\n",
        "the VGG Network can be partitioned into two parts:\n",
        "the first consisting mostly of convolutional and pooling layers\n",
        "and the second consisting of fully connected layers that are identical to those in AlexNet.\n",
        "The key difference is\n",
        "that the convolutional layers are grouped in nonlinear transformations that\n",
        "leave the dimensonality unchanged, followed by a resolution-reduction step, as\n",
        "depicted in :numref:`fig_vgg`.\n",
        "\n",
        "![From AlexNet to VGG. The key difference is that VGG consists of blocks of layers, whereas AlexNet's layers are all designed individually.](http://d2l.ai/_images/vgg.svg)\n",
        ":width:`400px`\n",
        ":label:`fig_vgg`\n",
        "\n",
        "The convolutional part of the network connects several VGG blocks from :numref:`fig_vgg` (also defined in the `vgg_block` function)\n",
        "in succession. This grouping of convolutions is a pattern that has\n",
        "remained almost unchanged over the past decade, although the specific choice of\n",
        "operations has undergone considerable modifications.\n",
        "The variable `arch` consists of a list of tuples (one per block),\n",
        "where each contains two values: the number of convolutional layers\n",
        "and the number of output channels,\n",
        "which are precisely the arguments required to call\n",
        "the `vgg_block` function. As such, VGG defines a *family* of networks rather than just\n",
        "a specific manifestation. To build a specific network we simply iterate over `arch` to compose the blocks.\n"
      ],
      "id": "6c267659"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:56:49.775273Z",
          "iopub.status.busy": "2023-08-18T19:56:49.774832Z",
          "iopub.status.idle": "2023-08-18T19:56:49.783845Z",
          "shell.execute_reply": "2023-08-18T19:56:49.782642Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "35ed8ba4"
      },
      "outputs": [],
      "source": [
        "class VGG(d2l.Classifier):\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        conv_blks = []\n",
        "        for (num_convs, out_channels) in arch:\n",
        "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
        "        self.net = nn.Sequential(\n",
        "            *conv_blks, nn.Flatten(),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ],
      "id": "35ed8ba4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "id": "f4413c3f"
      },
      "source": [
        "The original VGG network had five convolutional blocks,\n",
        "among which the first two have one convolutional layer each\n",
        "and the latter three contain two convolutional layers each.\n",
        "The first block has 64 output channels\n",
        "and each subsequent block doubles the number of output channels,\n",
        "until that number reaches 512.\n",
        "Since this network uses eight convolutional layers\n",
        "and three fully connected layers, it is often called VGG-11.\n"
      ],
      "id": "f4413c3f"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:56:49.789248Z",
          "iopub.status.busy": "2023-08-18T19:56:49.788373Z",
          "iopub.status.idle": "2023-08-18T19:56:51.334656Z",
          "shell.execute_reply": "2023-08-18T19:56:51.333439Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "fc110465",
        "outputId": "b28a0585-2db4-4cd1-e32b-a04748176ba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
            "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
            "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
            "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
            "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
            "Flatten output shape:\t torch.Size([1, 25088])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).layer_summary(\n",
        "    (1, 1, 224, 224))"
      ],
      "id": "fc110465"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 18,
        "id": "cb49027b"
      },
      "source": [
        "As you can see, we halve height and width at each block,\n",
        "finally reaching a height and width of 7\n",
        "before flattening the representations\n",
        "for processing by the fully connected part of the network.\n",
        ":citet:`Simonyan.Zisserman.2014` described several other variants of VGG.\n",
        "In fact, it has become the norm to propose *families* of networks with\n",
        "different speed--accuracy trade-off when introducing a new architecture.\n",
        "\n",
        "## 8.2.3. Training\n",
        "\n",
        "[**Since VGG-11 is computationally more demanding than AlexNet\n",
        "we construct a network with a smaller number of channels.**]\n",
        "This is more than sufficient for training on Fashion-MNIST.\n",
        "The [**model training**] process is similar to that of AlexNet in :numref:`sec_alexnet`.\n",
        "Again observe the close match between validation and training loss,\n",
        "suggesting only a small amount of overfitting.\n"
      ],
      "id": "cb49027b"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:56:51.339409Z",
          "iopub.status.busy": "2023-08-18T19:56:51.338575Z",
          "iopub.status.idle": "2023-08-18T20:01:43.617050Z",
          "shell.execute_reply": "2023-08-18T20:01:43.615832Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "ed532028",
        "outputId": "a6e0ed8b-a287-48d6-8fbc-ca85e0cdb80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T04:20:17.880943</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m8ac2d9fe5d\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m8ac2d9fe5d\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m8ac2d9fe5d\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m8ac2d9fe5d\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m8ac2d9fe5d\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m8ac2d9fe5d\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m8ac2d9fe5d\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m702b6f91d3\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m702b6f91d3\" x=\"30.103125\" y=\"126.418333\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 130.217552) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m702b6f91d3\" x=\"30.103125\" y=\"94.915213\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 98.714432) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m702b6f91d3\" x=\"30.103125\" y=\"63.412093\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 67.211312) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m702b6f91d3\" x=\"30.103125\" y=\"31.908973\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 35.708192) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 108.1124 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 108.1124 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 114.018964 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 108.1124 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 114.018964 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 108.1124 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 114.018964 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 114.018964 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \nL 200.605438 138.261556 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \nL 200.605438 138.261556 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \nL 205.873125 138.812864 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \nL 200.605438 138.261556 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \nL 205.873125 138.812864 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \nL 205.873125 101.87506 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \nL 200.605438 138.261556 \nL 210.349618 139.207927 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \nL 205.873125 138.812864 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \nL 205.873125 101.87506 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \nL 200.605438 138.261556 \nL 210.349618 139.207927 \nL 220.093797 138.761347 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \nL 205.873125 138.812864 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \nL 205.873125 101.87506 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \nL 200.605438 138.261556 \nL 210.349618 139.207927 \nL 220.093797 138.761347 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \nL 205.873125 138.812864 \nL 225.403125 139.5 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \nL 205.873125 101.87506 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.296364 \nL 54.442752 112.928218 \nL 64.186931 120.853264 \nL 73.93111 124.844142 \nL 83.675289 127.330904 \nL 93.419468 129.113093 \nL 103.163647 131.051261 \nL 112.907826 132.16241 \nL 122.652006 133.132839 \nL 132.396185 134.485213 \nL 142.140364 134.491471 \nL 151.884543 135.763966 \nL 161.628722 136.226049 \nL 171.372901 136.857089 \nL 181.11708 137.295096 \nL 190.861259 137.960333 \nL 200.605438 138.261556 \nL 210.349618 139.207927 \nL 220.093797 138.761347 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 108.1124 \nL 69.163125 123.369231 \nL 88.693125 129.877212 \nL 108.223125 132.996823 \nL 127.753125 135.130667 \nL 147.283125 136.238364 \nL 166.813125 137.03564 \nL 186.343125 137.861132 \nL 205.873125 138.812864 \nL 225.403125 139.5 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 114.018964 \nL 69.163125 107.594969 \nL 88.693125 105.189866 \nL 108.223125 103.756773 \nL 127.753125 103.283229 \nL 147.283125 102.641453 \nL 166.813125 102.585375 \nL 186.343125 102.136755 \nL 205.873125 101.87506 \nL 225.403125 101.58221 \n\" clip-path=\"url(#p359d12a244)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p359d12a244\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "id": "ed532028"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 21,
        "id": "157480ef"
      },
      "source": [
        "## 8.2.4. Summary\n",
        "\n",
        "One might argue that VGG is the first truly modern convolutional neural network. While AlexNet introduced many of the components of what make deep learning effective at scale, it is VGG that arguably introduced key properties such as blocks of multiple convolutions and a preference for deep and narrow networks. It is also the first network that is actually an entire family of similarly parametrized models, giving the practitioner ample trade-off between complexity and speed. This is also the place where modern deep learning frameworks shine. It is no longer necessary to generate XML configuration files to specify a network but rather, to assemble said networks through simple Python code.\n",
        "\n",
        "More recently ParNet :cite:`Goyal.Bochkovskiy.Deng.ea.2021` demonstrated that it is possible to achieve competitive performance using a much more shallow architecture through a large number of parallel computations. This is an exciting development and there is hope that it will influence architecture designs in the future. For the remainder of the chapter, though, we will follow the path of scientific progress over the past decade.\n",
        "\n"
      ],
      "id": "157480ef"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2.5. Exercises\n",
        "\n",
        "\n",
        "1. Compared with AlexNet, VGG is much slower in terms of computation, and it also needs more GPU memory.\n",
        "    1. Compare the number of parameters needed for AlexNet and VGG.\n",
        "    1. Compare the number of floating point operations used in the convolutional layers and in the fully connected layers.\n",
        "    1. How could you reduce the computational cost created by the fully connected layers?\n",
        "1. When displaying the dimensions associated with the various layers of the network, we only see the information associated with eight blocks (plus some auxiliary transforms), even though the network has 11 layers. Where did the remaining three layers go?\n",
        "1. Use Table 1 in the VGG paper :cite:`Simonyan.Zisserman.2014` to construct other common models, such as VGG-16 or VGG-19.\n",
        "1. Upsampling the resolution in Fashion-MNIST eight-fold from $28 \\times 28$ to $224 \\times 224$ dimensions is very wasteful. Try modifying the network architecture and resolution conversion, e.g., to 56 or to 84 dimensions for its input instead. Can you do so without reducing the accuracy of the network? Consult the VGG paper :cite:`Simonyan.Zisserman.2014` for ideas on adding more nonlinearities prior to downsampling.\n"
      ],
      "metadata": {
        "id": "77_hyd3Ezv0R"
      },
      "id": "77_hyd3Ezv0R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "-I-z4Ml0z46J"
      },
      "id": "-I-z4Ml0z46J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Comparing AlexNet and VGG**\n",
        "\n",
        "**1.1. Number of Parameters in AlexNet vs. VGG**\n",
        "\n",
        "* AlexNet:\n",
        "AlexNet has approximately 60 million parameters. Most of these parameters are concentrated in the fully connected (FC) layers.\n",
        "Specifically, the convolutional layers contribute around 3.5 million parameters, while the FC layers contribute the remaining ~57 million.\n",
        "\n",
        "* VGG-16:\n",
        "VGG-16 has approximately 138 million parameters. A large proportion of these parameters are also in the fully connected layers.\n",
        "VGG-16 has many more convolutional layers, and each of these layers tends to have a large number of filters (e.g., 64, 128, 256, 512), contributing significantly to the parameter count.\n",
        "\n",
        "**1.2. Number of Floating-Point Operations (FLOPs) in Convolutional vs. Fully Connected Layers**\n",
        "\n",
        "* AlexNet:\n",
        "\n",
        "The majority of floating-point operations (FLOPs) occur in the convolutional layers, even though the fully connected layers have the most parameters. This is because convolution involves repeatedly applying filters across the entire input feature map.\n",
        "Conv Layers: The first convolutional layer alone (11x11 filters on a 227x227 image) requires billions of FLOPs.\n",
        "FC Layers: The fully connected layers, though heavy in parameters, involve fewer operations compared to convolutional layers.\n",
        "\n",
        "* VGG-16:\n",
        "\n",
        "VGG-16 significantly increases the number of convolutional layers (13 convolutional layers compared to AlexNet’s 5). As a result, the number of FLOPs is much higher in the convolutional layers in VGG-16.\n",
        "Conv Layers: The computational cost of the convolutional layers dominates in VGG-16, contributing to the majority of FLOPs.\n",
        "FC Layers: Despite having fewer FC layers than AlexNet (only 3 FC layers), the fully connected layers still require substantial FLOPs but are less dominant in the overall computation compared to the convolutional layers.\n",
        "\n",
        "**1.3. Reducing the Computational Cost of Fully Connected Layers**\n",
        "\n",
        "* Global Average Pooling: One common technique to reduce the cost of fully connected layers is to replace them with global average pooling. This significantly reduces the number of parameters by eliminating dense connections.\n",
        "* Low-rank approximations: You can also use low-rank approximations for the weight matrices in the FC layers, reducing the number of multiplications.\n",
        "* Parameter sharing: Similar to convolutional layers, some techniques aim to apply parameter sharing to reduce redundancy in FC layers.\n",
        "* Binarized/Quantized Networks: Using a quantized or binarized network would reduce the memory requirements and computational cost, especially in FC layers, without a large impact on accuracy.\n",
        "\n",
        "**2. Missing Layers in the Displayed Blocks of the Network**\n",
        "\n",
        "In VGG networks, while it’s said that the model has 11 layers (e.g., VGG-16 has 16 layers, VGG-19 has 19 layers), the \"missing\" layers you referred to are typically:\n",
        "\n",
        "* ReLU Activations: Each convolutional layer is followed by a ReLU non-linearity, which counts as a separate layer, but when displaying the network, it’s common to group the convolution and ReLU as a single block.\n",
        "* Pooling Layers: Pooling layers, which are often max-pooling in VGG, are not counted as part of the main 16 or 19 layers, but they play a key role in downsampling the input feature maps.\n",
        "\n",
        "These activations and pooling layers are essential to the model's function but are often grouped with convolutional layers during summary visualization.\n",
        "\n",
        "3. Constructing VGG-16 or VGG-19 from Table 1 (Simonyan and Zisserman, 2014)\n",
        "VGG-16 and VGG-19 architectures can be constructed based on the number of convolutional layers and their arrangement. Here's how you can build them:\n",
        "\n",
        "* VGG-16:\n",
        "\n",
        " * Convolutional layers:\n",
        "  * 2 layers with 64 filters\n",
        "  * 2 layers with 128 filters\n",
        "  * 3 layers with 256 filters\n",
        "  * 3 layers with 512 filters\n",
        "  * 3 layers with 512 filters\n",
        "\n",
        "* Fully connected layers:\n",
        "  * 2 layers with 4096 neurons each\n",
        "  * 1 layer with 1000 output units (for classification)\n",
        "\n",
        "* VGG-19:\n",
        "\n",
        "  * Convolutional layers:\n",
        "   * 2 layers with 64 filters\n",
        "   * 2 layers with 128 filters\n",
        "   * 4 layers with 256 filters\n",
        "   * 4 layers with 512 filters\n",
        "   * 4 layers with 512 filters\n",
        "\n",
        "* Fully connected layers:\n",
        "\n",
        "Same as VGG-16, with 4096 neurons and 1000 output units.\n",
        "Both models use max pooling after blocks of convolutional layers and apply ReLU activation after each convolution.\n",
        "\n",
        "**4. Modifying the Network for Fashion-MNIST with Lower Input Resolutions**\n",
        "\n",
        "Fashion-MNIST images are\n",
        "28\n",
        "×\n",
        "28\n",
        "28×28, and upsampling these images to 224x224 or even 128x128 (as used by VGG) would be computationally wasteful.\n",
        "\n",
        "**Modifying VGG for Smaller Input Resolutions**\n",
        "\n",
        "Instead of upsampling by a large factor, you could modify the network to work with resolutions like 56x56 or 84x84. This can be done by:\n",
        "\n",
        "* Using smaller convolutional kernels (e.g., 3x3 as in the original VGG), but reduce the depth (number of filters) in the convolutional layers, especially in the earlier layers.\n",
        "* Downsample the input gradually using max pooling after several convolutional layers, so the resolution is reduced without losing significant information.\n",
        "* Add more nonlinearities (e.g., more ReLU activations) before downsampling via max-pooling layers to retain information in smaller resolutions.\n",
        "\n",
        "**Example Architecture for 56x56 Input Resolution:**\n",
        "* Convolutional layer (3x3 filters, 32 filters, stride=1, ReLU)\n",
        "* Max-pooling layer (2x2, stride=2)\n",
        "* Convolutional layer (3x3 filters, 64 filters, stride=1, ReLU)\n",
        "* Max-pooling layer (2x2, stride=2)\n",
        "* Fully connected layer (128 neurons, ReLU)\n",
        "* Output layer (10 neurons for classification)\n",
        "\n",
        "This approach keeps the network smaller, reduces computation, and preserves accuracy by retaining key elements of the VGG architecture (small filters and deep layers).\n",
        "\n",
        "**Conclusion:**\n",
        "* AlexNet vs. VGG: VGG is much larger in terms of both parameters and computation, with convolutional layers being the primary source of computational cost. AlexNet, while smaller, has a disproportionate number of parameters in its fully connected layers.\n",
        "* Reducing Fully Connected Layer Cost: You can use global average pooling or low-rank approximations to reduce the parameter count and computational cost of FC layers.\n",
        "* Layer Display in VGG: The three \"missing\" layers are usually ReLU activations or pooling layers that are not always shown in layer count summaries.\n",
        "* VGG Architecture for Fashion-MNIST: Instead of upsampling the input significantly, modify the network to operate at resolutions like 56x56, reducing computational waste while maintaining accuracy by applying more nonlinearities before downsampling."
      ],
      "metadata": {
        "id": "hPkoDlgSz8F4"
      },
      "id": "hPkoDlgSz8F4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "id": "dd565a2f"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/78)\n"
      ],
      "id": "dd565a2f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "4098e4aa"
      },
      "source": [
        "# 8.3. Network in Network (NiN)\n",
        ":label:`sec_nin`\n",
        "\n",
        "LeNet, AlexNet, and VGG all share a common design pattern:\n",
        "extract features exploiting *spatial* structure\n",
        "via a sequence of convolutions and pooling layers\n",
        "and post-process the representations via fully connected layers.\n",
        "The improvements upon LeNet by AlexNet and VGG mainly lie\n",
        "in how these later networks widen and deepen these two modules.\n",
        "\n",
        "This design poses two major challenges.\n",
        "First, the fully connected layers at the end\n",
        "of the architecture consume tremendous numbers of parameters. For instance, even a simple\n",
        "model such as VGG-11 requires a monstrous matrix, occupying almost\n",
        "400MB of RAM in single precision (FP32). This is a significant impediment to computation, in particular on\n",
        "mobile and embedded devices. After all, even high-end mobile phones sport no more than 8GB of RAM. At the time VGG was invented, this was an order of magnitude less (the iPhone 4S had 512MB). As such, it would have been difficult to justify spending the majority of memory on an image classifier.\n",
        "\n",
        "Second, it is equally impossible to add fully connected layers\n",
        "earlier in the network to increase the degree of nonlinearity: doing so would destroy the\n",
        "spatial structure and require potentially even more memory.\n",
        "\n",
        "The *network in network* (*NiN*) blocks :cite:`Lin.Chen.Yan.2013` offer an alternative,\n",
        "capable of solving both problems in one simple strategy.\n",
        "They were proposed based on a very simple insight: (i) use $1 \\times 1$ convolutions to add\n",
        "local nonlinearities across the channel activations and (ii) use global average pooling to integrate\n",
        "across all locations in the last representation layer. Note that global average pooling would not\n",
        "be effective, were it not for the added nonlinearities. Let's dive into this in detail.\n"
      ],
      "id": "4098e4aa"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:01:36.760551Z",
          "iopub.status.busy": "2023-08-18T20:01:36.760234Z",
          "iopub.status.idle": "2023-08-18T20:01:39.896403Z",
          "shell.execute_reply": "2023-08-18T20:01:39.895388Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "d11675e1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "id": "d11675e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "95132206"
      },
      "source": [
        "## 8.3.1. (**NiN Blocks**)\n",
        "\n",
        "Recall :numref:`subsec_1x1`. In it we said that the inputs and outputs of convolutional layers\n",
        "consist of four-dimensional tensors with axes\n",
        "corresponding to the example, channel, height, and width.\n",
        "Also recall that the inputs and outputs of fully connected layers\n",
        "are typically two-dimensional tensors corresponding to the example and feature.\n",
        "The idea behind NiN is to apply a fully connected layer\n",
        "at each pixel location (for each height and width).\n",
        "The resulting $1 \\times 1$ convolution can be thought of as\n",
        "a fully connected layer acting independently on each pixel location.\n",
        "\n",
        ":numref:`fig_nin` illustrates the main structural\n",
        "differences between VGG and NiN, and their blocks.\n",
        "Note both the difference in the NiN blocks (the initial convolution is followed by $1 \\times 1$ convolutions, whereas VGG retains $3 \\times 3$ convolutions) and at the end where we no longer require a giant fully connected layer.\n",
        "\n",
        "![Comparing the architectures of VGG and NiN, and of their blocks.](http://d2l.ai/_images/nin.svg)\n",
        ":width:`600px`\n",
        ":label:`fig_nin`\n"
      ],
      "id": "95132206"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:01:39.901279Z",
          "iopub.status.busy": "2023-08-18T20:01:39.900852Z",
          "iopub.status.idle": "2023-08-18T20:01:39.905954Z",
          "shell.execute_reply": "2023-08-18T20:01:39.905166Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "538cefc3"
      },
      "outputs": [],
      "source": [
        "def nin_block(out_channels, kernel_size, strides, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyConv2d(out_channels, kernel_size, strides, padding), nn.ReLU(),\n",
        "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU(),\n",
        "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU())"
      ],
      "id": "538cefc3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "5c944308"
      },
      "source": [
        "## 8.3.2. [**NiN Model**]\n",
        "\n",
        "NiN uses the same initial convolution sizes as AlexNet (it was proposed shortly thereafter).\n",
        "The kernel sizes are $11\\times 11$, $5\\times 5$, and $3\\times 3$, respectively,\n",
        "and the numbers of output channels match those of AlexNet. Each NiN block is followed by a max-pooling layer\n",
        "with a stride of 2 and a window shape of $3\\times 3$.\n",
        "\n",
        "The second significant difference between NiN and both AlexNet and VGG\n",
        "is that NiN avoids fully connected layers altogether.\n",
        "Instead, NiN uses a NiN block with a number of output channels equal to the number of label classes, followed by a *global* average pooling layer,\n",
        "yielding a vector of logits.\n",
        "This design significantly reduces the number of required model parameters, albeit at the expense of a potential increase in training time.\n"
      ],
      "id": "5c944308"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:01:39.910042Z",
          "iopub.status.busy": "2023-08-18T20:01:39.909747Z",
          "iopub.status.idle": "2023-08-18T20:01:39.916497Z",
          "shell.execute_reply": "2023-08-18T20:01:39.915589Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "200542dc"
      },
      "outputs": [],
      "source": [
        "class NiN(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nin_block(96, kernel_size=11, strides=4, padding=0),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nin_block(256, kernel_size=5, strides=1, padding=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nin_block(384, kernel_size=3, strides=1, padding=1),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(0.5),\n",
        "            nin_block(num_classes, kernel_size=3, strides=1, padding=1),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten())\n",
        "        self.net.apply(d2l.init_cnn)"
      ],
      "id": "200542dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "id": "f7562f54"
      },
      "source": [
        "We create a data example to see [**the output shape of each block**].\n"
      ],
      "id": "f7562f54"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:01:39.919706Z",
          "iopub.status.busy": "2023-08-18T20:01:39.919415Z",
          "iopub.status.idle": "2023-08-18T20:01:40.016875Z",
          "shell.execute_reply": "2023-08-18T20:01:40.015009Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "c0a1fe2c",
        "outputId": "515b18e6-6a6b-4725-d055-f2174b053a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
            "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
            "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
            "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
            "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
            "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
            "Flatten output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "NiN().layer_summary((1, 1, 224, 224))"
      ],
      "id": "c0a1fe2c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 18,
        "id": "b4ac0209"
      },
      "source": [
        "## 8.3.3. [**Training**]\n",
        "\n",
        "As before we use Fashion-MNIST to train the model using the same\n",
        "optimizer that we used for AlexNet and VGG.\n"
      ],
      "id": "b4ac0209"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:01:40.021257Z",
          "iopub.status.busy": "2023-08-18T20:01:40.020900Z",
          "iopub.status.idle": "2023-08-18T20:05:45.250434Z",
          "shell.execute_reply": "2023-08-18T20:05:45.248575Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "111948ca",
        "outputId": "16fb9d9f-ff9a-4924-99b4-d25aa9538177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T04:33:12.712400</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mf9929b5fcf\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mf9929b5fcf\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mf9929b5fcf\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mf9929b5fcf\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mf9929b5fcf\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mf9929b5fcf\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mf9929b5fcf\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m117affade5\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m117affade5\" x=\"30.103125\" y=\"120.399917\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 124.199136) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m117affade5\" x=\"30.103125\" y=\"90.840684\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 94.639902) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m117affade5\" x=\"30.103125\" y=\"61.28145\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 65.080668) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m117affade5\" x=\"30.103125\" y=\"31.722216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 35.521434) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 14.007527 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 14.007527 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 14.007527 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 14.007527 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \nL 200.605438 125.828949 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \nL 200.605438 125.828949 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \nL 205.873125 123.978762 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \nL 200.605438 125.828949 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \nL 205.873125 123.978762 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \nL 205.873125 100.148101 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \nL 200.605438 125.828949 \nL 210.349618 127.053946 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \nL 205.873125 123.978762 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \nL 205.873125 100.148101 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \nL 200.605438 125.828949 \nL 210.349618 127.053946 \nL 220.093797 126.796067 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \nL 205.873125 123.978762 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \nL 205.873125 100.148101 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \nL 200.605438 125.828949 \nL 210.349618 127.053946 \nL 220.093797 126.796067 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \nL 205.873125 123.978762 \nL 225.403125 128.208678 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \nL 205.873125 100.148101 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.815888 \nL 54.442752 15.854987 \nL 64.186931 30.527534 \nL 73.93111 45.85288 \nL 83.675289 79.734092 \nL 93.419468 98.372375 \nL 103.163647 107.136302 \nL 112.907826 111.891449 \nL 122.652006 112.06081 \nL 132.396185 117.729259 \nL 142.140364 119.959786 \nL 151.884543 121.071876 \nL 161.628722 122.216499 \nL 171.372901 123.337457 \nL 181.11708 124.187694 \nL 190.861259 125.25062 \nL 200.605438 125.828949 \nL 210.349618 127.053946 \nL 220.093797 126.796067 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 14.007527 \nL 69.163125 41.628726 \nL 88.693125 95.351946 \nL 108.223125 99.468955 \nL 127.753125 116.893536 \nL 147.283125 119.413524 \nL 166.813125 120.537112 \nL 186.343125 118.98435 \nL 205.873125 123.978762 \nL 225.403125 128.208678 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.531943 \nL 88.693125 113.074419 \nL 108.223125 108.63118 \nL 127.753125 102.808198 \nL 147.283125 102.2411 \nL 166.813125 102.065709 \nL 186.343125 103.088823 \nL 205.873125 100.148101 \nL 225.403125 98.756665 \n\" clip-path=\"url(#p16cb05b67f)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p16cb05b67f\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = NiN(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "id": "111948ca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 21,
        "id": "182ce04f"
      },
      "source": [
        "## 8.3.4. Summary\n",
        "\n",
        "NiN has dramatically fewer parameters than AlexNet and VGG. This stems primarily from the fact that it needs no giant fully connected layers. Instead, it uses global average pooling to aggregate across all image locations after the last stage of the network body. This obviates the need for expensive (learned) reduction operations and replaces them by a simple average. What surprised researchers at the time was the fact that this averaging operation did not harm accuracy. Note that averaging across a low-resolution representation (with many channels) also adds to the amount of translation invariance that the network can handle.\n",
        "\n",
        "Choosing fewer convolutions with wide kernels and replacing them by $1 \\times 1$ convolutions aids the quest for fewer parameters further. It can cater for a significant amount of nonlinearity across channels within any given location. Both $1 \\times 1$ convolutions and global average pooling significantly influenced subsequent CNN designs.\n",
        "\n",
        "\n"
      ],
      "id": "182ce04f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.3.5. Exercises\n",
        "\n",
        "1. Why are there two $1\\times 1$ convolutional layers per NiN block? Increase their number to three. Reduce their number to one. What changes?\n",
        "1. What changes if you replace the $1 \\times 1$ convolutions by $3 \\times 3$ convolutions?\n",
        "1. What happens if you replace the global average pooling by a fully connected layer (speed, accuracy, number of parameters)?\n",
        "1. Calculate the resource usage for NiN.\n",
        "    1. What is the number of parameters?\n",
        "    1. What is the amount of computation?\n",
        "    1. What is the amount of memory needed during training?\n",
        "    1. What is the amount of memory needed during prediction?\n",
        "1. What are possible problems with reducing the $384 \\times 5 \\times 5$ representation to a $10 \\times 5 \\times 5$ representation in one step?\n",
        "1. Use the structural design decisions in VGG that led to VGG-11, VGG-16, and VGG-19 to design a family of NiN-like networks."
      ],
      "metadata": {
        "id": "UqlGdhBV3ZYa"
      },
      "id": "UqlGdhBV3ZYa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "UGdoW7do3aUE"
      },
      "id": "UGdoW7do3aUE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Why are there two 1x1 Convolutional Layers per NiN Block?**\n",
        "\n",
        "NiN (Network in Network) uses 1x1 convolutional layers for several reasons:\n",
        "\n",
        "* Dimensionality Reduction: The 1x1 convolution helps reduce the depth of the feature maps, minimizing the number of channels while retaining the spatial information.\n",
        "* Non-linearity: By adding a second 1x1 layer, you introduce another non-linearity, making the network more expressive and capable of learning complex features.\n",
        "* Interaction Across Channels: 1x1 convolutions enable interactions between different feature channels, which can be beneficial for learning channel-wise patterns.\n",
        "\n",
        "**Increasing to Three 1x1 Convolutions**\n",
        "\n",
        "* Impact: Adding more 1x1 convolutions increases the model’s expressiveness and potentially improves the network's ability to extract features, as more non-linear transformations are applied.\n",
        "* Computation: The computational cost and the number of parameters will increase, as each 1x1 convolution layer adds more weights. However, the increase is not as large as in 3x3 or 5x5 convolutions.\n",
        "* Accuracy: The accuracy may increase slightly, but there's a risk of overfitting if the additional non-linearity is not necessary for the task at hand.\n",
        "Reducing to One 1x1 Convolution\n",
        "* Impact: Reducing the number of 1x1 convolutions would simplify the network and reduce the computational cost. However, the network may lose some expressive power due to fewer non-linear transformations.\n",
        "Computation: The computational load decreases as there are fewer layers.\n",
        "* Accuracy: There might be a slight reduction in accuracy, particularly in more complex tasks, as fewer layers could mean less capacity to learn intricate features.\n",
        "\n",
        "**2. Replacing 1x1 Convolutions with 3x3 Convolutions**\n",
        "\n",
        "* Impact: Replacing 1x1 convolutions with 3x3 convolutions significantly increases the number of parameters and computational cost, as the 3x3 filter operates on a larger spatial region.\n",
        "* Computation: The computational cost will increase dramatically since 3x3 convolutions involve more multiplications per operation. Specifically, the number of FLOPs will be 9 times higher per convolutional operation compared to 1x1.\n",
        "* Accuracy: The accuracy may increase, particularly if the task benefits from larger receptive fields, but it could also lead to overfitting, as more parameters introduce more complexity.\n",
        "* Memory: The memory requirements during both training and inference will increase due to the larger number of filters.\n",
        "\n",
        "**3. Replacing Global Average Pooling with a Fully Connected Layer**\n",
        "\n",
        "* Speed: Fully connected (FC) layers are slower than global average pooling because they introduce significantly more parameters and require more computations (multiplications).\n",
        "* Accuracy: Depending on the task, accuracy may improve slightly with FC layers, as they provide more learnable parameters. However, for tasks where global average pooling suffices, this extra capacity could lead to overfitting.\n",
        "* Number of Parameters: Replacing global average pooling with an FC layer would drastically increase the number of parameters. Global average pooling reduces the feature map to a single value per channel, while a fully connected layer connects every input to every output.\n",
        "* Memory Usage: The memory usage will increase because fully connected layers require more storage for weights and intermediate computations.\n",
        "\n",
        "**4. Resource Usage for NiN**\n",
        "\n",
        "** 4.1. Number of Parameters**\n",
        "The number of parameters in NiN depends on the architecture, specifically the number of channels and the size of the convolutional filters. To compute the number of parameters:\n",
        "\n",
        "* For each convolutional layer: The number of parameters is given by the product of the filter size, the number of input channels, and the number of output channels, plus bias terms.\n",
        "* Example:\n",
        "A 3x3 convolution with 64 input channels and 128 output channels will have\n",
        "3\n",
        "×\n",
        "3\n",
        "×\n",
        "64\n",
        "×\n",
        "128\n",
        "=\n",
        "73\n",
        ",\n",
        "728\n",
        "3×3×64×128=73,728 parameters.\n",
        "A 1x1 convolution with 128 input channels and 256 output channels will have\n",
        "1\n",
        "×\n",
        "1\n",
        "×\n",
        "128\n",
        "×\n",
        "256\n",
        "=\n",
        "32\n",
        ",\n",
        "768\n",
        "1×1×128×256=32,768 parameters.\n",
        "For the entire NiN model, the number of parameters is significantly smaller than architectures like VGG or ResNet due to the use of 1x1 convolutions, which limit parameter growth.\n",
        "\n",
        "**4.2. Amount of Computation (FLOPs)**\n",
        "To calculate the floating-point operations (FLOPs):\n",
        "\n",
        "* For each convolutional layer: The FLOPs can be estimated as\n",
        "(\n",
        "2\n",
        "×\n",
        "filter size\n",
        "×\n",
        "input channels\n",
        "×\n",
        "output channels\n",
        "×\n",
        "output width\n",
        "×\n",
        "output height\n",
        ")\n",
        "(2×filter size×input channels×output channels×output width×output height).\n",
        "The 1x1 convolutions reduce the number of operations compared to 3x3 or 5x5 convolutions.\n",
        "NiN's use of 1x1 convolutions reduces FLOPs significantly, making it more computationally efficient than architectures like VGG, but still requires more FLOPs than simpler architectures like LeNet.\n",
        "\n",
        "**4.3. Memory Needed During Training**\n",
        "During training, memory is required for:\n",
        "\n",
        "* Storing the weights (parameters).\n",
        "* Storing activations from each layer for backpropagation.\n",
        "* Storing gradients.\n",
        "\n",
        "Since NiN uses 1x1 convolutions, the number of parameters is lower than networks like VGG. However, the memory usage also depends on the batch size and input resolution.\n",
        "\n",
        "**4.4. Memory Needed During Prediction**\n",
        "During inference (prediction), memory is needed to store:\n",
        "\n",
        "* The model weights.\n",
        "* The intermediate activations (though typically fewer activations are stored compared to training).\n",
        "* NiN requires less memory during inference than VGG due to fewer parameters, but memory usage will still depend on input size and batch size.\n",
        "\n",
        "**5. Possible Problems with Reducing from 384x5x5 to 10x5x5 in One Step**\n",
        "\n",
        "* Loss of Spatial Information: Reducing the feature maps from 384 channels to 10 in a single step might lead to a loss of important spatial and feature information, affecting accuracy.\n",
        "* Gradual Reduction: A gradual reduction in channels over several layers allows the network to preserve useful information and ensure smooth learning of features at each stage.\n",
        "* Vanishing Gradient: A sudden reduction in feature map depth can also make it harder for gradients to propagate backward effectively during training, potentially causing issues like the vanishing gradient problem.\n",
        "\n",
        "**6. Designing NiN-like Networks Based on VGG Principles**\n",
        "To design a family of NiN-like networks using VGG principles, we can apply the ideas of deep convolutional stacks with small filters (e.g., 3x3 convolutions) while incorporating NiN’s use of 1x1 convolutions for dimension reduction and non-linearity:\n",
        "\n",
        "* NiN-11 (Inspired by VGG-11):\n",
        "  * Use smaller convolutional stacks, with alternating 1x1 convolutions for non-linearity.\n",
        "  * Apply max-pooling after every 2-3 convolutional blocks to gradually reduce spatial dimensions.\n",
        "* Example structure:\n",
        "  * Conv3x3, 64 filters → Conv1x1 → ReLU → Max-Pooling\n",
        "  * Conv3x3, 128 filters → Conv1x1 → ReLU → Max-Pooling\n",
        "  * Conv3x3, 256 filters → Conv1x1 → Conv1x1 → ReLU → Max-Pooling\n",
        "  * Global average pooling → Output\n",
        "* NiN-16 (Inspired by VGG-16):\n",
        "\n",
        "  * A deeper version with more 1x1 convolutional layers, similar to VGG-16’s deeper stacks of 3x3 convolutions.\n",
        "  * More blocks with 3x3 convolutions, followed by 1x1 convolutions to enhance non-linearity.\n",
        "  * This would increase the depth of the network while retaining NiN’s idea of using 1x1 convolutions for expressiveness without adding too many parameters.\n",
        "\n",
        "The use of VGG-style deep architectures with NiN’s 1x1 convolutions ensures that the networks can capture complex features without growing too large in terms of parameters. Additionally, replacing fully connected layers with global average pooling can reduce overfitting, making these networks more efficient for smaller datasets or lower-resolution inputs like Fashion-MNIST."
      ],
      "metadata": {
        "id": "oRIvVYuC3dNz"
      },
      "id": "oRIvVYuC3dNz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "id": "b01b3354"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/80)\n"
      ],
      "id": "b01b3354"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "8979a666"
      },
      "source": [
        "# 8.4. Multi-Branch Networks  (GoogLeNet)\n",
        ":label:`sec_googlenet`\n",
        "\n",
        "In 2014, *GoogLeNet*\n",
        "won the ImageNet Challenge :cite:`Szegedy.Liu.Jia.ea.2015`, using a structure\n",
        "that combined the strengths of NiN :cite:`Lin.Chen.Yan.2013`, repeated blocks :cite:`Simonyan.Zisserman.2014`,\n",
        "and a cocktail of convolution kernels. It was arguably also the first network that exhibited a clear distinction among the stem (data ingest), body (data processing), and head (prediction) in a CNN. This design pattern has persisted ever since in the design of deep networks: the *stem* is given by the first two or three convolutions that operate on the image. They extract low-level features from the underlying images. This is followed by a *body* of convolutional blocks. Finally, the *head* maps the features obtained so far to the required classification, segmentation, detection, or tracking problem at hand.\n",
        "\n",
        "The key contribution in GoogLeNet was the design of the network body. It solved the problem of selecting\n",
        "convolution kernels in an ingenious way. While other works tried to identify which convolution, ranging from $1 \\times 1$ to $11 \\times 11$ would be best, it simply *concatenated* multi-branch convolutions.\n",
        "In what follows we introduce a slightly simplified version of GoogLeNet: the original design included a number of tricks for stabilizing training through intermediate loss functions, applied to multiple layers of the network.\n",
        "They are no longer necessary due to the availability of improved training algorithms.\n"
      ],
      "id": "8979a666"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:43.017176Z",
          "iopub.status.busy": "2023-08-18T20:12:43.016624Z",
          "iopub.status.idle": "2023-08-18T20:12:46.230431Z",
          "shell.execute_reply": "2023-08-18T20:12:46.228850Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "066f8e89"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ],
      "id": "066f8e89"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "fd207136"
      },
      "source": [
        "## 8.4.1. (**Inception Blocks**)\n",
        "\n",
        "The basic convolutional block in GoogLeNet is called an *Inception block*,\n",
        "stemming from the meme \"we need to go deeper\" from the movie *Inception*.\n",
        "\n",
        "![Structure of the Inception block.](http://d2l.ai/_images/inception.svg)\n",
        ":label:`fig_inception`\n",
        "\n",
        "As depicted in :numref:`fig_inception`,\n",
        "the inception block consists of four parallel branches.\n",
        "The first three branches use convolutional layers\n",
        "with window sizes of $1\\times 1$, $3\\times 3$, and $5\\times 5$\n",
        "to extract information from different spatial sizes.\n",
        "The middle two branches also add a $1\\times 1$ convolution of the input\n",
        "to reduce the number of channels, reducing the model's complexity.\n",
        "The fourth branch uses a $3\\times 3$ max-pooling layer,\n",
        "followed by a $1\\times 1$ convolutional layer\n",
        "to change the number of channels.\n",
        "The four branches all use appropriate padding to give the input and output the same height and width.\n",
        "Finally, the outputs along each branch are concatenated\n",
        "along the channel dimension and comprise the block's output.\n",
        "The commonly-tuned hyperparameters of the Inception block\n",
        "are the number of output channels per layer, i.e., how to allocate capacity among convolutions of different size.\n"
      ],
      "id": "fd207136"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.235999Z",
          "iopub.status.busy": "2023-08-18T20:12:46.235477Z",
          "iopub.status.idle": "2023-08-18T20:12:46.245899Z",
          "shell.execute_reply": "2023-08-18T20:12:46.244271Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "7deda9e0"
      },
      "outputs": [],
      "source": [
        "class Inception(nn.Module):\n",
        "    # c1--c4 are the number of output channels for each branch\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super(Inception, self).__init__(**kwargs)\n",
        "        # Branch 1\n",
        "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
        "        # Branch 2\n",
        "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
        "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
        "        # Branch 3\n",
        "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
        "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
        "        # Branch 4\n",
        "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b1 = F.relu(self.b1_1(x))\n",
        "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
        "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
        "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
        "        return torch.cat((b1, b2, b3, b4), dim=1)"
      ],
      "id": "7deda9e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "2a943308"
      },
      "source": [
        "To gain some intuition for why this network works so well,\n",
        "consider the combination of the filters.\n",
        "They explore the image in a variety of filter sizes.\n",
        "This means that details at different extents\n",
        "can be recognized efficiently by filters of different sizes.\n",
        "At the same time, we can allocate different amounts of parameters\n",
        "for different filters.\n",
        "\n",
        "\n",
        "## 8.4.2. [**GoogLeNet Model**]\n",
        "\n",
        "As shown in :numref:`fig_inception_full`, GoogLeNet uses a stack of a total of 9 inception blocks, arranged into three groups with max-pooling in between,\n",
        "and global average pooling in its head to generate its estimates.\n",
        "Max-pooling between inception blocks reduces the dimensionality.\n",
        "At its stem, the first module is similar to AlexNet and LeNet.\n",
        "\n",
        "![The GoogLeNet architecture.](../img/inception-full-90.svg)\n",
        ":label:`fig_inception_full`\n",
        "\n",
        "We can now implement GoogLeNet piece by piece. Let's begin with the stem.\n",
        "The first module uses a 64-channel $7\\times 7$ convolutional layer.\n"
      ],
      "id": "2a943308"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.250221Z",
          "iopub.status.busy": "2023-08-18T20:12:46.249461Z",
          "iopub.status.idle": "2023-08-18T20:12:46.255915Z",
          "shell.execute_reply": "2023-08-18T20:12:46.254721Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "95b8f516"
      },
      "outputs": [],
      "source": [
        "class GoogleNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "id": "95b8f516"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "id": "762e20f9"
      },
      "source": [
        "The second module uses two convolutional layers:\n",
        "first, a 64-channel $1\\times 1$ convolutional layer,\n",
        "followed by a $3\\times 3$ convolutional layer that triples the number of channels. This corresponds to the second branch in the Inception block and concludes the design of the body. At this point we have 192 channels.\n"
      ],
      "id": "762e20f9"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.260637Z",
          "iopub.status.busy": "2023-08-18T20:12:46.259867Z",
          "iopub.status.idle": "2023-08-18T20:12:46.265450Z",
          "shell.execute_reply": "2023-08-18T20:12:46.264324Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "f2f1ae36"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b2(self):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
        "        nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "id": "f2f1ae36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 16,
        "id": "dcc6272e"
      },
      "source": [
        "The third module connects two complete Inception blocks in series.\n",
        "The number of output channels of the first Inception block is\n",
        "$64+128+32+32=256$. This amounts to\n",
        "a ratio of the number of output channels\n",
        "among the four branches of $2:4:1:1$. To achieve this, we first reduce the input\n",
        "dimensions by $\\frac{1}{2}$ and by $\\frac{1}{12}$ in the second and third branch respectively\n",
        "to arrive at $96 = 192/2$ and $16 = 192/12$ channels respectively.\n",
        "\n",
        "The number of output channels of the second Inception block\n",
        "is increased to $128+192+96+64=480$, yielding a ratio of $128:192:96:64 = 4:6:3:2$. As before,\n",
        "we need to reduce the number of intermediate dimensions in the second and third channel. A\n",
        "scale of $\\frac{1}{2}$ and $\\frac{1}{8}$ respectively suffices, yielding $128$ and $32$ channels\n",
        "respectively. This is captured by the arguments of the following `Inception` block constructors.\n"
      ],
      "id": "dcc6272e"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.269744Z",
          "iopub.status.busy": "2023-08-18T20:12:46.269267Z",
          "iopub.status.idle": "2023-08-18T20:12:46.276795Z",
          "shell.execute_reply": "2023-08-18T20:12:46.275528Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "id": "33a37805"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b3(self):\n",
        "    return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
        "                         Inception(128, (128, 192), (32, 96), 64),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "id": "33a37805"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 18,
        "id": "112f5cd2"
      },
      "source": [
        "The fourth module is more complicated.\n",
        "It connects five Inception blocks in series,\n",
        "and they have $192+208+48+64=512$, $160+224+64+64=512$,\n",
        "$128+256+64+64=512$, $112+288+64+64=528$,\n",
        "and $256+320+128+128=832$ output channels, respectively.\n",
        "The number of channels assigned to these branches is similar\n",
        "to that in the third module:\n",
        "the second branch with the $3\\times 3$ convolutional layer\n",
        "outputs the largest number of channels,\n",
        "followed by the first branch with only the $1\\times 1$ convolutional layer,\n",
        "the third branch with the $5\\times 5$ convolutional layer,\n",
        "and the fourth branch with the $3\\times 3$ max-pooling layer.\n",
        "The second and third branches will first reduce\n",
        "the number of channels according to the ratio.\n",
        "These ratios are slightly different in different Inception blocks.\n"
      ],
      "id": "112f5cd2"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.280409Z",
          "iopub.status.busy": "2023-08-18T20:12:46.280085Z",
          "iopub.status.idle": "2023-08-18T20:12:46.288926Z",
          "shell.execute_reply": "2023-08-18T20:12:46.287339Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "2beb4b7a"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b4(self):\n",
        "    return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
        "                         Inception(160, (112, 224), (24, 64), 64),\n",
        "                         Inception(128, (128, 256), (24, 64), 64),\n",
        "                         Inception(112, (144, 288), (32, 64), 64),\n",
        "                         Inception(256, (160, 320), (32, 128), 128),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "id": "2beb4b7a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 20,
        "id": "703d40c6"
      },
      "source": [
        "The fifth module has two Inception blocks with $256+320+128+128=832$\n",
        "and $384+384+128+128=1024$ output channels.\n",
        "The number of channels assigned to each branch\n",
        "is the same as that in the third and fourth modules,\n",
        "but differs in specific values.\n",
        "It should be noted that the fifth block is followed by the output layer.\n",
        "This block uses the global average pooling layer\n",
        "to change the height and width of each channel to 1, just as in NiN.\n",
        "Finally, we turn the output into a two-dimensional array\n",
        "followed by a fully connected layer\n",
        "whose number of outputs is the number of label classes.\n"
      ],
      "id": "703d40c6"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.294877Z",
          "iopub.status.busy": "2023-08-18T20:12:46.293900Z",
          "iopub.status.idle": "2023-08-18T20:12:46.301477Z",
          "shell.execute_reply": "2023-08-18T20:12:46.300150Z"
        },
        "origin_pos": 21,
        "tab": [
          "pytorch"
        ],
        "id": "8b836927"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b5(self):\n",
        "    return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
        "                         Inception(384, (192, 384), (48, 128), 128),\n",
        "                         nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())"
      ],
      "id": "8b836927"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 22,
        "id": "62f89c54"
      },
      "source": [
        "Now that we defined all blocks `b1` through `b5`, it is just a matter of assembling them all into a full network.\n"
      ],
      "id": "62f89c54"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.306521Z",
          "iopub.status.busy": "2023-08-18T20:12:46.305540Z",
          "iopub.status.idle": "2023-08-18T20:12:46.313597Z",
          "shell.execute_reply": "2023-08-18T20:12:46.312191Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "id": "fe47c47d"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def __init__(self, lr=0.1, num_classes=10):\n",
        "    super(GoogleNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                             self.b5(), nn.LazyLinear(num_classes))\n",
        "    self.net.apply(d2l.init_cnn)"
      ],
      "id": "fe47c47d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 24,
        "id": "b94378d8"
      },
      "source": [
        "The GoogLeNet model is computationally complex. Note the large number of\n",
        "relatively arbitrary hyperparameters in terms of the number of channels chosen, the number of blocks prior to dimensionality reduction, the relative partitioning of capacity across channels, etc. Much of it is due to the\n",
        "fact that at the time when GoogLeNet was introduced, automatic tools for network definition or design exploration\n",
        "were not yet available. For instance, by now we take it for granted that a competent deep learning framework is capable of inferring dimensionalities of input tensors automatically. At the time, many such configurations had to be specified explicitly by the experimenter, thus often slowing down active experimentation. Moreover, the tools needed for automatic exploration were still in flux and initial experiments largely amounted to costly brute-force exploration, genetic algorithms, and similar strategies.\n",
        "\n",
        "For now the only modification we will carry out is to\n",
        "[**reduce the input height and width from 224 to 96\n",
        "to have a reasonable training time on Fashion-MNIST.**]\n",
        "This simplifies the computation. Let's have a look at the\n",
        "changes in the shape of the output between the various modules.\n"
      ],
      "id": "b94378d8"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.317969Z",
          "iopub.status.busy": "2023-08-18T20:12:46.316995Z",
          "iopub.status.idle": "2023-08-18T20:12:46.501717Z",
          "shell.execute_reply": "2023-08-18T20:12:46.500827Z"
        },
        "origin_pos": 25,
        "tab": [
          "pytorch"
        ],
        "id": "83b695b7",
        "outputId": "b84c66b0-6099-4476-9886-baa899250da2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 192, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 480, 6, 6])\n",
            "Sequential output shape:\t torch.Size([1, 832, 3, 3])\n",
            "Sequential output shape:\t torch.Size([1, 1024])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "model = GoogleNet().layer_summary((1, 1, 96, 96))"
      ],
      "id": "83b695b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 27,
        "id": "2f3be870"
      },
      "source": [
        "## 8.4.3. [**Training**]\n",
        "\n",
        "As before, we train our model using the Fashion-MNIST dataset.\n",
        " We transform it to $96 \\times 96$ pixel resolution\n",
        " before invoking the training procedure.\n"
      ],
      "id": "2f3be870"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:12:46.505565Z",
          "iopub.status.busy": "2023-08-18T20:12:46.504978Z",
          "iopub.status.idle": "2023-08-18T20:16:06.908422Z",
          "shell.execute_reply": "2023-08-18T20:16:06.907202Z"
        },
        "origin_pos": 28,
        "tab": [
          "pytorch"
        ],
        "id": "d52cffee",
        "outputId": "0bb2850c-f875-47b7-8ef6-2267ff4ca7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T04:44:59.536358</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m0eb558f35d\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m0eb558f35d\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m0eb558f35d\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m0eb558f35d\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m0eb558f35d\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m0eb558f35d\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m0eb558f35d\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"ma96d4534b9\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#ma96d4534b9\" x=\"30.103125\" y=\"120.96238\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 124.761599) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#ma96d4534b9\" x=\"30.103125\" y=\"91.151246\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 94.950465) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#ma96d4534b9\" x=\"30.103125\" y=\"61.340112\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 65.139331) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#ma96d4534b9\" x=\"30.103125\" y=\"31.528978\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 35.328197) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 13.572758 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 13.572758 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 13.572758 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 13.572758 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \nL 200.605438 118.451449 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \nL 200.605438 118.451449 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \nL 205.873125 117.792918 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \nL 200.605438 118.451449 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \nL 205.873125 117.792918 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \nL 205.873125 103.839846 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \nL 200.605438 118.451449 \nL 210.349618 119.683191 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \nL 205.873125 117.792918 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \nL 205.873125 103.839846 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \nL 200.605438 118.451449 \nL 210.349618 119.683191 \nL 220.093797 120.858658 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \nL 205.873125 117.792918 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \nL 205.873125 103.839846 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \nL 200.605438 118.451449 \nL 210.349618 119.683191 \nL 220.093797 120.858658 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \nL 205.873125 117.792918 \nL 225.403125 121.061599 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \nL 205.873125 103.839846 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.541451 \nL 54.442752 13.593373 \nL 64.186931 13.642081 \nL 73.93111 13.723596 \nL 83.675289 13.853322 \nL 93.419468 14.128334 \nL 103.163647 14.859681 \nL 112.907826 18.383699 \nL 122.652006 43.225926 \nL 132.396185 81.875982 \nL 142.140364 96.19344 \nL 151.884543 103.038241 \nL 161.628722 107.620853 \nL 171.372901 111.435174 \nL 181.11708 114.091894 \nL 190.861259 116.030342 \nL 200.605438 118.451449 \nL 210.349618 119.683191 \nL 220.093797 120.858658 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 13.572758 \nL 69.163125 13.684841 \nL 88.693125 13.964935 \nL 108.223125 15.719355 \nL 127.753125 66.631621 \nL 147.283125 90.164085 \nL 166.813125 107.821159 \nL 186.343125 112.455365 \nL 205.873125 117.792918 \nL 225.403125 121.061599 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.654493 \nL 88.693125 132.619147 \nL 108.223125 132.542496 \nL 127.753125 124.718253 \nL 147.283125 116.929387 \nL 166.813125 107.336286 \nL 186.343125 105.962474 \nL 205.873125 103.839846 \nL 225.403125 102.041508 \n\" clip-path=\"url(#p0c0798a3da)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0c0798a3da\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = GoogleNet(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "id": "d52cffee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 30,
        "id": "14eaa685"
      },
      "source": [
        "## 8.4.4. Discussion\n",
        "\n",
        "A key feature of GoogLeNet is that it is actually *cheaper* to compute than its predecessors\n",
        "while simultaneously providing improved accuracy. This marks the beginning of a much more deliberate\n",
        "network design that trades off the cost of evaluating a network with a reduction in errors. It also marks the beginning of experimentation at a block level with network design hyperparameters, even though it was entirely manual at the time. We will revisit this topic in :numref:`sec_cnn-design` when discussing strategies for network structure exploration.\n",
        "\n",
        "Over the following sections we will encounter a number of design choices (e.g., batch normalization, residual connections, and channel grouping) that allow us to improve networks significantly. For now, you can be proud to have implemented what is arguably the first truly modern CNN.\n",
        "\n",
        "\n"
      ],
      "id": "14eaa685"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.4.5. Exercises\n",
        "\n",
        "1. GoogLeNet was so successful that it went through a number of iterations, progressively improving speed and accuracy. Try to implement and run some of them. They include the following:\n",
        "    1.1. Add a batch normalization layer :cite:`Ioffe.Szegedy.2015`, as described later in :numref:`sec_batch_norm`.\n",
        "    1.2. Make adjustments to the Inception block (width, choice and order of convolutions), as described in :citet:`Szegedy.Vanhoucke.Ioffe.ea.2016`.\n",
        "    1.3. Use label smoothing for model regularization, as described in :citet:`Szegedy.Vanhoucke.Ioffe.ea.2016`.\n",
        "    1.4. Make further adjustments to the Inception block by adding residual connection :cite:`Szegedy.Ioffe.Vanhoucke.ea.2017`, as described later in :numref:`sec_resnet`.\n",
        "2. What is the minimum image size needed for GoogLeNet to work?\n",
        "3. Can you design a variant of GoogLeNet that works on Fashion-MNIST's native resolution of $28 \\times 28$ pixels? How would you need to change the stem, the body, and the head of the network, if anything at all?\n",
        "4. Compare the model parameter sizes of AlexNet, VGG, NiN, and GoogLeNet. How do the latter two network\n",
        "   architectures significantly reduce the model parameter size?\n",
        "5. Compare the amount of computation needed in GoogLeNet and AlexNet. How does this affect the design of an accelerator chip, e.g., in terms of memory size, memory bandwidth, cache size, the amount of computation, and the benefit of specialized operations?"
      ],
      "metadata": {
        "id": "N9_LhRFM7K-j"
      },
      "id": "N9_LhRFM7K-j"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "eEAhJEGW7eVi"
      },
      "id": "eEAhJEGW7eVi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Improvements in GoogLeNet**\n",
        "To implement and run the improvements in GoogLeNet, we can outline a series of changes to enhance its performance in terms of speed and accuracy.\n",
        "\n",
        "**1.1. Adding a Batch Normalization Layer**\n",
        "\n",
        "Batch normalization can be added after the convolutions in the Inception blocks. It normalizes the inputs of each layer, which helps in stabilizing and speeding up the training process. Here's a simplified code snippet to demonstrate:"
      ],
      "metadata": {
        "id": "LIeK2HZX7x9n"
      },
      "id": "LIeK2HZX7x9n"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # Add additional branches as needed\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1x1(x)\n",
        "        # Additional branches\n",
        "        return branch1  # Combine branches appropriately\n"
      ],
      "metadata": {
        "id": "C4Kjo-R18BQW"
      },
      "id": "C4Kjo-R18BQW",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2. Adjustments to the Inception Block**\n",
        "\n",
        "Adjusting the width, choice, and order of convolutions can enhance performance. For example, you can replace some 5x5 convolutions with two consecutive 3x3 convolutions, which maintain the receptive field while reducing the number of parameters:"
      ],
      "metadata": {
        "id": "cpJDWhKP8FCd"
      },
      "id": "cpJDWhKP8FCd"
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        self.branch1x1 = nn.Conv2d(in_channels, 64, kernel_size=1)\n",
        "        self.branch3x3_1 = nn.Conv2d(in_channels, 128, kernel_size=1)\n",
        "        self.branch3x3_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        # Additional branches...\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1x1(x)\n",
        "        branch2 = self.branch3x3_1(x)\n",
        "        branch2 = self.branch3x3_2(branch2)\n",
        "        # Combine branches appropriately\n",
        "        return branch1 + branch2  # Or another merging strategy\n"
      ],
      "metadata": {
        "id": "8Z0XE1d68IXJ"
      },
      "id": "8Z0XE1d68IXJ",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3. Using Label Smoothing**\n",
        "\n",
        "Label smoothing helps to regularize the model by softening the target labels. Here’s how to implement it during loss computation:"
      ],
      "metadata": {
        "id": "es681NW78MK1"
      },
      "id": "es681NW78MK1"
    },
    {
      "cell_type": "code",
      "source": [
        "def label_smoothed_nll_loss(lprobs, target, eps):\n",
        "    nll_loss = -lprobs.gather(dim=-1, index=target.unsqueeze(-1)).mean()\n",
        "    smooth_loss = -lprobs.mean(dim=-1).mean()\n",
        "    loss = (1 - eps) * nll_loss + eps * smooth_loss\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "RoV0IBpc8Q8d"
      },
      "id": "RoV0IBpc8Q8d",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4. Adding Residual Connections**\n",
        "\n",
        "Residual connections can be added to the Inception block to facilitate gradient flow and training of deeper networks. This can be achieved by adding the input of the block to its output:\n",
        "\n"
      ],
      "metadata": {
        "id": "zRn93ckv8TB8"
      },
      "id": "zRn93ckv8TB8"
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionBlockWithResidual(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(InceptionBlockWithResidual, self).__init__()\n",
        "        self.branch1x1 = nn.Conv2d(in_channels, 64, kernel_size=1)\n",
        "        # Additional branches...\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # Store the input for residual connection\n",
        "        branch1 = self.branch1x1(x)\n",
        "        # Process other branches...\n",
        "        out = branch1 + residual  # Add the residual connection\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "N1R0VbKq8YKT"
      },
      "id": "N1R0VbKq8YKT",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Minimum Image Size for GoogLeNet**\n",
        "\n",
        "The minimum input image size for GoogLeNet is typically 224x224 pixels. This size ensures that the network's convolutional and pooling layers have sufficient spatial information to extract features effectively. Smaller input sizes may lead to issues like losing significant details and reduced accuracy.\n",
        "\n",
        "**3. Designing a Variant of GoogLeNet for Fashion-MNIST**\n",
        "To adapt GoogLeNet for Fashion-MNIST images of size 28x28 pixels, you would need to make several modifications:\n",
        "\n",
        "* **Stem**: Adjust the initial convolutional layers to account for the smaller input size. You might reduce the number of filters and the size of the convolutional kernel."
      ],
      "metadata": {
        "id": "ARvPdxV_8aj1"
      },
      "id": "ARvPdxV_8aj1"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedStem(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedStem, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)  # Adjust channels and kernel size\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        # Add more layers if needed\n",
        "\n"
      ],
      "metadata": {
        "id": "RA1tzoWS8hEI"
      },
      "id": "RA1tzoWS8hEI",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Body**: Reduce the number of filters in the Inception blocks to maintain a lower parameter count and computational load.\n",
        "\n",
        "* **Head**: Modify the final classification layer to output 10 classes for Fashion-MNIST.\n",
        "\n",
        "**4. Comparing Model Parameter Sizes**\n",
        "\n",
        "* **AlexNet**: ~60 million parameters.\n",
        "* **VGG**:\n",
        "  * VGG-16: ~138 million parameters.\n",
        "  * VGG-19: ~143 million parameters.\n",
        "* **NiN**: ~6 million parameters (significantly smaller than AlexNet and VGG due to its use of 1x1 convolutions).\n",
        "* **GoogLeNet**: ~6.9 million parameters (uses fewer parameters due to the inception module's efficiency).\n",
        "\n",
        "**Parameter Reduction Techniques**\n",
        "\n",
        "* VGG and GoogLeNet utilize small convolutional filters (3x3, 1x1), which reduce the number of parameters compared to larger filters used in AlexNet.\n",
        "* The Inception module in GoogLeNet efficiently combines multiple convolutional paths, enabling the network to learn richer features with fewer parameters.\n",
        "\n",
        "**5. Comparing Computation Needs**\n",
        "\n",
        "* **AlexNet**: Approximately 725 million FLOPs per image.\n",
        "* **GoogLeNet**: Approximately 1.5 billion FLOPs per image due to the use of multiple branches in the Inception modules.\n",
        "\n",
        "**Implications for Accelerator Chip Design**\n",
        "\n",
        "* **Memory Size**: GoogLeNet's higher computation demand necessitates larger on-chip memory to store weights and activations.\n",
        "* **Memory Bandwidth**: Higher computational needs lead to a requirement for greater memory bandwidth, as data needs to be fetched and written back frequently.\n",
        "* **Cache Size**: Efficient caching strategies are crucial to minimize latency due to high memory access.\n",
        "* **Computation**: The computation-heavy nature of GoogLeNet indicates a need for optimized arithmetic operations to improve efficiency.\n",
        "Specialized Operations: Implementing operations that can perform convolutions in parallel (like SIMD) can greatly benefit the architecture, especially for the Inception modules, which can exploit data parallelism effectively.\n",
        "In summary, while GoogLeNet is computationally more demanding than AlexNet, its architectural efficiencies allow it to perform well in practice, necessitating careful consideration in the design of supporting hardware like accelerator chips."
      ],
      "metadata": {
        "id": "_NJLBPJO8lic"
      },
      "id": "_NJLBPJO8lic"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 32,
        "tab": [
          "pytorch"
        ],
        "id": "1f196dce"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/82)\n"
      ],
      "id": "1f196dce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "c8502f85"
      },
      "source": [
        "# 8.5. Batch Normalization\n",
        ":label:`sec_batch_norm`\n",
        "\n",
        "Training deep neural networks is difficult.\n",
        "Getting them to converge in a reasonable amount of time can be tricky.\n",
        "In this section, we describe *batch normalization*, a popular and effective technique\n",
        "that consistently accelerates the convergence of deep networks :cite:`Ioffe.Szegedy.2015`.\n",
        "Together with residual blocks---covered later in :numref:`sec_resnet`---batch normalization\n",
        "has made it possible for practitioners to routinely train networks with over 100 layers.\n",
        "A secondary (serendipitous) benefit of batch normalization lies in its inherent regularization.\n"
      ],
      "id": "c8502f85"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:58:59.890305Z",
          "iopub.status.busy": "2023-08-18T19:58:59.889455Z",
          "iopub.status.idle": "2023-08-18T19:59:03.088529Z",
          "shell.execute_reply": "2023-08-18T19:59:03.087539Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "f7b44765"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "id": "f7b44765"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "85aa6aae"
      },
      "source": [
        "## 8.5.1. Training Deep Networks\n",
        "\n",
        "When working with data, we often preprocess before training.\n",
        "Choices regarding data preprocessing often make an enormous difference in the final results.\n",
        "Recall our application of MLPs to predicting house prices (:numref:`sec_kaggle_house`).\n",
        "Our first step when working with real data\n",
        "was to standardize our input features to have\n",
        "zero mean $\\boldsymbol{\\mu} = 0$ and unit variance $\\boldsymbol{\\Sigma} = \\boldsymbol{1}$ across multiple observations :cite:`friedman1987exploratory`, frequently rescaling the latter so  that the diagonal is unity, i.e., $\\Sigma_{ii} = 1$.\n",
        "Yet another strategy is to rescale vectors to unit length, possibly zero mean *per observation*.\n",
        "This can work well, e.g., for spatial sensor data. These preprocessing techniques and many others, are\n",
        "beneficial for keeping the estimation problem well controlled.\n",
        "For a review of feature selection and extraction see the article of :citet:`guyon2008feature`, for example.\n",
        "Standardizing vectors also has the nice side-effect of constraining the function complexity of functions that act upon it. For instance, the celebrated radius-margin bound :cite:`Vapnik95` in support vector machines and the Perceptron Convergence Theorem :cite:`Novikoff62` rely on inputs of bounded norm.\n",
        "\n",
        "Intuitively, this standardization plays nicely with our optimizers\n",
        "since it puts the parameters *a priori* on a similar scale.\n",
        "As such, it is only natural to ask whether a corresponding normalization step *inside* a deep network\n",
        "might not be beneficial. While this is not quite the reasoning that led to the invention of batch normalization :cite:`Ioffe.Szegedy.2015`, it is a useful way of understanding it and its cousin, layer normalization :cite:`Ba.Kiros.Hinton.2016`, within a unified framework.\n",
        "\n",
        "Second, for a typical MLP or CNN, as we train,\n",
        "the variables\n",
        "in intermediate layers (e.g., affine transformation outputs in MLP)\n",
        "may take values with widely varying magnitudes:\n",
        "whether along the layers from input to output, across units in the same layer,\n",
        "and over time due to our updates to the model parameters.\n",
        "The inventors of batch normalization postulated informally\n",
        "that this drift in the distribution of such variables could hamper the convergence of the network.\n",
        "Intuitively, we might conjecture that if one\n",
        "layer has variable activations that are 100 times that of another layer,\n",
        "this might necessitate compensatory adjustments in the learning rates. Adaptive solvers\n",
        "such as AdaGrad :cite:`Duchi.Hazan.Singer.2011`, Adam :cite:`Kingma.Ba.2014`, Yogi :cite:`Zaheer.Reddi.Sachan.ea.2018`, or Distributed Shampoo :cite:`anil2020scalable` aim to address this from the viewpoint of optimization, e.g., by adding aspects of second-order methods.\n",
        "The alternative is to prevent the problem from occurring, simply by adaptive normalization.\n",
        "\n",
        "Third, deeper networks are complex and tend to be more liable to overfitting.\n",
        "This means that regularization becomes more critical. A common technique for regularization is noise\n",
        "injection. This has been known for a long time, e.g., with regard to noise injection for the\n",
        "inputs :cite:`Bishop.1995`. It also forms the basis of dropout in :numref:`sec_dropout`. As it turns out, quite serendipitously, batch normalization conveys all three benefits: preprocessing, numerical stability, and regularization.\n",
        "\n",
        "Batch normalization is applied to individual layers, or optionally, to all of them:\n",
        "In each training iteration,\n",
        "we first normalize the inputs (of batch normalization)\n",
        "by subtracting their mean and\n",
        "dividing by their standard deviation,\n",
        "where both are estimated based on the statistics of the current minibatch.\n",
        "Next, we apply a scale coefficient and an offset to recover the lost degrees\n",
        "of freedom. It is precisely due to this *normalization* based on *batch* statistics\n",
        "that *batch normalization* derives its name.\n",
        "\n",
        "Note that if we tried to apply batch normalization with minibatches of size 1,\n",
        "we would not be able to learn anything.\n",
        "That is because after subtracting the means,\n",
        "each hidden unit would take value 0.\n",
        "As you might guess, since we are devoting a whole section to batch normalization,\n",
        "with large enough minibatches the approach proves effective and stable.\n",
        "One takeaway here is that when applying batch normalization,\n",
        "the choice of batch size is\n",
        "even more significant than without batch normalization, or at least,\n",
        "suitable calibration is needed as we might adjust batch size.\n",
        "\n",
        "Denote by $\\mathcal{B}$ a minibatch and let $\\mathbf{x} \\in \\mathcal{B}$ be an input to\n",
        "batch normalization ($\\textrm{BN}$). In this case the batch normalization is defined as follows:\n",
        "\n",
        "$$\\textrm{BN}(\\mathbf{x}) = \\boldsymbol{\\gamma} \\odot \\frac{\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_\\mathcal{B}}{\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}} + \\boldsymbol{\\beta}.$$\n",
        ":eqlabel:`eq_batchnorm`\n",
        "\n",
        "In :eqref:`eq_batchnorm`,\n",
        "$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ is the  sample mean\n",
        "and $\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}$ is the sample standard deviation of the minibatch $\\mathcal{B}$.\n",
        "After applying standardization,\n",
        "the resulting minibatch\n",
        "has zero mean and unit variance.\n",
        "The choice of unit variance\n",
        "(rather than some other magic number) is arbitrary. We recover this degree of freedom\n",
        "by including an elementwise\n",
        "*scale parameter* $\\boldsymbol{\\gamma}$ and *shift parameter* $\\boldsymbol{\\beta}$\n",
        "that have the same shape as $\\mathbf{x}$. Both are parameters that\n",
        "need to be learned as part of model training.\n",
        "\n",
        "The variable magnitudes\n",
        "for intermediate layers cannot diverge during training\n",
        "since batch normalization actively centers and rescales them back\n",
        "to a given mean and size (via $\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ and ${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$).\n",
        "Practical experience confirms that, as alluded to when discussing feature rescaling, batch normalization seems to allow for more aggressive learning rates.\n",
        "We calculate $\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ and ${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$ in :eqref:`eq_batchnorm` as follows:\n",
        "\n",
        "$$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B} = \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} \\mathbf{x}\n",
        "\\textrm{ and }\n",
        "\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}^2 = \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} (\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}})^2 + \\epsilon.$$\n",
        "\n",
        "Note that we add a small constant $\\epsilon > 0$\n",
        "to the variance estimate\n",
        "to ensure that we never attempt division by zero,\n",
        "even in cases where the empirical variance estimate might be very small or vanish.\n",
        "The estimates $\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ and ${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$ counteract the scaling issue\n",
        "by using noisy estimates of mean and variance.\n",
        "You might think that this noisiness should be a problem.\n",
        "On the contrary, it is actually beneficial.\n",
        "\n",
        "This turns out to be a recurring theme in deep learning.\n",
        "For reasons that are not yet well-characterized theoretically,\n",
        "various sources of noise in optimization\n",
        "often lead to faster training and less overfitting:\n",
        "this variation appears to act as a form of regularization.\n",
        ":citet:`Teye.Azizpour.Smith.2018` and :citet:`Luo.Wang.Shao.ea.2018`\n",
        "related the properties of batch normalization to Bayesian priors and penalties, respectively.\n",
        "In particular, this sheds some light on the puzzle\n",
        "of why batch normalization works best for moderate minibatch sizes in the 50--100 range.\n",
        "This particular size of minibatch seems to inject just the \"right amount\" of noise per layer, both in terms of scale via $\\hat{\\boldsymbol{\\sigma}}$, and in terms of offset via $\\hat{\\boldsymbol{\\mu}}$: a\n",
        "larger minibatch regularizes less due to the more stable estimates, whereas tiny minibatches\n",
        "destroy useful signal due to high variance. Exploring this direction further, considering alternative types\n",
        "of preprocessing and filtering may yet lead to other effective types of regularization.\n",
        "\n",
        "Fixing a trained model, you might think\n",
        "that we would prefer using the entire dataset\n",
        "to estimate the mean and variance.\n",
        "Once training is complete, why would we want\n",
        "the same image to be classified differently,\n",
        "depending on the batch in which it happens to reside?\n",
        "During training, such exact calculation is infeasible\n",
        "because the intermediate variables\n",
        "for all data examples\n",
        "change every time we update our model.\n",
        "However, once the model is trained,\n",
        "we can calculate the means and variances\n",
        "of each layer's variables based on the entire dataset.\n",
        "Indeed this is standard practice for\n",
        "models employing batch normalization;\n",
        "thus batch normalization layers function differently\n",
        "in *training mode* (normalizing by minibatch statistics)\n",
        "than in *prediction mode* (normalizing by dataset statistics).\n",
        "In this form they closely resemble the behavior of dropout regularization of :numref:`sec_dropout`,\n",
        "where noise is only injected during training.\n",
        "\n",
        "\n"
      ],
      "id": "85aa6aae"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.5.2. Batch Normalization Layers\n",
        "\n",
        "Batch normalization implementations for fully connected layers\n",
        "and convolutional layers are slightly different.\n",
        "One key difference between batch normalization and other layers\n",
        "is that because the former operates on a full minibatch at a time,\n",
        "we cannot just ignore the batch dimension\n",
        "as we did before when introducing other layers.\n",
        "\n"
      ],
      "metadata": {
        "id": "8ygXgrLZQF7x"
      },
      "id": "8ygXgrLZQF7x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.5.2.1. Fully Connected Layers\n",
        "\n",
        "When applying batch normalization to fully connected layers,\n",
        ":citet:`Ioffe.Szegedy.2015`, in their original paper inserted batch normalization after the affine transformation\n",
        "and *before* the nonlinear activation function. Later applications experimented with\n",
        "inserting batch normalization right *after* activation functions.\n",
        "Denoting the input to the fully connected layer by $\\mathbf{x}$,\n",
        "the affine transformation\n",
        "by $\\mathbf{W}\\mathbf{x} + \\mathbf{b}$ (with the weight parameter $\\mathbf{W}$ and the bias parameter $\\mathbf{b}$),\n",
        "and the activation function by $\\phi$,\n",
        "we can express the computation of a batch-normalization-enabled,\n",
        "fully connected layer output $\\mathbf{h}$ as follows:\n",
        "\n",
        "$$\\mathbf{h} = \\phi(\\textrm{BN}(\\mathbf{W}\\mathbf{x} + \\mathbf{b}) ).$$\n",
        "\n",
        "Recall that mean and variance are computed\n",
        "on the *same* minibatch\n",
        "on which the transformation is applied.\n",
        "\n"
      ],
      "metadata": {
        "id": "hl2S22c8QRcd"
      },
      "id": "hl2S22c8QRcd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.5.2.2. Convolutional Layers\n",
        "\n",
        "Similarly, with convolutional layers,\n",
        "we can apply batch normalization after the convolution\n",
        "but before the nonlinear activation function. The key difference from batch normalization\n",
        "in fully connected layers is that we apply the operation on a per-channel basis\n",
        "*across all locations*. This is compatible with our assumption of translation\n",
        "invariance that led to convolutions: we assumed that the specific location of a pattern\n",
        "within an image was not critical for the purpose of understanding.\n",
        "\n",
        "Assume that our minibatches contain $m$ examples\n",
        "and that for each channel,\n",
        "the output of the convolution has height $p$ and width $q$.\n",
        "For convolutional layers, we carry out each batch normalization\n",
        "over the $m \\cdot p \\cdot q$ elements per output channel simultaneously.\n",
        "Thus, we collect the values over all spatial locations\n",
        "when computing the mean and variance\n",
        "and consequently\n",
        "apply the same mean and variance\n",
        "within a given channel\n",
        "to normalize the value at each spatial location.\n",
        "Each channel has its own scale and shift parameters,\n",
        "both of which are scalars.\n",
        "\n"
      ],
      "metadata": {
        "id": "MtaSdVJCQW6t"
      },
      "id": "MtaSdVJCQW6t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.5.2.3. Layer Normalization\n",
        ":label:`subsec_layer-normalization-in-bn`\n",
        "\n",
        "Note that in the context of convolutions the batch normalization is well defined even for\n",
        "minibatches of size 1: after all, we have all the locations across an image to average. Consequently,\n",
        "mean and variance are well defined, even if it is just within a single observation. This consideration\n",
        "led :citet:`Ba.Kiros.Hinton.2016` to introduce the notion of *layer normalization*. It works just like\n",
        "a batch norm, only that it is applied to one observation at a time. Consequently both the offset and the scaling factor are scalars. For an $n$-dimensional vector $\\mathbf{x}$, layer norms are given by\n",
        "\n",
        "$$\\mathbf{x} \\rightarrow \\textrm{LN}(\\mathbf{x}) =  \\frac{\\mathbf{x} - \\hat{\\mu}}{\\hat\\sigma},$$\n",
        "\n",
        "where scaling and offset are applied coefficient-wise\n",
        "and given by\n",
        "\n",
        "$$\\hat{\\mu} \\stackrel{\\textrm{def}}{=} \\frac{1}{n} \\sum_{i=1}^n x_i \\textrm{ and }\n",
        "\\hat{\\sigma}^2 \\stackrel{\\textrm{def}}{=} \\frac{1}{n} \\sum_{i=1}^n (x_i - \\hat{\\mu})^2 + \\epsilon.$$\n",
        "\n",
        "As before we add a small offset $\\epsilon > 0$ to prevent division by zero. One of the major benefits of using layer normalization is that it prevents divergence. After all, ignoring $\\epsilon$, the output of the layer normalization is scale independent. That is, we have $\\textrm{LN}(\\mathbf{x}) \\approx \\textrm{LN}(\\alpha \\mathbf{x})$ for any choice of $\\alpha \\neq 0$. This becomes an equality for $|\\alpha| \\to \\infty$ (the approximate equality is due to the offset $\\epsilon$ for the variance).\n",
        "\n",
        "Another advantage of the layer normalization is that it does not depend on the minibatch size. It is also independent of whether we are in training or test regime. In other words, it is simply a deterministic transformation that standardizes the activations to a given scale. This can be very beneficial in preventing divergence in optimization. We skip further details and recommend that interested readers consult the original paper.\n",
        "\n",
        "### 8.5.2.4. Batch Normalization During Prediction\n",
        "\n",
        "As we mentioned earlier, batch normalization typically behaves differently\n",
        "in training mode than in prediction mode.\n",
        "First, the noise in the sample mean and the sample variance\n",
        "arising from estimating each on minibatches\n",
        "is no longer desirable once we have trained the model.\n",
        "Second, we might not have the luxury\n",
        "of computing per-batch normalization statistics.\n",
        "For example,\n",
        "we might need to apply our model to make one prediction at a time.\n",
        "\n",
        "Typically, after training, we use the entire dataset\n",
        "to compute stable estimates of the variable statistics\n",
        "and then fix them at prediction time.\n",
        "Hence, batch normalization behaves differently during training than at test time.\n",
        "Recall that dropout also exhibits this characteristic.\n",
        "\n"
      ],
      "metadata": {
        "id": "dcCJaFDEQgvH"
      },
      "id": "dcCJaFDEQgvH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.5.3. (**Implementation from Scratch**)\n",
        "\n",
        "To see how batch normalization works in practice, we implement one from scratch below.\n"
      ],
      "metadata": {
        "id": "tGZLS69dRmqU"
      },
      "id": "tGZLS69dRmqU"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:59:03.092523Z",
          "iopub.status.busy": "2023-08-18T19:59:03.092120Z",
          "iopub.status.idle": "2023-08-18T19:59:03.100348Z",
          "shell.execute_reply": "2023-08-18T19:59:03.099493Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "9a79b8f2"
      },
      "outputs": [],
      "source": [
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
        "    # Use is_grad_enabled to determine whether we are in training mode\n",
        "    if not torch.is_grad_enabled():\n",
        "        # In prediction mode, use mean and variance obtained by moving average\n",
        "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "    else:\n",
        "        assert len(X.shape) in (2, 4)\n",
        "        if len(X.shape) == 2:\n",
        "            # When using a fully connected layer, calculate the mean and\n",
        "            # variance on the feature dimension\n",
        "            mean = X.mean(dim=0)\n",
        "            var = ((X - mean) ** 2).mean(dim=0)\n",
        "        else:\n",
        "            # When using a two-dimensional convolutional layer, calculate the\n",
        "            # mean and variance on the channel dimension (axis=1). Here we\n",
        "            # need to maintain the shape of X, so that the broadcasting\n",
        "            # operation can be carried out later\n",
        "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "        # In training mode, the current mean and variance are used\n",
        "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
        "        # Update the mean and variance using moving average\n",
        "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
        "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
        "    Y = gamma * X_hat + beta  # Scale and shift\n",
        "    return Y, moving_mean.data, moving_var.data"
      ],
      "id": "9a79b8f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "49370dea"
      },
      "source": [
        "We can now [**create a proper `BatchNorm` layer.**]\n",
        "Our layer will maintain proper parameters\n",
        "for scale `gamma` and shift `beta`,\n",
        "both of which will be updated in the course of training.\n",
        "Additionally, our layer will maintain\n",
        "moving averages of the means and variances\n",
        "for subsequent use during model prediction.\n",
        "\n",
        "Putting aside the algorithmic details,\n",
        "note the design pattern underlying our implementation of the layer.\n",
        "Typically, we define the mathematics in a separate function, say `batch_norm`.\n",
        "We then integrate this functionality into a custom layer,\n",
        "whose code mostly addresses bookkeeping matters,\n",
        "such as moving data to the right device context,\n",
        "allocating and initializing any required variables,\n",
        "keeping track of moving averages (here for mean and variance), and so on.\n",
        "This pattern enables a clean separation of mathematics from boilerplate code.\n",
        "Also note that for the sake of convenience\n",
        "we did not worry about automatically inferring the input shape here;\n",
        "thus we need to specify the number of features throughout.\n",
        "By now all modern deep learning frameworks offer automatic detection of size and shape in the\n",
        "high-level batch normalization APIs (in practice we will use this instead).\n"
      ],
      "id": "49370dea"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:59:03.103959Z",
          "iopub.status.busy": "2023-08-18T19:59:03.103597Z",
          "iopub.status.idle": "2023-08-18T19:59:03.113624Z",
          "shell.execute_reply": "2023-08-18T19:59:03.112645Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "8a591dd1"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(nn.Module):\n",
        "    # num_features: the number of outputs for a fully connected layer or the\n",
        "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "    # fully connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # The variables that are not model parameters are initialized to 0 and\n",
        "        # 1\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "        # the device where X is located\n",
        "        if self.moving_mean.device != X.device:\n",
        "            self.moving_mean = self.moving_mean.to(X.device)\n",
        "            self.moving_var = self.moving_var.to(X.device)\n",
        "        # Save the updated moving_mean and moving_var\n",
        "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
        "            X, self.gamma, self.beta, self.moving_mean,\n",
        "            self.moving_var, eps=1e-5, momentum=0.1)\n",
        "        return Y"
      ],
      "id": "8a591dd1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 16,
        "id": "7e8bc89f"
      },
      "source": [
        "We used `momentum` to govern the aggregation over past mean and variance estimates. This is somewhat of a misnomer as it has nothing whatsoever to do with the *momentum* term of optimization. Nonetheless, it is the commonly adopted name for this term and in deference to API naming convention we use the same variable name in our code.\n",
        "\n",
        "## 8.5.4. [**LeNet with Batch Normalization**]\n",
        "\n",
        "To see how to apply `BatchNorm` in context,\n",
        "below we apply it to a traditional LeNet model (:numref:`sec_lenet`).\n",
        "Recall that batch normalization is applied\n",
        "after the convolutional layers or fully connected layers\n",
        "but before the corresponding activation functions.\n"
      ],
      "id": "7e8bc89f"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:59:03.118112Z",
          "iopub.status.busy": "2023-08-18T19:59:03.117737Z",
          "iopub.status.idle": "2023-08-18T19:59:03.124711Z",
          "shell.execute_reply": "2023-08-18T19:59:03.123881Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "id": "21c51c36"
      },
      "outputs": [],
      "source": [
        "class BNLeNetScratch(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), BatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), BatchNorm(16, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120),\n",
        "            BatchNorm(120, num_dims=2), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "            BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))"
      ],
      "id": "21c51c36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 21,
        "id": "e842386f"
      },
      "source": [
        "As before, we will [**train our network on the Fashion-MNIST dataset**].\n",
        "This code is virtually identical to that when we first trained LeNet.\n"
      ],
      "id": "e842386f"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:59:03.127886Z",
          "iopub.status.busy": "2023-08-18T19:59:03.127595Z",
          "iopub.status.idle": "2023-08-18T20:00:16.870229Z",
          "shell.execute_reply": "2023-08-18T20:00:16.869283Z"
        },
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "064cdd64",
        "outputId": "7df366d6-be49-4392-f556-ba8d04be80f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T06:23:05.252687</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m5d2514332e\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5d2514332e\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m5d2514332e\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m5d2514332e\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m5d2514332e\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m5d2514332e\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m5d2514332e\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m5e105c877f\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5e105c877f\" x=\"30.103125\" y=\"121.267983\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 125.067202) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m5e105c877f\" x=\"30.103125\" y=\"81.241269\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 85.040488) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m5e105c877f\" x=\"30.103125\" y=\"41.214555\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 45.013774) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 49.633125 82.774309 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_14\"/>\n   <g id=\"line2d_15\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 49.633125 82.774309 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 41.919139 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 49.633125 82.774309 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 41.919139 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 49.633125 82.774309 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 41.919139 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 41.919139 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \nL 200.605438 137.232319 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \nL 200.605438 137.232319 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \nL 205.873125 117.167757 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \nL 200.605438 137.232319 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \nL 205.873125 117.167757 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \nL 205.873125 30.91496 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \nL 200.605438 137.232319 \nL 210.349618 138.186995 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \nL 205.873125 117.167757 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \nL 205.873125 30.91496 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \nL 200.605438 137.232319 \nL 210.349618 138.186995 \nL 220.093797 139.5 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \nL 205.873125 117.167757 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \nL 205.873125 30.91496 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \nL 200.605438 137.232319 \nL 210.349618 138.186995 \nL 220.093797 139.5 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \nL 205.873125 117.167757 \nL 225.403125 119.874084 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \nL 205.873125 30.91496 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 80.93634 \nL 54.442752 96.311498 \nL 64.186931 104.923296 \nL 73.93111 112.564732 \nL 83.675289 113.978042 \nL 93.419468 120.690958 \nL 103.163647 120.900824 \nL 112.907826 124.454748 \nL 122.652006 126.439387 \nL 132.396185 129.299161 \nL 142.140364 129.740267 \nL 151.884543 131.07331 \nL 161.628722 133.348808 \nL 171.372901 134.300451 \nL 181.11708 134.924982 \nL 190.861259 136.306951 \nL 200.605438 137.232319 \nL 210.349618 138.186995 \nL 220.093797 139.5 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 49.633125 82.774309 \nL 69.163125 98.325647 \nL 88.693125 55.180617 \nL 108.223125 101.870904 \nL 127.753125 91.798658 \nL 147.283125 118.734817 \nL 166.813125 122.302493 \nL 186.343125 107.131593 \nL 205.873125 117.167757 \nL 225.403125 119.874084 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 41.919139 \nL 69.163125 36.397258 \nL 88.693125 51.716026 \nL 108.223125 35.823299 \nL 127.753125 41.998306 \nL 147.283125 30.677459 \nL 166.813125 29.311833 \nL 186.343125 37.762884 \nL 205.873125 30.91496 \nL 225.403125 31.548294 \n\" clip-path=\"url(#p60b3f4bb0a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 100.434375 \nL 218.403125 100.434375 \nQ 220.403125 100.434375 220.403125 98.434375 \nL 220.403125 54.565625 \nQ 220.403125 52.565625 218.403125 52.565625 \nL 138.8125 52.565625 \nQ 136.8125 52.565625 136.8125 54.565625 \nL 136.8125 98.434375 \nQ 136.8125 100.434375 138.8125 100.434375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_126\">\n     <path d=\"M 140.8125 60.664063 \nL 150.8125 60.664063 \nL 160.8125 60.664063 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 64.164063) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 75.620313 \nL 150.8125 75.620313 \nL 160.8125 75.620313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 79.120313) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 90.576563 \nL 150.8125 90.576563 \nL 160.8125 90.576563 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 94.076563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p60b3f4bb0a\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "model = BNLeNetScratch(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "id": "064cdd64"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 24,
        "id": "27eb3037"
      },
      "source": [
        "Let's [**have a look at the scale parameter `gamma`\n",
        "and the shift parameter `beta`**] learned\n",
        "from the first batch normalization layer.\n"
      ],
      "id": "27eb3037"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:00:16.875213Z",
          "iopub.status.busy": "2023-08-18T20:00:16.874610Z",
          "iopub.status.idle": "2023-08-18T20:00:16.971921Z",
          "shell.execute_reply": "2023-08-18T20:00:16.970745Z"
        },
        "origin_pos": 26,
        "tab": [
          "pytorch"
        ],
        "id": "4969fdc2",
        "outputId": "7f557617-b01c-4197-be38-a47f2416ec0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.4083, 2.1084, 2.0874, 1.9650, 1.4157, 1.8314],\n",
              "        grad_fn=<ViewBackward0>),\n",
              " tensor([-0.0254,  0.2018,  1.7383,  0.5730, -0.4490, -0.9677],\n",
              "        grad_fn=<ViewBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.net[1].gamma.reshape((-1,)), model.net[1].beta.reshape((-1,))"
      ],
      "id": "4969fdc2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 29,
        "id": "6befcbce"
      },
      "source": [
        "## 8.5.5. [**Concise Implementation**]\n",
        "\n",
        "Compared with the `BatchNorm` class,\n",
        "which we just defined ourselves,\n",
        "we can use the `BatchNorm` class defined in high-level APIs from the deep learning framework directly.\n",
        "The code looks virtually identical\n",
        "to our implementation above, except that we no longer need to provide additional arguments for it to get the dimensions right.\n"
      ],
      "id": "6befcbce"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:00:16.975625Z",
          "iopub.status.busy": "2023-08-18T20:00:16.975018Z",
          "iopub.status.idle": "2023-08-18T20:00:16.981373Z",
          "shell.execute_reply": "2023-08-18T20:00:16.980550Z"
        },
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "id": "ef2ab147"
      },
      "outputs": [],
      "source": [
        "class BNLeNet(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
        "            nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
        "            nn.Sigmoid(), nn.LazyLinear(num_classes))"
      ],
      "id": "ef2ab147"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 32,
        "id": "75bb4f92"
      },
      "source": [
        "Below, we [**use the same hyperparameters to train our model.**]\n",
        "Note that as usual, the high-level API variant runs much faster\n",
        "because its code has been compiled to C++ or CUDA\n",
        "while our custom implementation must be interpreted by Python.\n"
      ],
      "id": "75bb4f92"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:00:16.984898Z",
          "iopub.status.busy": "2023-08-18T20:00:16.984364Z",
          "iopub.status.idle": "2023-08-18T20:01:21.082406Z",
          "shell.execute_reply": "2023-08-18T20:01:21.081474Z"
        },
        "origin_pos": 33,
        "tab": [
          "pytorch"
        ],
        "id": "0d6aaf49",
        "outputId": "9a21df5b-2503-4c95-c037-a3249aafc53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"186.416227pt\" viewBox=\"0 0 238.965625 186.416227\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T06:35:04.219806</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 186.416227 \nL 238.965625 186.416227 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 148.859977 \nL 225.403125 148.859977 \nL 225.403125 10.259977 \nL 30.103125 10.259977 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"maa29bf2082\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#maa29bf2082\" x=\"30.103125\" y=\"148.859977\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 163.458414) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#maa29bf2082\" x=\"69.163125\" y=\"148.859977\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 163.458414) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#maa29bf2082\" x=\"108.223125\" y=\"148.859977\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 163.458414) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#maa29bf2082\" x=\"147.283125\" y=\"148.859977\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 163.458414) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#maa29bf2082\" x=\"186.343125\" y=\"148.859977\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 163.458414) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#maa29bf2082\" x=\"225.403125\" y=\"148.859977\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 163.458414) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 177.136539) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"mdffd1ac2ea\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mdffd1ac2ea\" x=\"30.103125\" y=\"123.970839\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 127.770058) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mdffd1ac2ea\" x=\"30.103125\" y=\"86.313632\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 90.112851) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mdffd1ac2ea\" x=\"30.103125\" y=\"48.656426\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 52.455644) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mdffd1ac2ea\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 14.798438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 16.559977 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 89.457009 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 89.457009 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 48.313816 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 89.457009 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 48.313816 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 89.457009 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 48.313816 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 48.313816 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \nL 200.605438 139.7137 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \nL 200.605438 139.7137 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \nL 205.873125 133.192103 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \nL 200.605438 139.7137 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \nL 205.873125 133.192103 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \nL 205.873125 35.056335 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \nL 200.605438 139.7137 \nL 210.349618 142.559977 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \nL 205.873125 133.192103 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \nL 205.873125 35.056335 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \nL 200.605438 139.7137 \nL 210.349618 142.559977 \nL 220.093797 141.314098 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \nL 205.873125 133.192103 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \nL 205.873125 35.056335 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \nL 200.605438 139.7137 \nL 210.349618 142.559977 \nL 220.093797 141.314098 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \nL 205.873125 133.192103 \nL 225.403125 132.417524 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \nL 205.873125 35.056335 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 16.559977 \nL 44.698573 85.102888 \nL 54.442752 101.172919 \nL 64.186931 108.078265 \nL 73.93111 115.037774 \nL 83.675289 118.386562 \nL 93.419468 122.886873 \nL 103.163647 123.899554 \nL 112.907826 127.30404 \nL 122.652006 129.349849 \nL 132.396185 132.107095 \nL 142.140364 132.067375 \nL 151.884543 135.577962 \nL 161.628722 134.792203 \nL 171.372901 137.620311 \nL 181.11708 137.413537 \nL 190.861259 140.160809 \nL 200.605438 139.7137 \nL 210.349618 142.559977 \nL 220.093797 141.314098 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 89.457009 \nL 69.163125 103.881158 \nL 88.693125 113.589261 \nL 108.223125 101.365487 \nL 127.753125 122.331473 \nL 147.283125 123.505738 \nL 166.813125 115.118642 \nL 186.343125 131.078139 \nL 205.873125 133.192103 \nL 225.403125 132.417524 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 48.313816 \nL 69.163125 44.329124 \nL 88.693125 41.294054 \nL 108.223125 45.800109 \nL 127.753125 38.165884 \nL 147.283125 38.668626 \nL 166.813125 41.517495 \nL 186.343125 36.043198 \nL 205.873125 35.056335 \nL 225.403125 35.745277 \n\" clip-path=\"url(#p1e789ab1b4)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 148.859977 \nL 30.103125 10.259977 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 148.859977 \nL 225.403125 10.259977 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 148.859977 \nL 225.403125 148.859977 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 10.259977 \nL 225.403125 10.259977 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 103.494352 \nL 218.403125 103.494352 \nQ 220.403125 103.494352 220.403125 101.494352 \nL 220.403125 57.625602 \nQ 220.403125 55.625602 218.403125 55.625602 \nL 138.8125 55.625602 \nQ 136.8125 55.625602 136.8125 57.625602 \nL 136.8125 101.494352 \nQ 136.8125 103.494352 138.8125 103.494352 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 63.724039 \nL 150.8125 63.724039 \nL 160.8125 63.724039 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 67.224039) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 78.680289 \nL 150.8125 78.680289 \nL 160.8125 78.680289 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 82.180289) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 93.636539 \nL 150.8125 93.636539 \nL 160.8125 93.636539 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 97.136539) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1e789ab1b4\">\n   <rect x=\"30.103125\" y=\"10.259977\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "model = BNLeNet(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "id": "0d6aaf49"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 35,
        "id": "353f1805"
      },
      "source": [
        "## 8.5.6. Discussion\n",
        "\n",
        "Intuitively, batch normalization is thought\n",
        "to make the optimization landscape smoother.\n",
        "However, we must be careful to distinguish between\n",
        "speculative intuitions and true explanations\n",
        "for the phenomena that we observe when training deep models.\n",
        "Recall that we do not even know why simpler\n",
        "deep neural networks (MLPs and conventional CNNs)\n",
        "generalize well in the first place.\n",
        "Even with dropout and weight decay,\n",
        "they remain so flexible that their ability to generalize to unseen data\n",
        "likely needs significantly more refined learning-theoretic generalization guarantees.\n",
        "\n",
        "The original paper proposing batch normalization :cite:`Ioffe.Szegedy.2015`, in addition to introducing a powerful and useful tool,\n",
        "offered an explanation for why it works:\n",
        "by reducing *internal covariate shift*.\n",
        "Presumably by *internal covariate shift* they\n",
        "meant something like the intuition expressed above---the\n",
        "notion that the distribution of variable values changes\n",
        "over the course of training.\n",
        "However, there were two problems with this explanation:\n",
        "i) This drift is very different from *covariate shift*,\n",
        "rendering the name a misnomer. If anything, it is closer to concept drift.\n",
        "ii) The explanation offers an under-specified intuition\n",
        "but leaves the question of *why precisely this technique works*\n",
        "an open question wanting for a rigorous explanation.\n",
        "Throughout this book, we aim to convey the intuitions that practitioners\n",
        "use to guide their development of deep neural networks.\n",
        "However, we believe that it is important\n",
        "to separate these guiding intuitions\n",
        "from established scientific fact.\n",
        "Eventually, when you master this material\n",
        "and start writing your own research papers\n",
        "you will want to be clear to delineate\n",
        "between technical claims and hunches.\n",
        "\n",
        "Following the success of batch normalization,\n",
        "its explanation in terms of *internal covariate shift*\n",
        "has repeatedly surfaced in debates in the technical literature\n",
        "and broader discourse about how to present machine learning research.\n",
        "In a memorable speech given while accepting a Test of Time Award\n",
        "at the 2017 NeurIPS conference,\n",
        "Ali Rahimi used *internal covariate shift*\n",
        "as a focal point in an argument likening\n",
        "the modern practice of deep learning to alchemy.\n",
        "Subsequently, the example was revisited in detail\n",
        "in a position paper outlining\n",
        "troubling trends in machine learning :cite:`Lipton.Steinhardt.2018`.\n",
        "Other authors\n",
        "have proposed alternative explanations for the success of batch normalization,\n",
        "some :cite:`Santurkar.Tsipras.Ilyas.ea.2018`\n",
        "claiming that batch normalization's success comes despite exhibiting behavior\n",
        "that is in some ways opposite to those claimed in the original paper.\n",
        "\n",
        "\n",
        "We note that the *internal covariate shift*\n",
        "is no more worthy of criticism than any of\n",
        "thousands of similarly vague claims\n",
        "made every year in the technical machine learning literature.\n",
        "Likely, its resonance as a focal point of these debates\n",
        "owes to its broad recognizability for the target audience.\n",
        "Batch normalization has proven an indispensable method,\n",
        "applied in nearly all deployed image classifiers,\n",
        "earning the paper that introduced the technique\n",
        "tens of thousands of citations. We conjecture, though, that the guiding principles\n",
        "of regularization through noise injection, acceleration through rescaling and lastly preprocessing\n",
        "may well lead to further inventions of layers and techniques in the future.\n",
        "\n",
        "On a more practical note, there are a number of aspects worth remembering about batch normalization:\n",
        "\n",
        "* During model training, batch normalization continuously adjusts the intermediate output of\n",
        "  the network by utilizing the mean and standard deviation of the minibatch, so that the\n",
        "  values of the intermediate output in each layer throughout the neural network are more stable.\n",
        "* Batch normalization is slightly different for fully connected layers than for convolutional layers. In fact,\n",
        "  for convolutional layers, layer normalization can sometimes be used as an alternative.\n",
        "* Like a dropout layer, batch normalization layers have different behaviors\n",
        "  in training mode than in prediction mode.\n",
        "* Batch normalization is useful for regularization and improving convergence in optimization. By contrast,\n",
        "  the original motivation of reducing internal covariate shift seems not to be a valid explanation.\n",
        "* For more robust models that are less sensitive to input perturbations, consider removing batch normalization :cite:`wang2022removing`.\n",
        "\n"
      ],
      "id": "353f1805"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.5.7. Exercises\n",
        "\n",
        "1. Should we remove the bias parameter from the fully connected layer or the convolutional layer before the batch normalization? Why?\n",
        "2. Compare the learning rates for LeNet with and without batch normalization.\n",
        "\n",
        "   2.1. Plot the increase in validation accuracy.\n",
        "\n",
        "   2.2. How large can you make the learning rate before the optimization fails in both cases?\n",
        "3. Do we need batch normalization in every layer? Experiment with it.\n",
        "4. Implement a \"lite\" version of batch normalization that only removes the mean, or alternatively one that\n",
        "   only removes the variance. How does it behave?\n",
        "5. Fix the parameters `beta` and `gamma`. Observe and analyze the results.\n",
        "6. Can you replace dropout by batch normalization? How does the behavior change?\n",
        "7. Research ideas: think of other normalization transforms that you can apply:\n",
        "\n",
        "   7.1. Can you apply the probability integral transform?\n",
        "\n",
        "   7.2. Can you use a full-rank covariance estimate? Why should you probably not do that?\n",
        "\n",
        "   7.3. Can you use other compact matrix variants (block-diagonal,\n",
        "   low-displacement rank, Monarch, etc.)?\n",
        "\n",
        "   7.4. Does a sparsification compression act as a regularizer?\n",
        "   \n",
        "   7.5. Are there other projections (e.g., convex cone, symmetry group-specific transforms) that you can use?\n"
      ],
      "metadata": {
        "id": "q-MX7xi3S4zv"
      },
      "id": "q-MX7xi3S4zv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "ugq1mZVQUaik"
      },
      "id": "ugq1mZVQUaik"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Removing the Bias Parameter**\n",
        "\n",
        "You should remove the bias parameter from the convolutional layer before the batch normalization. This is because batch normalization is designed to shift the activation to have a mean of zero and scale it to have a standard deviation of one. If a bias term is present, it can interfere with the normalization process, as the bias will shift the mean away from zero, negating the benefits of batch normalization.\n",
        "\n",
        "**2. Learning Rates for LeNet with and without Batch Normalization**\n",
        "\n",
        "Batch normalization can significantly influence the choice of learning rates during training.\n",
        "\n",
        "**2.1. Plot the Increase in Validation Accuracy**\n",
        "\n",
        "You can implement training of LeNet both with and without batch normalization, and track the validation accuracy over epochs. Here’s a sample implementation to generate the plot:"
      ],
      "metadata": {
        "id": "wD0Uum7HUccn"
      },
      "id": "wD0Uum7HUccn"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have validation accuracy lists\n",
        "accuracy_with_bn = [0.5, 0.7, 0.8, 0.85]  # Example data\n",
        "accuracy_without_bn = [0.5, 0.65, 0.75, 0.80]  # Example data\n",
        "epochs = range(1, len(accuracy_with_bn) + 1)\n",
        "\n",
        "plt.plot(epochs, accuracy_with_bn, label='With Batch Norm')\n",
        "plt.plot(epochs, accuracy_without_bn, label='Without Batch Norm')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Validation Accuracy: LeNet with vs. without Batch Normalization')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Pw3ncu4IUheJ",
        "outputId": "f8bb43de-25fc-43cb-8850-34e0adea512d"
      },
      "id": "Pw3ncu4IUheJ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"428.1325pt\" height=\"325.986375pt\" viewBox=\"0 0 428.1325 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T06:36:54.590041</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 428.1325 325.986375 \nL 428.1325 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 288.430125 \nL 407.26375 288.430125 \nL 407.26375 22.318125 \nL 50.14375 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mb550702eeb\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb550702eeb\" x=\"66.376477\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <g transform=\"translate(58.424915 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mb550702eeb\" x=\"120.485568\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <g transform=\"translate(112.534006 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mb550702eeb\" x=\"174.594659\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <g transform=\"translate(166.643097 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mb550702eeb\" x=\"228.70375\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(220.752187 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mb550702eeb\" x=\"282.812841\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <g transform=\"translate(274.861278 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mb550702eeb\" x=\"336.921932\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(328.970369 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#mb550702eeb\" x=\"391.031023\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <g transform=\"translate(383.07946 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Epochs -->\n     <g transform=\"translate(210.788125 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"m6d6fb6056d\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"276.334125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.50 -->\n      <g transform=\"translate(20.878125 280.133344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"241.774125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.55 -->\n      <g transform=\"translate(20.878125 245.573344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"207.214125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.60 -->\n      <g transform=\"translate(20.878125 211.013344) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"172.654125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.65 -->\n      <g transform=\"translate(20.878125 176.453344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"138.094125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.70 -->\n      <g transform=\"translate(20.878125 141.893344) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"103.534125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.75 -->\n      <g transform=\"translate(20.878125 107.333344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"68.974125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.80 -->\n      <g transform=\"translate(20.878125 72.773344) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m6d6fb6056d\" x=\"50.14375\" y=\"34.414125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.85 -->\n      <g transform=\"translate(20.878125 38.213344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Validation Accuracy -->\n     <g transform=\"translate(14.798438 204.481937) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-56\" d=\"M 1831 0 \nL 50 4666 \nL 709 4666 \nL 2188 738 \nL 3669 4666 \nL 4325 4666 \nL 2547 0 \nL 1831 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"177.503906\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"240.980469\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"302.259766\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"341.46875\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"369.251953\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"430.433594\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"493.8125\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"525.599609\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"592.257812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"647.238281\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"702.21875\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"765.597656\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"806.710938\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"867.990234\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"922.970703\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 66.376477 276.334125 \nL 174.594659 138.094125 \nL 282.812841 68.974125 \nL 391.031023 34.414125 \n\" clip-path=\"url(#pc059a7a869)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 66.376477 276.334125 \nL 174.594659 172.654125 \nL 282.812841 103.534125 \nL 391.031023 68.974125 \n\" clip-path=\"url(#pc059a7a869)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 288.430125 \nL 50.14375 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 407.26375 288.430125 \nL 407.26375 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 288.430125 \nL 407.26375 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 22.318125 \nL 407.26375 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Validation Accuracy: LeNet with vs. without Batch Normalization -->\n    <g transform=\"translate(36.475 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-3a\" d=\"M 750 794 \nL 1409 794 \nL 1409 0 \nL 750 0 \nL 750 794 \nz\nM 750 3309 \nL 1409 3309 \nL 1409 2516 \nL 750 2516 \nL 750 3309 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 531 \nL 3531 531 \nL 3531 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-42\" d=\"M 1259 2228 \nL 1259 519 \nL 2272 519 \nQ 2781 519 3026 730 \nQ 3272 941 3272 1375 \nQ 3272 1813 3026 2020 \nQ 2781 2228 2272 2228 \nL 1259 2228 \nz\nM 1259 4147 \nL 1259 2741 \nL 2194 2741 \nQ 2656 2741 2882 2914 \nQ 3109 3088 3109 3444 \nQ 3109 3797 2882 3972 \nQ 2656 4147 2194 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2241 4666 \nQ 2963 4666 3353 4366 \nQ 3744 4066 3744 3513 \nQ 3744 3084 3544 2831 \nQ 3344 2578 2956 2516 \nQ 3422 2416 3680 2098 \nQ 3938 1781 3938 1306 \nQ 3938 681 3513 340 \nQ 3088 0 2303 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-7a\" d=\"M 353 3500 \nL 3084 3500 \nL 3084 2975 \nL 922 459 \nL 3084 459 \nL 3084 0 \nL 275 0 \nL 275 525 \nL 2438 3041 \nL 353 3041 \nL 353 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-56\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"149.720703\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"177.503906\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"240.980469\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"302.259766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"341.46875\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"369.251953\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"430.433594\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"493.8125\"/>\n     <use xlink:href=\"#DejaVuSans-41\" x=\"525.599609\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"592.257812\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"647.238281\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"702.21875\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"765.597656\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"806.710938\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"867.990234\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"922.970703\"/>\n     <use xlink:href=\"#DejaVuSans-3a\" x=\"974.900391\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1008.591797\"/>\n     <use xlink:href=\"#DejaVuSans-4c\" x=\"1040.378906\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1094.341797\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" x=\"1155.865234\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1230.669922\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1292.193359\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1331.402344\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"1363.189453\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1444.976562\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1472.759766\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1511.96875\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1575.347656\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"1607.134766\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1666.314453\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"1718.414062\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1750.201172\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"1781.988281\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1863.775391\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1891.558594\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1930.767578\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1994.146484\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"2055.328125\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"2118.707031\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"2157.916016\"/>\n     <use xlink:href=\"#DejaVuSans-42\" x=\"2189.703125\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"2258.306641\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"2319.585938\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"2358.794922\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"2413.775391\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"2477.154297\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" x=\"2508.941406\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"2583.746094\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"2644.927734\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"2684.291016\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"2781.703125\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"2842.982422\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"2870.765625\"/>\n     <use xlink:href=\"#DejaVuSans-7a\" x=\"2898.548828\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"2951.039062\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"3012.318359\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"3051.527344\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"3079.310547\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"3140.492188\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 57.14375 59.674375 \nL 190.596875 59.674375 \nQ 192.596875 59.674375 192.596875 57.674375 \nL 192.596875 29.318125 \nQ 192.596875 27.318125 190.596875 27.318125 \nL 57.14375 27.318125 \nQ 55.14375 27.318125 55.14375 29.318125 \nL 55.14375 57.674375 \nQ 55.14375 59.674375 57.14375 59.674375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 59.14375 35.416562 \nL 69.14375 35.416562 \nL 79.14375 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- With Batch Norm -->\n     <g transform=\"translate(87.14375 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-57\" d=\"M 213 4666 \nL 850 4666 \nL 1831 722 \nL 2809 4666 \nL 3519 4666 \nL 4500 722 \nL 5478 4666 \nL 6119 4666 \nL 4947 0 \nL 4153 0 \nL 3169 4050 \nL 2175 0 \nL 1381 0 \nL 213 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-57\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"96.626953\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"124.410156\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"163.619141\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"226.998047\"/>\n      <use xlink:href=\"#DejaVuSans-42\" x=\"258.785156\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"327.388672\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"388.667969\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"427.876953\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"482.857422\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"546.236328\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" x=\"578.023438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"652.828125\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"714.009766\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"753.373047\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 59.14375 50.094687 \nL 69.14375 50.094687 \nL 79.14375 50.094687 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- Without Batch Norm -->\n     <g transform=\"translate(87.14375 53.594687) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-57\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"96.626953\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"124.410156\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"163.619141\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.998047\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"288.179688\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"351.558594\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"390.767578\"/>\n      <use xlink:href=\"#DejaVuSans-42\" x=\"422.554688\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"491.158203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"552.4375\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"591.646484\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"646.626953\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"710.005859\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" x=\"741.792969\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"816.597656\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"877.779297\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"917.142578\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc059a7a869\">\n   <rect x=\"50.14375\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Maximum Learning Rate Before Failure**\n",
        "\n",
        "The maximum learning rate varies based on the use of batch normalization. Generally, with batch normalization, you can use higher learning rates due to the more stable gradients it provides. You can experiment by incrementally increasing the learning rate in your optimizer and monitoring the training loss until it diverges.\n",
        "\n",
        "**3. Batch Normalization in Every Layer?**\n",
        "\n",
        "You do not necessarily need batch normalization in every layer. While it can be beneficial, there are diminishing returns when applied to all layers, especially towards the output layers. Experimenting with different configurations can help determine the optimal placement for batch normalization. Some strategies could be:\n",
        "\n",
        "* Only applying it after convolutional layers.\n",
        "* Avoiding it in layers where it may not add significant value (e.g., the final layer before classification).\n",
        "\n",
        "**4. Implementing a \"Lite\" Version of Batch Normalization**\n",
        "\n",
        "A \"lite\" version of batch normalization can be implemented to either only remove the mean or only remove the variance:\n",
        "\n",
        "**4.1. Only Removes Mean:**"
      ],
      "metadata": {
        "id": "LRuuwC5IUret"
      },
      "id": "LRuuwC5IUret"
    },
    {
      "cell_type": "code",
      "source": [
        "class LiteBatchNormMean(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(LiteBatchNormMean, self).__init__()\n",
        "        self.num_features = num_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=0, keepdim=True)\n",
        "        return x - mean\n"
      ],
      "metadata": {
        "id": "Pr7EvxKWVBan"
      },
      "id": "Pr7EvxKWVBan",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2. Only Removes Variance:**\n"
      ],
      "metadata": {
        "id": "yZ6Ug-qRVFvW"
      },
      "id": "yZ6Ug-qRVFvW"
    },
    {
      "cell_type": "code",
      "source": [
        "class LiteBatchNormVariance(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(LiteBatchNormVariance, self).__init__()\n",
        "        self.num_features = num_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        var = x.var(dim=0, keepdim=True)\n",
        "        return x / torch.sqrt(var + 1e-5)  # Adding small epsilon to prevent division by zero\n"
      ],
      "metadata": {
        "id": "4svRjuKbVDT2"
      },
      "id": "4svRjuKbVDT2",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Fixing Parameters beta and gamma**\n",
        "\n",
        "Fixing the parameters beta and gamma to constant values (e.g., zero and one) will mean that the batch normalization will no longer scale or shift the output. This can lead to instability in training, as the model loses the advantages of adjusting these parameters to learn better representations. The performance might degrade since you are not allowing the model to adapt the normalized output effectively.\n",
        "\n",
        "**6. Replacing Dropout with Batch Normalization**\n",
        "\n",
        "You cannot simply replace dropout with batch normalization, as they serve different purposes:\n",
        "\n",
        "* Dropout is a regularization technique that randomly sets a portion of the neurons to zero during training to prevent overfitting.\n",
        "* Batch normalization stabilizes the training process by normalizing activations.\n",
        "* Replacing dropout with batch normalization might lead to better convergence but can also lead to overfitting if regularization is not compensated for.\n",
        "\n",
        "**7. Research Ideas for Normalization Transforms**\n",
        "\n",
        "Yes, the probability integral transform can be applied to normalize input distributions. It transforms data into a uniform distribution, which can improve the training dynamics for some networks.\n",
        "\n",
        "**7.2. Full-Rank Covariance Estimate**\n",
        "\n",
        "Using a full-rank covariance estimate for normalization could provide better adaptivity to the data distribution, but it also increases the computational complexity and might lead to overfitting due to the increased number of parameters.\n",
        "\n",
        "**7.3. Compact Matrix Variants**\n",
        "\n",
        "Using compact matrix representations like block-diagonal or low-rank approximations can be beneficial for reducing computational cost and memory usage, but they may introduce approximation errors that affect performance.\n",
        "\n",
        "**7.4. Sparsification Compression as Regularizer**\n",
        "\n",
        "Sparsification can act as a regularizer by forcing the model to focus on the most important features and potentially improving generalization by preventing overfitting.\n",
        "\n",
        "**7.5. Other Projections**\n",
        "\n",
        "Other projections such as convex cone transforms or symmetry group-specific transformations could potentially improve network performance by leveraging inherent data structures, but they would require careful design and validation to ensure they don’t introduce instability.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Batch normalization is a powerful technique in deep learning that stabilizes training and allows for higher learning rates. However, it should be implemented thoughtfully, considering its effects on model performance and training dynamics. Experimenting with different normalization methods and architectures can yield insights into improving models for specific datasets and tasks."
      ],
      "metadata": {
        "id": "Le075SJqVNHG"
      },
      "id": "Le075SJqVNHG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 37,
        "tab": [
          "pytorch"
        ],
        "id": "3c9f5a14"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/84)\n"
      ],
      "id": "3c9f5a14"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "e11b4915"
      },
      "source": [
        "# 8.6. Residual Networks (ResNet) and ResNeXt\n",
        ":label:`sec_resnet`\n",
        "\n",
        "As we design ever deeper networks it becomes imperative to understand how adding layers can increase the complexity and expressiveness of the network.\n",
        "Even more important is the ability to design networks where adding layers makes networks strictly more expressive rather than just different.\n",
        "To make some progress we need a bit of mathematics.\n"
      ],
      "id": "e11b4915"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:50.915858Z",
          "iopub.status.busy": "2023-08-18T19:50:50.915085Z",
          "iopub.status.idle": "2023-08-18T19:50:53.897064Z",
          "shell.execute_reply": "2023-08-18T19:50:53.895755Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "d6e5d075"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ],
      "id": "d6e5d075"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "f46d0878"
      },
      "source": [
        "## 8.6.1. Function Classes\n",
        "\n",
        "Consider $\\mathcal{F}$, the class of functions that a specific network architecture (together with learning rates and other hyperparameter settings) can reach.\n",
        "That is, for all $f \\in \\mathcal{F}$ there exists some set of parameters (e.g., weights and biases) that can be obtained through training on a suitable dataset.\n",
        "Let's assume that $f^*$ is the \"truth\" function that we really would like to find.\n",
        "If it is in $\\mathcal{F}$, we are in good shape but typically we will not be quite so lucky.\n",
        "Instead, we will try to find some $f^*_\\mathcal{F}$ which is our best bet within $\\mathcal{F}$.\n",
        "For instance,\n",
        "given a dataset with features $\\mathbf{X}$\n",
        "and labels $\\mathbf{y}$,\n",
        "we might try finding it by solving the following optimization problem:\n",
        "\n",
        "$$f^*_\\mathcal{F} \\stackrel{\\textrm{def}}{=} \\mathop{\\mathrm{argmin}}_f L(\\mathbf{X}, \\mathbf{y}, f) \\textrm{ subject to } f \\in \\mathcal{F}.$$\n",
        "\n",
        "We know that regularization :cite:`tikhonov1977solutions,morozov2012methods` may control complexity of $\\mathcal{F}$\n",
        "and achieve consistency, so a larger size of training data\n",
        "generally leads to better $f^*_\\mathcal{F}$.\n",
        "It is only reasonable to assume that if we design a different and more powerful architecture $\\mathcal{F}'$ we should arrive at a better outcome. In other words, we would expect that $f^*_{\\mathcal{F}'}$ is \"better\" than $f^*_{\\mathcal{F}}$. However, if $\\mathcal{F} \\not\\subseteq \\mathcal{F}'$ there is no guarantee that this should even happen. In fact, $f^*_{\\mathcal{F}'}$ might well be worse.\n",
        "As illustrated by :numref:`fig_functionclasses`,\n",
        "for non-nested function classes, a larger function class does not always move closer to the \"truth\" function $f^*$. For instance,\n",
        "on the left of :numref:`fig_functionclasses`,\n",
        "though $\\mathcal{F}_3$ is closer to $f^*$ than $\\mathcal{F}_1$, $\\mathcal{F}_6$ moves away and there is no guarantee that further increasing the complexity can reduce the distance from $f^*$.\n",
        "With nested function classes\n",
        "where $\\mathcal{F}_1 \\subseteq \\cdots \\subseteq \\mathcal{F}_6$\n",
        "on the right of :numref:`fig_functionclasses`,\n",
        "we can avoid the aforementioned issue from the non-nested function classes.\n",
        "\n",
        "\n",
        "![For non-nested function classes, a larger (indicated by area) function class does not guarantee we will get closer to the \"truth\" function ($\\mathit{f}^*$). This does not happen in nested function classes.](http://d2l.ai/_images/functionclasses.svg)\n",
        ":label:`fig_functionclasses`\n",
        "\n",
        "Thus,\n",
        "only if larger function classes contain the smaller ones are we guaranteed that increasing them strictly increases the expressive power of the network.\n",
        "For deep neural networks,\n",
        "if we can\n",
        "train the newly-added layer into an identity function $f(\\mathbf{x}) = \\mathbf{x}$, the new model will be as effective as the original model. As the new model may get a better solution to fit the training dataset, the added layer might make it easier to reduce training errors.\n",
        "\n",
        "This is the question that :citet:`He.Zhang.Ren.ea.2016` considered when working on very deep computer vision models.\n",
        "At the heart of their proposed *residual network* (*ResNet*) is the idea that every additional layer should\n",
        "more easily\n",
        "contain the identity function as one of its elements.\n",
        "These considerations are rather profound but they led to a surprisingly simple\n",
        "solution, a *residual block*.\n",
        "With it, ResNet won the ImageNet Large Scale Visual Recognition Challenge in 2015. The design had a profound influence on how to\n",
        "build deep neural networks. For instance, residual blocks have been added to recurrent networks :cite:`prakash2016neural,kim2017residual`. Likewise, Transformers :cite:`Vaswani.Shazeer.Parmar.ea.2017` use them to stack many layers of networks efficiently. It is also used in graph neural networks :cite:`Kipf.Welling.2016` and, as a basic concept, it has been used extensively in computer vision :cite:`Redmon.Farhadi.2018,Ren.He.Girshick.ea.2015`.\n",
        "Note that residual networks are predated by highway networks :cite:`srivastava2015highway` that share some of the motivation, albeit without the elegant parametrization around the identity function.\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "f46d0878"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.6.2. (**Residual Blocks**)\n",
        ":label:`subsec_residual-blks`\n",
        "\n",
        "Let's focus on a local part of a neural network, as depicted in :numref:`fig_residual_block`. Denote the input by $\\mathbf{x}$.\n",
        "We assume that $f(\\mathbf{x})$, the desired underlying mapping we want to obtain by learning, is to be used as input to the activation function on the top.\n",
        "On the left,\n",
        "the portion within the dotted-line box\n",
        "must directly learn $f(\\mathbf{x})$.\n",
        "On the right,\n",
        "the portion within the dotted-line box\n",
        "needs to\n",
        "learn the *residual mapping* $g(\\mathbf{x}) = f(\\mathbf{x}) - \\mathbf{x}$,\n",
        "which is how the residual block derives its name.\n",
        "If the identity mapping $f(\\mathbf{x}) = \\mathbf{x}$ is the desired underlying mapping,\n",
        "the residual mapping amounts to $g(\\mathbf{x}) = 0$ and it is thus easier to learn:\n",
        "we only need to push the weights and biases\n",
        "of the\n",
        "upper weight layer (e.g., fully connected layer and convolutional layer)\n",
        "within the dotted-line box\n",
        "to zero.\n",
        "The right figure illustrates the *residual block* of ResNet,\n",
        "where the solid line carrying the layer input\n",
        "$\\mathbf{x}$ to the addition operator\n",
        "is called a *residual connection* (or *shortcut connection*).\n",
        "With residual blocks, inputs can\n",
        "forward propagate faster through the residual connections across layers.\n",
        "In fact,\n",
        "the residual block\n",
        "can be thought of as\n",
        "a special case of the multi-branch Inception block:\n",
        "it has two branches\n",
        "one of which is the identity mapping.\n",
        "\n",
        "![In a regular block (left), the portion within the dotted-line box must directly learn the mapping $\\mathit{f}(\\mathbf{x})$. In a residual block (right), the portion within the dotted-line box needs to learn the residual mapping $\\mathit{g}(\\mathbf{x}) = \\mathit{f}(\\mathbf{x}) - \\mathbf{x}$, making the identity mapping $\\mathit{f}(\\mathbf{x}) = \\mathbf{x}$ easier to learn.](../img/residual-block.svg)\n",
        ":label:`fig_residual_block`\n",
        "\n",
        "\n",
        "ResNet has VGG's full $3\\times 3$ convolutional layer design. The residual block has two $3\\times 3$ convolutional layers with the same number of output channels. Each convolutional layer is followed by a batch normalization layer and a ReLU activation function. Then, we skip these two convolution operations and add the input directly before the final ReLU activation function.\n",
        "This kind of design requires that the output of the two convolutional layers has to be of the same shape as the input, so that they can be added together. If we want to change the number of channels, we need to introduce an additional $1\\times 1$ convolutional layer to transform the input into the desired shape for the addition operation. Let's have a look at the code below."
      ],
      "metadata": {
        "id": "ncJT5aOdWpTp"
      },
      "id": "ncJT5aOdWpTp"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:53.901535Z",
          "iopub.status.busy": "2023-08-18T19:50:53.900638Z",
          "iopub.status.idle": "2023-08-18T19:50:53.909065Z",
          "shell.execute_reply": "2023-08-18T19:50:53.907927Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "35fa7497"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):  #@save\n",
        "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
        "                                   stride=strides)\n",
        "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ],
      "id": "35fa7497"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "d5a254f6"
      },
      "source": [
        "This code generates two types of networks: one where we add the input to the output before applying the ReLU nonlinearity whenever `use_1x1conv=False`; and one where we adjust channels and resolution by means of a $1 \\times 1$ convolution before adding. :numref:`fig_resnet_block` illustrates this.\n",
        "\n",
        "![ResNet block with and without $1 \\times 1$ convolution, which transforms the input into the desired shape for the addition operation.](../img/resnet-block.svg)\n",
        ":label:`fig_resnet_block`\n",
        "\n",
        "Now let's look at [**a situation where the input and output are of the same shape**], where $1 \\times 1$ convolution is not needed.\n"
      ],
      "id": "d5a254f6"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:53.913050Z",
          "iopub.status.busy": "2023-08-18T19:50:53.912286Z",
          "iopub.status.idle": "2023-08-18T19:50:53.955152Z",
          "shell.execute_reply": "2023-08-18T19:50:53.953792Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "2057b8bc",
        "outputId": "a53633bd-2f7a-4423-b959-569092f2311d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "blk = Residual(3)\n",
        "X = torch.randn(4, 3, 6, 6)\n",
        "blk(X).shape"
      ],
      "id": "2057b8bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 15,
        "id": "81b3b8b1"
      },
      "source": [
        "We also have the option to [**halve the output height and width while increasing the number of output channels**].\n",
        "In this case we use $1 \\times 1$ convolutions via `use_1x1conv=True`. This comes in handy at the beginning of each ResNet block to reduce the spatial dimensionality via `strides=2`.\n"
      ],
      "id": "81b3b8b1"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:53.958860Z",
          "iopub.status.busy": "2023-08-18T19:50:53.958579Z",
          "iopub.status.idle": "2023-08-18T19:50:53.983195Z",
          "shell.execute_reply": "2023-08-18T19:50:53.981643Z"
        },
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ],
        "id": "341c1c55",
        "outputId": "bbe9c553-79ae-4228-dcdc-ac7ab317cf6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 6, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "blk = Residual(6, use_1x1conv=True, strides=2)\n",
        "blk(X).shape"
      ],
      "id": "341c1c55"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 18,
        "id": "735745a2"
      },
      "source": [
        "## 8.6.3. [**ResNet Model**]\n",
        "\n",
        "The first two layers of ResNet are the same as those of the GoogLeNet we described before: the $7\\times 7$ convolutional layer with 64 output channels and a stride of 2 is followed by the $3\\times 3$ max-pooling layer with a stride of 2. The difference is the batch normalization layer added after each convolutional layer in ResNet.\n"
      ],
      "id": "735745a2"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:53.987745Z",
          "iopub.status.busy": "2023-08-18T19:50:53.986818Z",
          "iopub.status.idle": "2023-08-18T19:50:53.994446Z",
          "shell.execute_reply": "2023-08-18T19:50:53.993110Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "393dd8de"
      },
      "outputs": [],
      "source": [
        "class ResNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "id": "393dd8de"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 21,
        "id": "537173c6"
      },
      "source": [
        "GoogLeNet uses four modules made up of Inception blocks.\n",
        "However, ResNet uses four modules made up of residual blocks, each of which uses several residual blocks with the same number of output channels.\n",
        "The number of channels in the first module is the same as the number of input channels. Since a max-pooling layer with a stride of 2 has already been used, it is not necessary to reduce the height and width. In the first residual block for each of the subsequent modules, the number of channels is doubled compared with that of the previous module, and the height and width are halved.\n"
      ],
      "id": "537173c6"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:53.998963Z",
          "iopub.status.busy": "2023-08-18T19:50:53.997879Z",
          "iopub.status.idle": "2023-08-18T19:50:54.005699Z",
          "shell.execute_reply": "2023-08-18T19:50:54.004419Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "id": "4d92b69c"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(ResNet)\n",
        "def block(self, num_residuals, num_channels, first_block=False):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "        if i == 0 and not first_block:\n",
        "            blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "        else:\n",
        "            blk.append(Residual(num_channels))\n",
        "    return nn.Sequential(*blk)"
      ],
      "id": "4d92b69c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 26,
        "id": "582781fd"
      },
      "source": [
        "Then, we add all the modules to ResNet. Here, two residual blocks are used for each module. Lastly, just like GoogLeNet, we add a global average pooling layer, followed by the fully connected layer output.\n"
      ],
      "id": "582781fd"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:54.010309Z",
          "iopub.status.busy": "2023-08-18T19:50:54.009135Z",
          "iopub.status.idle": "2023-08-18T19:50:54.017906Z",
          "shell.execute_reply": "2023-08-18T19:50:54.016848Z"
        },
        "origin_pos": 27,
        "tab": [
          "pytorch"
        ],
        "id": "0019ee3f"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(ResNet)\n",
        "def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1())\n",
        "    for i, b in enumerate(arch):\n",
        "        self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "    self.net.add_module('last', nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "    self.net.apply(d2l.init_cnn)"
      ],
      "id": "0019ee3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 29,
        "id": "91a9c2ac"
      },
      "source": [
        "There are four convolutional layers in each module (excluding the $1\\times 1$ convolutional layer). Together with the first $7\\times 7$ convolutional layer and the final fully connected layer, there are 18 layers in total. Therefore, this model is commonly known as ResNet-18.\n",
        "By configuring different numbers of channels and residual blocks in the module, we can create different ResNet models, such as the deeper 152-layer ResNet-152. Although the main architecture of ResNet is similar to that of GoogLeNet, ResNet's structure is simpler and easier to modify. All these factors have resulted in the rapid and widespread use of ResNet. :numref:`fig_resnet18` depicts the full ResNet-18.\n",
        "\n",
        "![The ResNet-18 architecture.](../img/resnet18-90.svg)\n",
        ":label:`fig_resnet18`\n",
        "\n",
        "Before training ResNet, let's [**observe how the input shape changes across different modules in ResNet**]. As in all the previous architectures, the resolution decreases while the number of channels increases up until the point where a global average pooling layer aggregates all features.\n"
      ],
      "id": "91a9c2ac"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:54.021691Z",
          "iopub.status.busy": "2023-08-18T19:50:54.021249Z",
          "iopub.status.idle": "2023-08-18T19:50:54.027632Z",
          "shell.execute_reply": "2023-08-18T19:50:54.026516Z"
        },
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "id": "61e60e34"
      },
      "outputs": [],
      "source": [
        "class ResNet18(ResNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),\n",
        "                       lr, num_classes)"
      ],
      "id": "61e60e34"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:54.031902Z",
          "iopub.status.busy": "2023-08-18T19:50:54.030981Z",
          "iopub.status.idle": "2023-08-18T19:50:54.188619Z",
          "shell.execute_reply": "2023-08-18T19:50:54.187488Z"
        },
        "origin_pos": 32,
        "tab": [
          "pytorch"
        ],
        "id": "f153f6ed",
        "outputId": "04a9d7f8-e659-442f-ee0e-46ea52cf5d3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 128, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 256, 6, 6])\n",
            "Sequential output shape:\t torch.Size([1, 512, 3, 3])\n",
            "Sequential output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "ResNet18().layer_summary((1, 1, 96, 96))"
      ],
      "id": "f153f6ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 35,
        "id": "c04c33c9"
      },
      "source": [
        "## 8.6.4. [**Training**]\n",
        "\n",
        "We train ResNet on the Fashion-MNIST dataset, just like before. ResNet is quite a powerful and flexible architecture. The plot capturing training and validation loss illustrates a significant gap between both graphs, with the training loss being considerably lower. For a network of this flexibility, more training data would offer distinct benefit in closing the gap and improving accuracy.\n"
      ],
      "id": "c04c33c9"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:50:54.192632Z",
          "iopub.status.busy": "2023-08-18T19:50:54.191821Z",
          "iopub.status.idle": "2023-08-18T19:53:34.753784Z",
          "shell.execute_reply": "2023-08-18T19:53:34.752565Z"
        },
        "origin_pos": 36,
        "tab": [
          "pytorch"
        ],
        "id": "61b87bb9",
        "outputId": "eb7cea5a-0cad-4c53-834c-d1df12eca568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-02b532dcfd80>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'net'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Neural network is defined'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    165\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                             return_indices=self.return_indices)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T08:05:54.145424</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m6e92e50f1a\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m6e92e50f1a\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m6e92e50f1a\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m6e92e50f1a\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m6e92e50f1a\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m6e92e50f1a\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m6e92e50f1a\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"mba9aedbea4\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mba9aedbea4\" x=\"30.103125\" y=\"113.752845\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 117.552064) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mba9aedbea4\" x=\"30.103125\" y=\"70.698536\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 74.497754) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mba9aedbea4\" x=\"30.103125\" y=\"27.644226\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 31.443445) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path d=\"M 34.954394 78.996024 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 78.996024 \nL 44.698573 126.855546 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 78.996024 \nL 44.698573 126.855546 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 49.633125 119.564953 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_14\"/>\n   <g id=\"line2d_15\">\n    <path d=\"M 34.954394 78.996024 \nL 44.698573 126.855546 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 49.633125 119.564953 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 13.5 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 34.954394 78.996024 \nL 44.698573 126.855546 \nL 54.442752 139.5 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 49.633125 119.564953 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 13.5 \n\" clip-path=\"url(#p30d319b037)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_23\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p30d319b037\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = ResNet18(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "id": "61b87bb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 38,
        "id": "bc09eb06"
      },
      "source": [
        "## 8.6.5. ResNeXt\n",
        ":label:`subsec_resnext`\n",
        "\n",
        "One of the challenges one encounters in the design of ResNet is the trade-off between nonlinearity and dimensionality within a given block. That is, we could add more nonlinearity by increasing the number of layers, or by increasing the width of the convolutions. An alternative strategy is to increase the number of channels that can carry information between blocks. Unfortunately, the latter comes with a quadratic penalty since the computational cost of ingesting $c_\\textrm{i}$ channels and emitting $c_\\textrm{o}$ channels is proportional to $\\mathcal{O}(c_\\textrm{i} \\cdot c_\\textrm{o})$ (see our discussion in :numref:`sec_channels`).\n",
        "\n",
        "We can take some inspiration from the Inception block of :numref:`fig_inception` which has information flowing through the block in separate groups. Applying the idea of multiple independent groups to the ResNet block of :numref:`fig_resnet_block` led to the design of ResNeXt :cite:`Xie.Girshick.Dollar.ea.2017`.\n",
        "Different from the smorgasbord of transformations in Inception,\n",
        "ResNeXt adopts the *same* transformation in all branches,\n",
        "thus minimizing the need for manual tuning of each branch.\n",
        "\n",
        "![The ResNeXt block. The use of grouped convolution with $\\mathit{g}$ groups is $\\mathit{g}$ times faster than a dense convolution. It is a bottleneck residual block when the number of intermediate channels $\\mathit{b}$ is less than $\\mathit{c}$.](../img/resnext-block.svg)\n",
        ":label:`fig_resnext_block`\n",
        "\n",
        "Breaking up a convolution from $c_\\textrm{i}$ to $c_\\textrm{o}$ channels into one of $g$ groups of size $c_\\textrm{i}/g$ generating $g$ outputs of size $c_\\textrm{o}/g$ is called, quite fittingly, a *grouped convolution*. The computational cost (proportionally) is reduced from $\\mathcal{O}(c_\\textrm{i} \\cdot c_\\textrm{o})$ to $\\mathcal{O}(g \\cdot (c_\\textrm{i}/g) \\cdot (c_\\textrm{o}/g)) = \\mathcal{O}(c_\\textrm{i} \\cdot c_\\textrm{o} / g)$, i.e., it is $g$ times faster. Even better, the number of parameters needed to generate the output is also reduced from a $c_\\textrm{i} \\times c_\\textrm{o}$ matrix to $g$ smaller matrices of size $(c_\\textrm{i}/g) \\times (c_\\textrm{o}/g)$, again a $g$ times reduction. In what follows we assume that both $c_\\textrm{i}$ and $c_\\textrm{o}$ are divisible by $g$.\n",
        "\n",
        "The only challenge in this design is that no information is exchanged between the $g$ groups. The ResNeXt block of\n",
        ":numref:`fig_resnext_block` amends this in two ways: the grouped convolution with a $3 \\times 3$ kernel is sandwiched in between two $1 \\times 1$ convolutions. The second one serves double duty in changing the number of channels back. The benefit is that we only pay the $\\mathcal{O}(c \\cdot b)$ cost for $1 \\times 1$ kernels and can make do with an $\\mathcal{O}(b^2 / g)$ cost for $3 \\times 3$ kernels. Similar to the residual block implementation in\n",
        ":numref:`subsec_residual-blks`, the residual connection is replaced (thus generalized) by a $1 \\times 1$ convolution.\n",
        "\n",
        "The right-hand figure in :numref:`fig_resnext_block` provides a much more concise summary of the resulting network block. It will also play a major role in the design of generic modern CNNs in :numref:`sec_cnn-design`. Note that the idea of grouped convolutions dates back to the implementation of AlexNet :cite:`Krizhevsky.Sutskever.Hinton.2012`. When distributing the network across two GPUs with limited memory, the implementation treated each GPU as its own channel with no ill effects.\n",
        "\n",
        "The following implementation of the `ResNeXtBlock` class takes as argument `groups` ($g$), with\n",
        "`bot_channels` ($b$) intermediate (bottleneck) channels. Lastly, when we need to reduce the height and width of the representation, we add a stride of $2$ by setting `use_1x1conv=True, strides=2`.\n"
      ],
      "id": "bc09eb06"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:53:34.757842Z",
          "iopub.status.busy": "2023-08-18T19:53:34.757550Z",
          "iopub.status.idle": "2023-08-18T19:53:34.767922Z",
          "shell.execute_reply": "2023-08-18T19:53:34.766805Z"
        },
        "origin_pos": 40,
        "tab": [
          "pytorch"
        ],
        "id": "aa67ceaf"
      },
      "outputs": [],
      "source": [
        "class ResNeXtBlock(nn.Module):  #@save\n",
        "    \"\"\"The ResNeXt block.\"\"\"\n",
        "    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,\n",
        "                 strides=1):\n",
        "        super().__init__()\n",
        "        bot_channels = int(round(num_channels * bot_mul))\n",
        "        self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)\n",
        "        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,\n",
        "                                   stride=strides, padding=1,\n",
        "                                   groups=bot_channels//groups)\n",
        "        self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "        self.bn3 = nn.LazyBatchNorm2d()\n",
        "        if use_1x1conv:\n",
        "            self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "            self.bn4 = nn.LazyBatchNorm2d()\n",
        "        else:\n",
        "            self.conv4 = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = F.relu(self.bn2(self.conv2(Y)))\n",
        "        Y = self.bn3(self.conv3(Y))\n",
        "        if self.conv4:\n",
        "            X = self.bn4(self.conv4(X))\n",
        "        return F.relu(Y + X)"
      ],
      "id": "aa67ceaf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 43,
        "id": "03b62951"
      },
      "source": [
        "Its use is entirely analogous to that of the `ResNetBlock` discussed previously. For instance, when using (`use_1x1conv=False, strides=1`), the input and output are of the same shape. Alternatively, setting `use_1x1conv=True, strides=2` halves the output height and width.\n"
      ],
      "id": "03b62951"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:53:34.771844Z",
          "iopub.status.busy": "2023-08-18T19:53:34.771565Z",
          "iopub.status.idle": "2023-08-18T19:53:34.803609Z",
          "shell.execute_reply": "2023-08-18T19:53:34.802407Z"
        },
        "origin_pos": 44,
        "tab": [
          "pytorch"
        ],
        "id": "ec6906e4",
        "outputId": "135f8862-dc89-4433-8204-306131761b18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 32, 96, 96])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blk = ResNeXtBlock(32, 16, 1)\n",
        "X = torch.randn(4, 32, 96, 96)\n",
        "blk(X).shape"
      ],
      "id": "ec6906e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 47,
        "id": "94a2283f"
      },
      "source": [
        "## 8.6.6. Summary and Discussion\n",
        "\n",
        "Nested function classes are desirable since they allow us to obtain strictly *more powerful* rather than also subtly *different* function classes when adding capacity. One way of accomplishing this is by letting additional layers to simply pass through the input to the output. Residual connections allow for this. As a consequence, this changes the inductive bias from simple functions being of the form $f(\\mathbf{x}) = 0$ to simple functions looking like $f(\\mathbf{x}) = \\mathbf{x}$.\n",
        "\n",
        "\n",
        "The residual mapping can learn the identity function more easily, such as pushing parameters in the weight layer to zero. We can train an effective *deep* neural network by having residual blocks. Inputs can forward propagate faster through the residual connections across layers. As a consequence, we can thus train much deeper networks. For instance, the original ResNet paper :cite:`He.Zhang.Ren.ea.2016` allowed for up to 152 layers. Another benefit of residual networks is that it allows us to add layers, initialized as the identity function, *during* the training process. After all, the default behavior of a layer is to let the data pass through unchanged. This can accelerate the training of very large networks in some cases.\n",
        "\n",
        "Prior to residual connections,\n",
        "bypassing paths with gating units were introduced\n",
        "to effectively train highway networks with over 100 layers\n",
        ":cite:`srivastava2015highway`.\n",
        "Using identity functions as bypassing paths,\n",
        "ResNet performed remarkably well\n",
        "on multiple computer vision tasks.\n",
        "Residual connections had a major influence on the design of subsequent deep neural networks, of either convolutional or sequential nature.\n",
        "As we will introduce later,\n",
        "the Transformer architecture :cite:`Vaswani.Shazeer.Parmar.ea.2017`\n",
        "adopts residual connections (together with other design choices) and is pervasive\n",
        "in areas as diverse as\n",
        "language, vision, speech, and reinforcement learning.\n",
        "\n",
        "ResNeXt is an example for how the design of convolutional neural networks has evolved over time: by being more frugal with computation and trading it off against the size of the activations (number of channels), it allows for faster and more accurate networks at lower cost. An alternative way of viewing grouped convolutions is to think of a block-diagonal matrix for the convolutional weights. Note that there are quite a few such \"tricks\" that lead to more efficient networks. For instance, ShiftNet :cite:`wu2018shift` mimicks the effects of a $3 \\times 3$ convolution, simply by adding shifted activations to the channels, offering increased function complexity, this time without any computational cost.\n",
        "\n",
        "A common feature of the designs we have discussed so far is that the network design is fairly manual, primarily relying on the ingenuity of the designer to find the \"right\" network hyperparameters. While clearly feasible, it is also very costly in terms of human time and there is no guarantee that the outcome is optimal in any sense. In :numref:`sec_cnn-design` we will discuss a number of strategies for obtaining high quality networks in a more automated fashion. In particular, we will review the notion of *network design spaces* that led to the RegNetX/Y models\n",
        ":cite:`Radosavovic.Kosaraju.Girshick.ea.2020`.\n",
        "\n",
        "## 8.6.7. Exercises\n",
        "\n",
        "1. What are the major differences between the Inception block in :numref:`fig_inception` and the residual block? How do they compare in terms of computation, accuracy, and the classes of functions they can describe?\n",
        "1. Refer to Table 1 in the ResNet paper :cite:`He.Zhang.Ren.ea.2016` to implement different variants of the network.\n",
        "1. For deeper networks, ResNet introduces a \"bottleneck\" architecture to reduce model complexity. Try to implement it.\n",
        "1. In subsequent versions of ResNet, the authors changed the \"convolution, batch normalization, and activation\" structure to the \"batch normalization, activation, and convolution\" structure. Make this improvement yourself. See Figure 1 in :citet:`He.Zhang.Ren.ea.2016*1` for details.\n",
        "1. Why can't we just increase the complexity of functions without bound, even if the function classes are nested?\n"
      ],
      "id": "94a2283f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "DFkjQoRDfTCA"
      },
      "id": "DFkjQoRDfTCA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Major Differences Between Inception Block and Residual Block**\n",
        "\n",
        "\n",
        "* Architecture:\n",
        "\n",
        "  * Inception Block: Combines multiple convolutional layers with different kernel sizes (1x1, 3x3, 5x5) along with pooling operations, allowing the network to capture features at various scales simultaneously. This structure is often referred to as \"multi-path\" because it has multiple branches processing the input data in parallel.\n",
        "  * Residual Block: Utilizes skip connections that bypass one or more layers. The output of the residual block is the sum of the input and the processed output of the convolutional layers. This design allows the model to learn identity mappings, which makes it easier to train deep networks.\n",
        "\n",
        "* Computation:\n",
        "  * Inception Block: Typically requires more computations due to the multiple convolutions of varying sizes. This can lead to increased memory usage as well, especially when processing high-dimensional inputs.\n",
        "  * Residual Block: While still computationally intensive, residual blocks can often be simpler because they generally use fewer operations than an inception block since they rely primarily on 3x3 convolutions and identity connections.\n",
        "\n",
        "* Accuracy:\n",
        "  * Both architectures aim to improve accuracy but can excel in different scenarios. Inception blocks often provide better accuracy for tasks with complex features due to their diverse pathways. Residual blocks are beneficial for training very deep networks by mitigating the vanishing gradient problem.\n",
        "\n",
        "* Classes of Functions:\n",
        "\n",
        "  * Inception Block: Can approximate a wider variety of functions due to its parallel paths and multiple kernel sizes, which enhances its ability to model complex features.\n",
        "  * Residual Block: Focuses on learning the residuals or the differences between the input and output, making it effective for deeper networks while preserving important information from previous layers.\n",
        "\n",
        "**2. Implementing Different Variants of ResNet**\n",
        "\n",
        "Referencing Table 1 in the ResNet paper, you can implement different variants of ResNet, such as ResNet-50, ResNet-101, or ResNet-152, by defining a function to create the residual blocks according to the specified layers. Here’s a basic structure to get you started:"
      ],
      "metadata": {
        "id": "CoFdy5W5fVdh"
      },
      "id": "CoFdy5W5fVdh"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "def resnet50(num_classes=1000):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n"
      ],
      "metadata": {
        "id": "SB_DxdO2iJLU"
      },
      "id": "SB_DxdO2iJLU",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Implementing Bottleneck Architecture**\n",
        "\n",
        "The bottleneck architecture reduces the number of parameters and computations. Here’s an implementation of the bottleneck version of the residual block:"
      ],
      "metadata": {
        "id": "bfxTtqchj1WC"
      },
      "id": "bfxTtqchj1WC"
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "PcjMOxp4j9zO"
      },
      "id": "PcjMOxp4j9zO",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Complexity of Functions**\n",
        "\n",
        "While it might seem intuitive to keep increasing the complexity of functions, several limitations exist:\n",
        "\n",
        "* Overfitting: As complexity increases, models may capture noise in the training data rather than the underlying distribution, leading to poor generalization on unseen data.\n",
        "* Computational Resources: Increased complexity often requires significantly more computational power and memory, which may not be feasible or practical in real-world applications.\n",
        "* Diminishing Returns: The improvements in performance with increased complexity may follow a diminishing returns pattern, where added complexity yields minimal gains.\n",
        "* Optimization Difficulty: More complex functions can be harder to optimize, resulting in longer training times and potential convergence issues.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Understanding the differences between Inception and residual blocks, along with effectively implementing ResNet variants and architectures, enhances model performance and computational efficiency. Adjusting the order of operations and considering function complexity can lead to better training dynamics and model generalization."
      ],
      "metadata": {
        "id": "FwtTvKANkBsJ"
      },
      "id": "FwtTvKANkBsJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 49,
        "tab": [
          "pytorch"
        ],
        "id": "af80c347"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/86)\n"
      ],
      "id": "af80c347"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "f122fb8e"
      },
      "source": [
        "# 8.7. Densely Connected Networks (DenseNet)\n",
        ":label:`sec_densenet`\n",
        "\n",
        "ResNet significantly changed the view of how to parametrize the functions in deep networks. *DenseNet* (dense convolutional network) is to some extent the logical extension of this :cite:`Huang.Liu.Van-Der-Maaten.ea.2017`.\n",
        "DenseNet is characterized by both the connectivity pattern where\n",
        "each layer connects to all the preceding layers\n",
        "and the concatenation operation (rather than the addition operator in ResNet) to preserve and reuse features\n",
        "from earlier layers.\n",
        "To understand how to arrive at it, let's take a small detour to mathematics.\n"
      ],
      "id": "f122fb8e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:25.812288Z",
          "iopub.status.busy": "2023-08-18T19:47:25.811221Z",
          "iopub.status.idle": "2023-08-18T19:47:28.844635Z",
          "shell.execute_reply": "2023-08-18T19:47:28.843703Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "898d7836"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "id": "898d7836"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "abbc7e4b"
      },
      "source": [
        "## 8.7.1. From ResNet to DenseNet\n",
        "\n",
        "Recall the Taylor expansion for functions. At the point $x = 0$ it can be written as\n",
        "\n",
        "$$f(x) = f(0) + x \\cdot \\left[f'(0) + x \\cdot \\left[\\frac{f''(0)}{2!}  + x \\cdot \\left[\\frac{f'''(0)}{3!}  + \\cdots \\right]\\right]\\right].$$\n",
        "\n",
        "\n",
        "The key point is that it decomposes a function into terms of increasingly higher order. In a similar vein, ResNet decomposes functions into\n",
        "\n",
        "$$f(\\mathbf{x}) = \\mathbf{x} + g(\\mathbf{x}).$$\n",
        "\n",
        "That is, ResNet decomposes $f$ into a simple linear term and a more complex\n",
        "nonlinear one.\n",
        "What if we wanted to capture (not necessarily add) information beyond two terms?\n",
        "One such solution is DenseNet :cite:`Huang.Liu.Van-Der-Maaten.ea.2017`.\n",
        "\n",
        "![The main difference between ResNet (left) and DenseNet (right) in cross-layer connections: use of addition and use of concatenation. ](../img/densenet-block.svg)\n",
        ":label:`fig_densenet_block`\n",
        "\n",
        "As shown in :numref:`fig_densenet_block`, the key difference between ResNet and DenseNet is that in the latter case outputs are *concatenated* (denoted by $[,]$) rather than added.\n",
        "As a result, we perform a mapping from $\\mathbf{x}$ to its values after applying an increasingly complex sequence of functions:\n",
        "\n",
        "$$\\mathbf{x} \\to \\left[\n",
        "\\mathbf{x},\n",
        "f_1(\\mathbf{x}),\n",
        "f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right), f_3\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right), f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right)\\right]\\right), \\ldots\\right].$$\n",
        "\n",
        "In the end, all these functions are combined in MLP to reduce the number of features again. In terms of implementation this is quite simple:\n",
        "rather than adding terms, we concatenate them. The name DenseNet arises from the fact that the dependency graph between variables becomes quite dense. The final layer of such a chain is densely connected to all previous layers. The dense connections are shown in :numref:`fig_densenet`.\n",
        "\n",
        "![Dense connections in DenseNet. Note how the dimensionality increases with depth.](http://d2l.ai/_images/densenet.svg)\n",
        ":label:`fig_densenet`\n",
        "\n",
        "The main components that comprise a DenseNet are *dense blocks* and *transition layers*. The former define how the inputs and outputs are concatenated, while the latter control the number of channels so that it is not too large,\n",
        "since the expansion $\\mathbf{x} \\to \\left[\\mathbf{x}, f_1(\\mathbf{x}),\n",
        "f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right), \\ldots \\right]$ can be quite high-dimensional.\n",
        "\n",
        "\n"
      ],
      "id": "abbc7e4b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.7.2. [**Dense Blocks**]\n",
        "\n",
        "DenseNet uses the modified \"batch normalization, activation, and convolution\"\n",
        "structure of ResNet (see the exercise in :numref:`sec_resnet`).\n",
        "First, we implement this convolution block structure.\n"
      ],
      "metadata": {
        "id": "XZVLFvZ_k7GU"
      },
      "id": "XZVLFvZ_k7GU"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.849074Z",
          "iopub.status.busy": "2023-08-18T19:47:28.848270Z",
          "iopub.status.idle": "2023-08-18T19:47:28.853093Z",
          "shell.execute_reply": "2023-08-18T19:47:28.852284Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "7d95675e"
      },
      "outputs": [],
      "source": [
        "def conv_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1))"
      ],
      "id": "7d95675e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "b4e66d06"
      },
      "source": [
        "A *dense block* consists of multiple convolution blocks, each using the same number of output channels. In the forward propagation, however, we concatenate the input and output of each convolution block on the channel dimension. Lazy evaluation allows us to adjust the dimensionality automatically.\n"
      ],
      "id": "b4e66d06"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.856547Z",
          "iopub.status.busy": "2023-08-18T19:47:28.855981Z",
          "iopub.status.idle": "2023-08-18T19:47:28.862956Z",
          "shell.execute_reply": "2023-08-18T19:47:28.861783Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "805394e3"
      },
      "outputs": [],
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_convs, num_channels):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layer = []\n",
        "        for i in range(num_convs):\n",
        "            layer.append(conv_block(num_channels))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate input and output of each block along the channels\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X"
      ],
      "id": "805394e3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 16,
        "id": "b17dfe15"
      },
      "source": [
        "In the following example,\n",
        "we [**define a `DenseBlock` instance**] with two convolution blocks of 10 output channels.\n",
        "When using an input with three channels, we will get an output with  $3 + 10 + 10=23$ channels. The number of convolution block channels controls the growth in the number of output channels relative to the number of input channels. This is also referred to as the *growth rate*.\n"
      ],
      "id": "b17dfe15"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.867108Z",
          "iopub.status.busy": "2023-08-18T19:47:28.866407Z",
          "iopub.status.idle": "2023-08-18T19:47:28.909936Z",
          "shell.execute_reply": "2023-08-18T19:47:28.908954Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "id": "e369c1ad",
        "outputId": "11f591f7-bd63-4d81-d95b-6ed33e40aa3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 23, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "blk = DenseBlock(2, 10)\n",
        "X = torch.randn(4, 3, 8, 8)\n",
        "Y = blk(X)\n",
        "Y.shape"
      ],
      "id": "e369c1ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 19,
        "id": "69c8df7b"
      },
      "source": [
        "## 8.7.3. [**Transition Layers**]\n",
        "\n",
        "Since each dense block will increase the number of channels, adding too many of them will lead to an excessively complex model. A *transition layer* is used to control the complexity of the model. It reduces the number of channels by using a $1\\times 1$ convolution. Moreover, it halves the height and width via average pooling with a stride of 2.\n"
      ],
      "id": "69c8df7b"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.915937Z",
          "iopub.status.busy": "2023-08-18T19:47:28.914796Z",
          "iopub.status.idle": "2023-08-18T19:47:28.920281Z",
          "shell.execute_reply": "2023-08-18T19:47:28.919184Z"
        },
        "origin_pos": 21,
        "tab": [
          "pytorch"
        ],
        "id": "6160cc48"
      },
      "outputs": [],
      "source": [
        "def transition_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2))"
      ],
      "id": "6160cc48"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 24,
        "id": "280d3329"
      },
      "source": [
        "[**Apply a transition layer**] with 10 channels to the output of the dense block in the previous example.  This reduces the number of output channels to 10, and halves the height and width.\n"
      ],
      "id": "280d3329"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.924597Z",
          "iopub.status.busy": "2023-08-18T19:47:28.924323Z",
          "iopub.status.idle": "2023-08-18T19:47:28.938373Z",
          "shell.execute_reply": "2023-08-18T19:47:28.937285Z"
        },
        "origin_pos": 26,
        "tab": [
          "pytorch"
        ],
        "id": "fc0cacfc",
        "outputId": "7b417203-0302-493c-e2c7-7ce459891090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "blk = transition_block(10)\n",
        "blk(Y).shape"
      ],
      "id": "fc0cacfc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 29,
        "id": "b9bc8e5c"
      },
      "source": [
        "## 8.7.4. [**DenseNet Model**]\n",
        "\n",
        "Next, we will construct a DenseNet model. DenseNet first uses the same single convolutional layer and max-pooling layer as in ResNet.\n"
      ],
      "id": "b9bc8e5c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.942331Z",
          "iopub.status.busy": "2023-08-18T19:47:28.941755Z",
          "iopub.status.idle": "2023-08-18T19:47:28.946845Z",
          "shell.execute_reply": "2023-08-18T19:47:28.946015Z"
        },
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "id": "79e0aaa1"
      },
      "outputs": [],
      "source": [
        "class DenseNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "id": "79e0aaa1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 32,
        "id": "6dccb085"
      },
      "source": [
        "Then, similar to the four modules made up of residual blocks that ResNet uses,\n",
        "DenseNet uses four dense blocks.\n",
        "As with ResNet, we can set the number of convolutional layers used in each dense block. Here, we set it to 4, consistent with the ResNet-18 model in :numref:`sec_resnet`. Furthermore, we set the number of channels (i.e., growth rate) for the convolutional layers in the dense block to 32, so 128 channels will be added to each dense block.\n",
        "\n",
        "In ResNet, the height and width are reduced between each module by a residual block with a stride of 2. Here, we use the transition layer to halve the height and width and halve the number of channels. Similar to ResNet, a global pooling layer and a fully connected layer are connected at the end to produce the output.\n"
      ],
      "id": "6dccb085"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.950027Z",
          "iopub.status.busy": "2023-08-18T19:47:28.949746Z",
          "iopub.status.idle": "2023-08-18T19:47:28.958660Z",
          "shell.execute_reply": "2023-08-18T19:47:28.957444Z"
        },
        "origin_pos": 33,
        "tab": [
          "pytorch"
        ],
        "id": "58137883"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(DenseNet)\n",
        "def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
        "             lr=0.1, num_classes=10):\n",
        "    super(DenseNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1())\n",
        "    for i, num_convs in enumerate(arch):\n",
        "        self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
        "                                                          growth_rate))\n",
        "        # The number of output channels in the previous dense block\n",
        "        num_channels += num_convs * growth_rate\n",
        "        # A transition layer that halves the number of channels is added\n",
        "        # between the dense blocks\n",
        "        if i != len(arch) - 1:\n",
        "            num_channels //= 2\n",
        "            self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
        "                num_channels))\n",
        "    self.net.add_module('last', nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "    self.net.apply(d2l.init_cnn)"
      ],
      "id": "58137883"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 35,
        "id": "a04e481f"
      },
      "source": [
        "## 8.7.5. [**Training**]\n",
        "\n",
        "Since we are using a deeper network here, in this section, we will reduce the input height and width from 224 to 96 to simplify the computation.\n"
      ],
      "id": "a04e481f"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:47:28.963624Z",
          "iopub.status.busy": "2023-08-18T19:47:28.962964Z",
          "iopub.status.idle": "2023-08-18T19:50:01.060105Z",
          "shell.execute_reply": "2023-08-18T19:50:01.059052Z"
        },
        "origin_pos": 36,
        "tab": [
          "pytorch"
        ],
        "id": "ef87c44e",
        "outputId": "88a9b6d3-ce98-41e7-d034-d1c46ef2443a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T08:57:56.195189</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m0459be5030\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m0459be5030\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m0459be5030\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m0459be5030\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m0459be5030\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m0459be5030\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m0459be5030\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m572f35f11e\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m572f35f11e\" x=\"30.103125\" y=\"131.865693\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 135.664911) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m572f35f11e\" x=\"30.103125\" y=\"99.506225\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 103.305444) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m572f35f11e\" x=\"30.103125\" y=\"67.146757\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 70.945976) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m572f35f11e\" x=\"30.103125\" y=\"34.78729\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 38.586509) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 93.363412 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 93.363412 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 26.860628 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 93.363412 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 26.860628 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 93.363412 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 26.860628 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 26.860628 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \nL 200.605438 137.473659 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \nL 200.605438 137.473659 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \nL 205.873125 121.846189 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \nL 200.605438 137.473659 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \nL 205.873125 121.846189 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \nL 205.873125 17.084306 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \nL 200.605438 137.473659 \nL 210.349618 138.878972 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \nL 205.873125 121.846189 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \nL 205.873125 17.084306 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \nL 200.605438 137.473659 \nL 210.349618 138.878972 \nL 220.093797 139.5 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \nL 205.873125 121.846189 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \nL 205.873125 17.084306 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \nL 200.605438 137.473659 \nL 210.349618 138.878972 \nL 220.093797 139.5 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \nL 205.873125 121.846189 \nL 225.403125 125.129021 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \nL 205.873125 17.084306 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.805695 \nL 54.442752 105.590163 \nL 64.186931 111.86586 \nL 73.93111 117.132812 \nL 83.675289 120.30202 \nL 93.419468 123.643483 \nL 103.163647 123.801799 \nL 112.907826 127.208104 \nL 122.652006 128.26542 \nL 132.396185 130.715758 \nL 142.140364 130.065303 \nL 151.884543 132.994903 \nL 161.628722 133.37018 \nL 171.372901 135.70494 \nL 181.11708 135.1896 \nL 190.861259 137.29797 \nL 200.605438 137.473659 \nL 210.349618 138.878972 \nL 220.093797 139.5 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 93.363412 \nL 69.163125 100.132489 \nL 88.693125 110.553225 \nL 108.223125 113.246393 \nL 127.753125 114.941806 \nL 147.283125 117.824031 \nL 166.813125 117.08452 \nL 186.343125 111.499886 \nL 205.873125 121.846189 \nL 225.403125 125.129021 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 26.860628 \nL 69.163125 24.924565 \nL 88.693125 21.516452 \nL 108.223125 20.620423 \nL 127.753125 19.916399 \nL 147.283125 18.764361 \nL 166.813125 19.676391 \nL 186.343125 21.052437 \nL 205.873125 17.084306 \nL 225.403125 16.28428 \n\" clip-path=\"url(#p359a2704b2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 100.434375 \nL 218.403125 100.434375 \nQ 220.403125 100.434375 220.403125 98.434375 \nL 220.403125 54.565625 \nQ 220.403125 52.565625 218.403125 52.565625 \nL 138.8125 52.565625 \nQ 136.8125 52.565625 136.8125 54.565625 \nL 136.8125 98.434375 \nQ 136.8125 100.434375 138.8125 100.434375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 60.664063 \nL 150.8125 60.664063 \nL 160.8125 60.664063 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 64.164063) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 75.620313 \nL 150.8125 75.620313 \nL 160.8125 75.620313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 79.120313) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 90.576563 \nL 150.8125 90.576563 \nL 160.8125 90.576563 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 94.076563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p359a2704b2\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = DenseNet(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "trainer.fit(model, data)"
      ],
      "id": "ef87c44e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 38,
        "id": "bacabdce"
      },
      "source": [
        "## 8.7.6. Summary and Discussion\n",
        "\n",
        "The main components that comprise DenseNet are dense blocks and transition layers. For the latter, we need to keep the dimensionality under control when composing the network by adding transition layers that shrink the number of channels again.\n",
        "In terms of cross-layer connections, in contrast to ResNet, where inputs and outputs are added together, DenseNet concatenates inputs and outputs on the channel dimension.\n",
        "Although these concatenation operations\n",
        "reuse features to achieve computational efficiency,\n",
        "unfortunately they lead to heavy GPU memory consumption.\n",
        "As a result,\n",
        "applying DenseNet may require more memory-efficient implementations that may increase training time :cite:`pleiss2017memory`.\n",
        "\n",
        "\n"
      ],
      "id": "bacabdce"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.7.7. Exercises\n",
        "\n",
        "1. Why do we use average pooling rather than max-pooling in the transition layer?\n",
        "1. One of the advantages mentioned in the DenseNet paper is that its model parameters are smaller than those of ResNet. Why is this the case?\n",
        "1. One problem for which DenseNet has been criticized is its high memory consumption.\n",
        "    1. Is this really the case? Try to change the input shape to 224 x 224 to compare the actual GPU memory consumption empirically.\n",
        "    1. Can you think of an alternative means of reducing the memory consumption? How would you need to change the framework?\n",
        "1. Implement the various DenseNet versions presented in Table 1 of the DenseNet paper :cite:`Huang.Liu.Van-Der-Maaten.ea.2017`.\n",
        "1. Design an MLP-based model by applying the DenseNet idea. Apply it to the housing price prediction task in :numref:`sec_kaggle_house`.\n"
      ],
      "metadata": {
        "id": "6S_tlXhdlP3m"
      },
      "id": "6S_tlXhdlP3m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "AfpEP6ANlgm9"
      },
      "id": "AfpEP6ANlgm9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Average Pooling vs. Max-Pooling in Transition Layers**\n",
        "\n",
        "Average Pooling is typically used in the transition layers of DenseNet for several reasons:\n",
        "\n",
        "* Feature Preservation: Average pooling retains more information from the feature maps compared to max pooling, which may discard some valuable information by focusing only on the maximum values.\n",
        "* Gradient Flow: Average pooling helps maintain a smoother gradient flow throughout the network, which can be beneficial during backpropagation, especially in very deep networks.\n",
        "* Noise Reduction: Average pooling can be less sensitive to noise, as it considers the average of the values instead of just the peak (max) value, leading to better generalization in some cases.\n",
        "In DenseNet, the average pooling helps reduce the spatial dimensions while retaining a richer representation of the input features.\n",
        "\n",
        "**2. Smaller Model Parameters in DenseNet Compared to ResNet**\n",
        "\n",
        "DenseNet's model parameters are typically smaller than those of ResNet due to the following reasons:\n",
        "\n",
        "* Feature Reuse: In DenseNet, each layer receives input from all preceding layers, which allows for greater feature reuse. This reduces the need for redundant parameters since multiple layers can learn to represent the same feature.\n",
        "* Fewer Filters: Since each layer has direct access to the feature maps of all previous layers, DenseNet can use fewer filters in each layer compared to ResNet, which relies on adding skip connections without directly reusing features.\n",
        "* Growth Rate: The design of DenseNet includes a hyperparameter called the \"growth rate,\" which controls how many new feature maps are added at each layer. This controlled growth allows DenseNet to maintain a smaller parameter count.\n",
        "\n",
        "**3. Memory Consumption Criticism of DenseNet**\n",
        "\n",
        "**3.1 Is this really the case?**\n",
        "\n",
        "Yes, DenseNet is often criticized for its high memory consumption, particularly due to the following reasons:\n",
        "\n",
        "* Storage of Intermediate Feature Maps: Because every layer in DenseNet has access to all previous feature maps, the memory consumption increases with the depth of the network. This leads to a significant number of intermediate feature maps needing to be stored during training.\n",
        "* Increased GPU Memory Usage: With higher resolutions (like 224x224), the number of feature maps and their sizes increase, leading to greater memory usage on the GPU.\n",
        "* To empirically analyze memory consumption, one could use tools such as NVIDIA's nvidia-smi for real-time monitoring of GPU memory during training.\n",
        "\n",
        "**3.2 Alternative Means of Reducing Memory Consumption**\n",
        "\n",
        "To reduce memory consumption in DenseNet, several strategies can be employed:\n",
        "\n",
        "* Reduce Input Size: Using smaller input dimensions can significantly reduce memory usage.\n",
        "* Gradient Checkpointing: This technique saves memory by not storing all intermediate activations and recomputing them during the backward pass.\n",
        "* Dynamic Memory Allocation: Implementing a dynamic approach to allocate memory for feature maps only when needed can help minimize usage.\n",
        "* Reducing Growth Rate: Decreasing the growth rate will lead to fewer feature maps being generated in each layer, thus reducing overall memory consumption.\n",
        "Changing the framework might involve implementing one or more of these strategies directly into the model architecture or training loop, optimizing how layers interact with memory.\n",
        "\n",
        "**4. Implementing Various DenseNet Versions**\n",
        "To implement the different versions of DenseNet as presented in the DenseNet paper, you can use a framework like TensorFlow or PyTorch. Below is a basic outline of how you might implement DenseNet variants based on the configurations described in Table 1 of the DenseNet paper."
      ],
      "metadata": {
        "id": "zX_SBT_Flk2d"
      },
      "id": "zX_SBT_Flk2d"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Dense Block implementation\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, num_layers):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        current_channels = in_channels\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            self.layers.append(self._make_layer(current_channels, growth_rate))\n",
        "            current_channels += growth_rate  # After each layer, the number of channels increases\n",
        "\n",
        "    def _make_layer(self, in_channels, growth_rate):\n",
        "        return nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1)  # growth_rate filters\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            new_features = layer(x)\n",
        "            x = torch.cat((x, new_features), 1)  # Concatenate input with new features\n",
        "        return x\n",
        "\n",
        "# Transition Layer implementation\n",
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels // 2, kernel_size=1)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "# DenseNet implementation\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_blocks, growth_rate, num_layers, num_classes=10):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.dense_blocks = nn.ModuleList()\n",
        "        in_channels = 3  # Input channels (RGB image has 3 channels)\n",
        "\n",
        "        for i in range(num_blocks):\n",
        "            self.dense_blocks.append(DenseBlock(in_channels, growth_rate, num_layers))\n",
        "            in_channels += num_layers * growth_rate  # Update in_channels after each DenseBlock\n",
        "            if i < num_blocks - 1:  # No transition layer after the last block\n",
        "                self.dense_blocks.append(TransitionLayer(in_channels))\n",
        "                in_channels = in_channels // 2  # After transition, in_channels is halved\n",
        "\n",
        "        # Calculate the size of the output after all convolutional layers\n",
        "        self.num_features = self._calculate_num_features(in_channels)\n",
        "        self.fc = nn.Linear(self.num_features, num_classes)  # Adjust based on the flattened size\n",
        "\n",
        "    def _calculate_num_features(self, in_channels):\n",
        "        \"\"\"Calculate the number of features after the last convolutional layer.\"\"\"\n",
        "        # Assuming input image size of 224x224 (you can modify this based on your input size)\n",
        "        input_size = 224\n",
        "        # Simulating passing through layers to get the final feature map size\n",
        "        x = torch.rand(1, 3, input_size, input_size)\n",
        "        for block in self.dense_blocks:\n",
        "            x = block(x)\n",
        "        return x.numel()  # Return the number of elements (flattened size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.dense_blocks:\n",
        "            x = block(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Example of creating a DenseNet with specific configurations\n",
        "model = DenseNet(num_blocks=4, growth_rate=12, num_layers=6)  # Adjust parameters as needed\n",
        "\n",
        "# Proceed to create the dataset and dataloader\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Example training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):  # For illustration, run for 5 epochs\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch [{epoch + 1}/5], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "M0IBcEzkq9F4",
        "outputId": "178c0535-9124-498b-da1f-68165bbc6b80"
      },
      "id": "M0IBcEzkq9F4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 62516172.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-78a63cfa2b61>\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch + 1}/5], Loss: {loss.item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Designing an MLP-based Model Using DenseNet Ideas for Housing Price Prediction**\n",
        "\n",
        "To implement an MLP-based model using DenseNet principles for housing price prediction, you can follow this structure:\n",
        "\n",
        "* Dense Layers: Implement dense layers with similar growth rates as in DenseNet.\n",
        "* Concatenate Outputs: Like in DenseNet, concatenate outputs from previous layers to enhance feature reuse.\n",
        "\n",
        "Here's an outline of how you might set it up"
      ],
      "metadata": {
        "id": "JCEYn-5oq92K"
      },
      "id": "JCEYn-5oq92K"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load California housing datasets\n",
        "train_data = pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "test_data = pd.read_csv('/content/sample_data/california_housing_test.csv')\n",
        "\n",
        "# Set up features (X) and target (y)\n",
        "X_train = train_data.drop('median_house_value', axis=1).values\n",
        "y_train = train_data['median_house_value'].values\n",
        "X_test = test_data.drop('median_house_value', axis=1).values\n",
        "y_test = test_data['median_house_value'].values\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert features and target to tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)  # Ensure the target has shape (n_samples, 1)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.FloatTensor(y_test).view(-1, 1)\n",
        "\n",
        "# Define DenseMLP model class\n",
        "class DenseMLP(nn.Module):\n",
        "    def __init__(self, input_size, growth_rate, num_layers):\n",
        "        super(DenseMLP, self).__init__()\n",
        "        self.input_layer = nn.Linear(input_size, growth_rate)  # First layer matches the input size\n",
        "\n",
        "        # Create a list of dense layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            # Each layer takes the concatenated outputs of all previous layers\n",
        "            self.layers.append(nn.Linear(growth_rate * (i + 1), growth_rate))\n",
        "\n",
        "        # Update output layer to accept the correct number of inputs\n",
        "        self.output_layer = nn.Linear(growth_rate * (num_layers + 1), 1)  # +1 for the input layer output\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial activation for the input layer\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        print(f'After input layer: {x.shape}')  # Debugging: print the shape after the input layer\n",
        "        outputs = [x]  # Store outputs for concatenation\n",
        "\n",
        "        # Iterate through each dense layer\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            # Concatenate all previous outputs as input to the current layer\n",
        "            x = layer(torch.cat(outputs, dim=1))\n",
        "            print(f'After layer {i + 1}: {x.shape}')  # Debugging: print the shape after each layer\n",
        "            outputs.append(x)  # Store the output\n",
        "\n",
        "        # Concatenate all outputs and apply the final layer\n",
        "        x = torch.cat(outputs, dim=1)\n",
        "        print(f'After concatenation of all outputs: {x.shape}')  # Debugging: print shape before output layer\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "# Update input_size to match the number of features in the dataset\n",
        "input_size = X_train.shape[1]  # Should be 8 for the California Housing dataset\n",
        "growth_rate = 10\n",
        "num_layers = 3\n",
        "\n",
        "# Instantiate the model\n",
        "model = DenseMLP(input_size=input_size, growth_rate=growth_rate, num_layers=num_layers)\n",
        "model.train()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    output = model(X_train_tensor)  # Check if this line runs without error\n",
        "    # Calculate the loss\n",
        "    loss = criterion(output, y_train_tensor)  # Compare model output with target\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    predictions = model(X_test_tensor)\n",
        "    # Calculate and print RMSE or other evaluation metrics\n",
        "    rmse = torch.sqrt(criterion(predictions, y_test_tensor)).item()\n",
        "    print(f'Test RMSE: {rmse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoYmTOBUrFtx",
        "outputId": "2760ef92-4735-4100-a0e7-9ce1c13aed19"
      },
      "id": "UoYmTOBUrFtx",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [10/100], Loss: 56425046016.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [20/100], Loss: 56424951808.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [30/100], Loss: 56424833024.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [40/100], Loss: 56424673280.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [50/100], Loss: 56424448000.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [60/100], Loss: 56424087552.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [70/100], Loss: 56423526400.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [80/100], Loss: 56422670336.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [90/100], Loss: 56421371904.0000\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "After input layer: torch.Size([17000, 10])\n",
            "After layer 1: torch.Size([17000, 10])\n",
            "After layer 2: torch.Size([17000, 10])\n",
            "After layer 3: torch.Size([17000, 10])\n",
            "After concatenation of all outputs: torch.Size([17000, 40])\n",
            "Epoch [100/100], Loss: 56419434496.0000\n",
            "After input layer: torch.Size([3000, 10])\n",
            "After layer 1: torch.Size([3000, 10])\n",
            "After layer 2: torch.Size([3000, 10])\n",
            "After layer 3: torch.Size([3000, 10])\n",
            "After concatenation of all outputs: torch.Size([3000, 40])\n",
            "Test RMSE: 234859.0156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "* You’ve learned why average pooling is favored in DenseNet, the advantages of its parameter efficiency, and the memory consumption issues associated with it.\n",
        "* You were provided code implementations for DenseNet variants and an MLP-based model inspired by DenseNet for housing price prediction.\n",
        "* Considerations for memory consumption optimization were discussed, along with empirical approaches to gauge memory usage on different input shapes.\n",
        "If you have any more questions or need further elaboration on any of the topics, feel free to ask!"
      ],
      "metadata": {
        "id": "xaokGB8YrISu"
      },
      "id": "xaokGB8YrISu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 40,
        "tab": [
          "pytorch"
        ],
        "id": "a06d0ab9"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/88)\n"
      ],
      "id": "a06d0ab9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "7ea1dde2"
      },
      "source": [
        "# 8.8. Designing Convolution Network Architectures\n",
        ":label:`sec_cnn-design`\n",
        "\n",
        "The previous sections have taken us on a tour of modern network design for computer vision. Common to all the work we covered was that it greatly relied on the intuition of scientists. Many of the architectures are heavily informed by human creativity and to a much lesser extent by systematic exploration of the design space that deep networks offer. Nonetheless, this *network engineering* approach has been tremendously successful.\n",
        "\n",
        "Ever since AlexNet (:numref:`sec_alexnet`)\n",
        "beat conventional computer vision models on ImageNet,\n",
        "it has become popular to construct very deep networks\n",
        "by stacking blocks of convolutions, all designed according to the same pattern.\n",
        "In particular, $3 \\times 3$ convolutions were\n",
        "popularized by VGG networks (:numref:`sec_vgg`).\n",
        "NiN (:numref:`sec_nin`) showed that even $1 \\times 1$ convolutions could\n",
        "be beneficial by adding local nonlinearities.\n",
        "Moreover, NiN solved the problem of aggregating information at the head of a network\n",
        "by aggregating across all locations.\n",
        "GoogLeNet (:numref:`sec_googlenet`) added multiple branches of different convolution width,\n",
        "combining the advantages of VGG and NiN in its Inception block.\n",
        "ResNets (:numref:`sec_resnet`)\n",
        "changed the inductive bias towards the identity mapping (from $f(x) = 0$). This allowed for very deep networks. Almost a decade later, the ResNet design is still popular, a testament to its design. Lastly, ResNeXt (:numref:`subsec_resnext`) added grouped convolutions, offering a better trade-off between parameters and computation. A precursor to Transformers for vision, the Squeeze-and-Excitation Networks (SENets) allow for efficient information transfer between locations\n",
        ":cite:`Hu.Shen.Sun.2018`. This was accomplished by computing a per-channel global attention function.\n",
        "\n",
        "Up to now we have omitted networks obtained via *neural architecture search* (NAS) :cite:`zoph2016neural,liu2018darts`. We chose to do so since their cost is usually enormous, relying on brute-force search, genetic algorithms, reinforcement learning, or some other form of hyperparameter optimization. Given a fixed search space,\n",
        "NAS uses a search strategy to automatically select\n",
        "an architecture based on the returned performance estimation.\n",
        "The outcome of NAS\n",
        "is a single network instance. EfficientNets are a notable outcome of this search :cite:`tan2019efficientnet`.\n",
        "\n",
        "In the following we discuss an idea that is quite different to the quest for the *single best network*. It is computationally relatively inexpensive, it leads to scientific insights on the way, and it is quite effective in terms of the quality of outcomes. Let's review the strategy by :citet:`Radosavovic.Kosaraju.Girshick.ea.2020` to *design network design spaces*. The strategy combines the strength of manual design and NAS. It accomplishes this by operating on *distributions of networks* and optimizing the distributions in a way to obtain good performance for entire families of networks. The outcome of it are *RegNets*, specifically RegNetX and RegNetY, plus a range of guiding principles for the design of performant CNNs.\n"
      ],
      "id": "7ea1dde2"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:41.106812Z",
          "iopub.status.busy": "2023-08-18T19:46:41.106523Z",
          "iopub.status.idle": "2023-08-18T19:46:44.212758Z",
          "shell.execute_reply": "2023-08-18T19:46:44.211435Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "d2d025e9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ],
      "id": "d2d025e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "a6e554d6"
      },
      "source": [
        "## 8.8.1. The AnyNet Design Space\n",
        ":label:`subsec_the-anynet-design-space`\n",
        "\n",
        "The description below closely follows the reasoning in :citet:`Radosavovic.Kosaraju.Girshick.ea.2020` with some abbreviations to make it fit in the scope of the book.\n",
        "To begin, we need a template for the family of networks to explore. One of the commonalities of the designs in this chapter is that the networks consist of a *stem*, a *body* and a *head*. The stem performs initial image processing, often through convolutions with a larger window size. The body consists of multiple blocks, carrying out the bulk of the transformations needed to go from raw images to object representations. Lastly, the head converts this into the desired outputs, such as via a softmax regressor for multiclass classification.\n",
        "The body, in turn, consists of multiple stages, operating on the image at decreasing resolutions. In fact, both the stem and each subsequent stage quarter the spatial resolution. Lastly, each stage consists of one or more blocks. This pattern is common to all networks, from VGG to ResNeXt. Indeed, for the design of generic AnyNet networks, :citet:`Radosavovic.Kosaraju.Girshick.ea.2020` used the ResNeXt block of :numref:`fig_resnext_block`.\n",
        "\n",
        "\n",
        "![The AnyNet design space. The numbers $(\\mathit{c}, \\mathit{r})$ along each arrow indicate the number of channels $c$ and the resolution $\\mathit{r} \\times \\mathit{r}$ of the images at that point. From left to right: generic network structure composed of stem, body, and head; body composed of four stages; detailed structure of a stage; two alternative structures for blocks, one without downsampling and one that halves the resolution in each dimension. Design choices include depth $\\mathit{d_i}$, the number of output channels $\\mathit{c_i}$, the number of groups $\\mathit{g_i}$, and bottleneck ratio $\\mathit{k_i}$ for any stage $\\mathit{i}$.](http://d2l.ai/_images/anynet.svg)\n",
        ":label:`fig_anynet_full`\n",
        "\n",
        "Let's review the structure outlined in :numref:`fig_anynet_full` in detail. As mentioned, an AnyNet consists of a stem, body, and head. The stem takes as its input RGB images (3 channels), using a $3 \\times 3$ convolution with a stride of $2$, followed by a batch norm, to halve the resolution from $r \\times r$ to $r/2 \\times r/2$. Moreover, it generates $c_0$ channels that serve as input to the body.\n",
        "\n",
        "Since the network is designed to work well with ImageNet images of shape $224 \\times 224 \\times 3$, the body serves to reduce this to $7 \\times 7 \\times c_4$ through 4 stages (recall that $224 / 2^{1+4} = 7$), each with an eventual stride of $2$. Lastly, the head employs an entirely standard design via global average pooling, similar to NiN (:numref:`sec_nin`), followed by a fully connected layer to emit an $n$-dimensional vector for $n$-class classification.\n",
        "\n",
        "Most of the relevant design decisions are inherent to the body of the network. It proceeds in stages, where each stage is composed of the same type of ResNeXt blocks as we discussed in :numref:`subsec_resnext`. The design there is again entirely generic: we begin with a block that halves the resolution by using a stride of $2$ (the rightmost in :numref:`fig_anynet_full`). To match this, the residual branch of the ResNeXt block needs to pass through a $1 \\times 1$ convolution. This block is followed by a variable number of additional ResNeXt blocks that leave both resolution and the number of channels unchanged. Note that a common design practice is to add a slight bottleneck in the design of convolutional blocks.\n",
        "As such, with bottleneck ratio $k_i \\geq 1$ we afford some number of channels, $c_i/k_i$,  within each block for stage $i$ (as the experiments show, this is not really effective and should be skipped). Lastly, since we are dealing with ResNeXt blocks, we also need to pick the number of groups $g_i$ for grouped convolutions at stage $i$.\n",
        "\n",
        "This seemingly generic design space provides us nonetheless with many parameters: we can set the block width (number of channels) $c_0, \\ldots c_4$, the depth (number of blocks) per stage $d_1, \\ldots d_4$, the bottleneck ratios $k_1, \\ldots k_4$, and the group widths (numbers of groups) $g_1, \\ldots g_4$.\n",
        "In total this adds up to 17 parameters, resulting in an unreasonably large number of configurations that would warrant exploring. We need some tools to reduce this huge design space effectively. This is where the conceptual beauty of design spaces comes in. Before we do so, let's implement the generic design first.\n"
      ],
      "id": "a6e554d6"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:44.217808Z",
          "iopub.status.busy": "2023-08-18T19:46:44.216883Z",
          "iopub.status.idle": "2023-08-18T19:46:44.224255Z",
          "shell.execute_reply": "2023-08-18T19:46:44.223047Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "0bcf1d35"
      },
      "outputs": [],
      "source": [
        "class AnyNet(d2l.Classifier):\n",
        "    def stem(self, num_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU())"
      ],
      "id": "0bcf1d35"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "e24d3006"
      },
      "source": [
        "Each stage consists of `depth` ResNeXt blocks,\n",
        "where `num_channels` specifies the block width.\n",
        "Note that the first block halves the height and width of input images.\n"
      ],
      "id": "e24d3006"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:44.228508Z",
          "iopub.status.busy": "2023-08-18T19:46:44.227739Z",
          "iopub.status.idle": "2023-08-18T19:46:44.236181Z",
          "shell.execute_reply": "2023-08-18T19:46:44.234611Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "c6faf93f"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(AnyNet)\n",
        "def stage(self, depth, num_channels, groups, bot_mul):\n",
        "    blk = []\n",
        "    for i in range(depth):\n",
        "        if i == 0:\n",
        "            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,\n",
        "                use_1x1conv=True, strides=2))\n",
        "        else:\n",
        "            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul))\n",
        "    return nn.Sequential(*blk)"
      ],
      "id": "c6faf93f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 16,
        "id": "fb035054"
      },
      "source": [
        "Putting the network stem, body, and head together,\n",
        "we complete the implementation of AnyNet.\n"
      ],
      "id": "fb035054"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:44.241780Z",
          "iopub.status.busy": "2023-08-18T19:46:44.240678Z",
          "iopub.status.idle": "2023-08-18T19:46:44.250216Z",
          "shell.execute_reply": "2023-08-18T19:46:44.248805Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "id": "18a44834"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(AnyNet)\n",
        "def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):\n",
        "    super(AnyNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.stem(stem_channels))\n",
        "    for i, s in enumerate(arch):\n",
        "        self.net.add_module(f'stage{i+1}', self.stage(*s))\n",
        "    self.net.add_module('head', nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "    self.net.apply(d2l.init_cnn)"
      ],
      "id": "18a44834"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 19,
        "id": "114b65ed"
      },
      "source": [
        "## 8.8.2. Distributions and Parameters of Design Spaces\n",
        "\n",
        "As just discussed in :numref:`subsec_the-anynet-design-space`, parameters of a design space are hyperparameters of networks in that design space.\n",
        "Consider the problem of identifying good parameters in the AnyNet design space. We could try finding the *single best* parameter choice for a given amount of computation (e.g., FLOPs and compute time). If we allowed for even only *two* possible choices for each parameter, we would have to explore $2^{17} = 131072$ combinations to find the best solution. This is clearly infeasible because of its exorbitant cost. Even worse, we do not really learn anything from this exercise in terms of how one should design a network. Next time we add, say, an X-stage, or a shift operation, or similar, we would need to start from scratch. Even worse, due to the stochasticity in training (rounding, shuffling, bit errors), no two runs are likely to produce exactly the same results. A better strategy would be to try to determine general guidelines of how the choices of parameters should be related. For instance, the bottleneck ratio, the number of channels, blocks, groups, or their change between layers should ideally be governed by a collection of simple rules. The approach in :citet:`radosavovic2019network` relies on the following four assumptions:\n",
        "\n",
        "1. We assume that general design principles actually exist, so that many networks satisfying these requirements should offer good performance. Consequently, identifying a *distribution* over networks can be a sensible strategy. In other words, we assume that there are many good needles in the haystack.\n",
        "1. We need not train networks to convergence before we can assess whether a network is good. Instead, it is sufficient to use the intermediate results as reliable guidance for final accuracy. Using (approximate) proxies to optimize an objective is referred to as multi-fidelity optimization :cite:`forrester2007multi`. Consequently, design optimization is carried out, based on the accuracy achieved after only a few passes through the dataset, reducing the cost significantly.\n",
        "1. Results obtained at a smaller scale (for smaller networks) generalize to larger ones. Consequently, optimization is carried out for networks that are structurally similar, but with a smaller number of blocks, fewer channels, etc. Only in the end will we need to verify that the so-found networks also offer good performance at scale.\n",
        "1. Aspects of the design can be approximately factorized so that it is possible to infer their effect on the quality of the outcome somewhat independently. In other words, the optimization problem is moderately easy.\n",
        "\n",
        "These assumptions allow us to test many networks cheaply. In particular, we can *sample* uniformly from the space of configurations and evaluate their performance. Subsequently, we can evaluate the quality of the choice of parameters by reviewing the *distribution* of error/accuracy that can be achieved with said networks. Denote by $F(e)$ the cumulative distribution function (CDF) for errors committed by networks of a given design space, drawn using probability disribution $p$. That is,\n",
        "\n",
        "$$F(e, p) \\stackrel{\\textrm{def}}{=} P_{\\textrm{net} \\sim p} \\{e(\\textrm{net}) \\leq e\\}.$$\n",
        "\n",
        "Our goal is now to find a distribution $p$ over *networks* such that most networks have a very low error rate and where the support of $p$ is concise. Of course, this is computationally infeasible to perform accurately. We resort to a sample of networks $\\mathcal{Z} \\stackrel{\\textrm{def}}{=} \\{\\textrm{net}_1, \\ldots \\textrm{net}_n\\}$ (with errors $e_1, \\ldots, e_n$, respectively) from $p$ and use the empirical CDF $\\hat{F}(e, \\mathcal{Z})$ instead:\n",
        "\n",
        "$$\\hat{F}(e, \\mathcal{Z}) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}(e_i \\leq e).$$\n",
        "\n",
        "Whenever the CDF for one set of choices majorizes (or matches) another CDF it follows that its choice of parameters is superior (or indifferent). Accordingly\n",
        ":citet:`Radosavovic.Kosaraju.Girshick.ea.2020` experimented with a shared network bottleneck ratio $k_i = k$ for all stages $i$ of the network. This gets rid of three of the four parameters governing the bottleneck ratio. To assess whether this (negatively) affects the performance one can draw networks from the constrained and from the unconstrained distribution and compare the corresonding CDFs. It turns out that this constraint does not affect the accuracy of the distribution of networks at all, as can be seen in the first panel of :numref:`fig_regnet-fig`.\n",
        "Likewise, we could choose to pick the same group width $g_i = g$ occurring at the various stages of the network. Again, this does not affect performance, as can be seen in the second panel of :numref:`fig_regnet-fig`.\n",
        "Both steps combined reduce the number of free parameters by six.\n",
        "\n",
        "![Comparing error empirical distribution functions of design spaces. $\\textrm{AnyNet}_\\mathit{A}$ is the original design space; $\\textrm{AnyNet}_\\mathit{B}$ ties the bottleneck ratios, $\\textrm{AnyNet}_\\mathit{C}$ also ties group widths, $\\textrm{AnyNet}_\\mathit{D}$ increases the network depth across stages. From left to right: (i) tying bottleneck ratios has no effect on performance; (ii) tying group widths has no effect on performance; (iii) increasing network widths (channels) across stages improves performance; (iv) increasing network depths across stages improves performance. Figure courtesy of :citet:`Radosavovic.Kosaraju.Girshick.ea.2020`.](../img/regnet-fig.png)\n",
        ":label:`fig_regnet-fig`\n",
        "\n",
        "Next we look for ways to reduce the multitude of potential choices for width and depth of the stages. It is a reasonable assumption that, as we go deeper, the number of channels should increase, i.e., $c_i \\geq c_{i-1}$ ($w_{i+1} \\geq w_i$ per their notation in :numref:`fig_regnet-fig`), yielding\n",
        "$\\textrm{AnyNetX}_D$. Likewise, it is equally reasonable to assume that as the stages progress, they should become deeper, i.e., $d_i \\geq d_{i-1}$, yielding $\\textrm{AnyNetX}_E$. This can be experimentally verified in the third and fourth panel of :numref:`fig_regnet-fig`, respectively.\n",
        "\n"
      ],
      "id": "114b65ed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.8.3. RegNet\n",
        "\n",
        "The resulting $\\textrm{AnyNetX}_E$ design space consists of simple networks\n",
        "following easy-to-interpret design principles:\n",
        "\n",
        "* Share the bottleneck ratio $k_i = k$ for all stages $i$;\n",
        "* Share the group width $g_i = g$ for all stages $i$;\n",
        "* Increase network width across stages: $c_{i} \\leq c_{i+1}$;\n",
        "* Increase network depth across stages: $d_{i} \\leq d_{i+1}$.\n",
        "\n",
        "This leaves us with a final set of choices: how to pick the specific values for the above parameters of the eventual $\\textrm{AnyNetX}_E$ design space. By studying the best-performing networks from the distribution in $\\textrm{AnyNetX}_E$ one can observe the following: the width of the network ideally increases linearly with the block index across the network, i.e., $c_j \\approx c_0 + c_a j$, where $j$ is the block index and slope $c_a > 0$. Given that we get to choose a different block width only per stage, we arrive at a piecewise constant function, engineered to match this dependence. Furthermore, experiments also show that a bottleneck ratio of $k = 1$ performs best, i.e., we are advised not to use bottlenecks at all.\n",
        "\n",
        "We recommend the interested reader reviews further details in the design of specific networks for different amounts of computation by perusing :citet:`Radosavovic.Kosaraju.Girshick.ea.2020`. For instance, an effective 32-layer RegNetX variant is given by $k = 1$ (no bottleneck), $g = 16$ (group width is 16), $c_1 = 32$ and $c_2 = 80$ channels for the first and second stage, respectively, chosen to be $d_1=4$ and $d_2=6$ blocks deep. The astonishing insight from the design is that it still applies, even when investigating networks at a larger scale. Even better, it even holds for Squeeze-and-Excitation (SE) network designs (RegNetY) that have a global channel activation :cite:`Hu.Shen.Sun.2018`.\n"
      ],
      "metadata": {
        "id": "Kj1L_iNh7vSF"
      },
      "id": "Kj1L_iNh7vSF"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:44.255171Z",
          "iopub.status.busy": "2023-08-18T19:46:44.254345Z",
          "iopub.status.idle": "2023-08-18T19:46:44.262677Z",
          "shell.execute_reply": "2023-08-18T19:46:44.261273Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "id": "dab5f41a"
      },
      "outputs": [],
      "source": [
        "class RegNetX32(AnyNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        stem_channels, groups, bot_mul = 32, 16, 1\n",
        "        depths, channels = (4, 6), (32, 80)\n",
        "        super().__init__(\n",
        "            ((depths[0], channels[0], groups, bot_mul),\n",
        "             (depths[1], channels[1], groups, bot_mul)),\n",
        "            stem_channels, lr, num_classes)"
      ],
      "id": "dab5f41a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 22,
        "id": "cd897988"
      },
      "source": [
        "We can see that each RegNetX stage progressively reduces resolution and increases output channels.\n"
      ],
      "id": "cd897988"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:44.267142Z",
          "iopub.status.busy": "2023-08-18T19:46:44.266080Z",
          "iopub.status.idle": "2023-08-18T19:46:44.365256Z",
          "shell.execute_reply": "2023-08-18T19:46:44.364396Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "id": "75a56c8e",
        "outputId": "79dfd061-8c7e-4847-80dd-56d941b06235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t torch.Size([1, 32, 48, 48])\n",
            "Sequential output shape:\t torch.Size([1, 32, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 80, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "RegNetX32().layer_summary((1, 1, 96, 96))"
      ],
      "id": "75a56c8e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 26,
        "id": "d568cc20"
      },
      "source": [
        "## 8.8.4. Training\n",
        "\n",
        "Training the 32-layer RegNetX on the Fashion-MNIST dataset is just like before.\n"
      ],
      "id": "d568cc20"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:44.368862Z",
          "iopub.status.busy": "2023-08-18T19:46:44.368269Z",
          "iopub.status.idle": "2023-08-18T19:50:01.782279Z",
          "shell.execute_reply": "2023-08-18T19:50:01.781241Z"
        },
        "origin_pos": 27,
        "tab": [
          "pytorch"
        ],
        "id": "91cbec9a",
        "outputId": "d4dabffe-6180-4a2d-fbc7-41231e43479c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-09-28T11:23:30.557319</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"maf79198600\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#maf79198600\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#maf79198600\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#maf79198600\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#maf79198600\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#maf79198600\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#maf79198600\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"mddc4e29aff\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mddc4e29aff\" x=\"30.103125\" y=\"137.872442\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 141.67166) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mddc4e29aff\" x=\"30.103125\" y=\"113.717079\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 117.516298) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mddc4e29aff\" x=\"30.103125\" y=\"89.561717\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 93.360935) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mddc4e29aff\" x=\"30.103125\" y=\"65.406354\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.7 -->\n      <g transform=\"translate(7.2 69.205573) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mddc4e29aff\" x=\"30.103125\" y=\"41.250991\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 45.05021) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mddc4e29aff\" x=\"30.103125\" y=\"17.095629\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.9 -->\n      <g transform=\"translate(7.2 20.894848) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 116.265098 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 116.265098 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 49.633125 33.080145 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_17\"/>\n   <g id=\"line2d_18\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 116.265098 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 49.633125 33.080145 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 64.078191 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 116.265098 \nL 54.442752 139.5 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 49.633125 33.080145 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 64.078191 \n\" clip-path=\"url(#pc0b3f8ba16)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_25\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc0b3f8ba16\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = RegNetX32(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "trainer.fit(model, data)"
      ],
      "id": "91cbec9a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 29,
        "id": "f60c0281"
      },
      "source": [
        "## 8.8.5. Discussion\n",
        "\n",
        "With desirable inductive biases (assumptions or preferences) like locality and translation invariance (:numref:`sec_why-conv`)\n",
        "for vision, CNNs have been the dominant architectures in this area. This remained the case from LeNet up until Transformers (:numref:`sec_transformer`) :cite:`Dosovitskiy.Beyer.Kolesnikov.ea.2021,touvron2021training` started surpassing CNNs in terms of accuracy. While much of the recent progress in terms of vision Transformers *can* be backported into CNNs :cite:`liu2022convnet`, it is only possible at a higher computational cost. Just as importantly, recent hardware optimizations (NVIDIA Ampere and Hopper) have only widened the gap in favor of Transformers.\n",
        "\n",
        "It is worth noting that Transformers have a significantly lower degree of inductive bias towards locality and translation invariance than CNNs. That learned structures prevailed is due, not least, to the availability of large image collections, such as LAION-400m and LAION-5B :cite:`schuhmann2022laion` with up to 5 billion images. Quite surprisingly, some of the more relevant work in this context even includes MLPs :cite:`tolstikhin2021mlp`.\n",
        "\n",
        "In sum, vision Transformers (:numref:`sec_vision-transformer`) by now lead in terms of\n",
        "state-of-the-art performance in large-scale image classification,\n",
        "showing that *scalability trumps inductive biases* :cite:`Dosovitskiy.Beyer.Kolesnikov.ea.2021`.\n",
        "This includes pretraining large-scale Transformers (:numref:`sec_large-pretraining-transformers`) with multi-head self-attention (:numref:`sec_multihead-attention`). We invite the readers to dive into these chapters for a much more detailed discussion.\n",
        "\n"
      ],
      "id": "f60c0281"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.8.6. Exercises\n",
        "\n",
        "1. Increase the number of stages to four. Can you design a deeper RegNetX that performs better?\n",
        "1. De-ResNeXt-ify RegNets by replacing the ResNeXt block with the ResNet block. How does your new model perform?\n",
        "1. Implement multiple instances of a \"VioNet\" family by *violating* the design principles of RegNetX. How do they perform? Which of ($d_i$, $c_i$, $g_i$, $b_i$) is the most important factor?\n",
        "1. Your goal is to design the \"perfect\" MLP. Can you use the design principles introduced above to find good architectures? Is it possible to extrapolate from small to large networks?\n"
      ],
      "metadata": {
        "id": "B_W2ejvI79VS"
      },
      "id": "B_W2ejvI79VS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "g0_RDlCl8bw-"
      },
      "id": "g0_RDlCl8bw-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Increase the Number of Stages to Four in RegNetX**\n",
        "\n",
        "RegNetX, as described in \"Designing Network Design Spaces\" by Radosavovic et al., organizes the network into multiple stages where each stage has a different number of filters and block types. In this task, we will deepen RegNetX by increasing the number of stages from three to four, keeping other parameters flexible for experimentation.\n",
        "\n",
        "**Key Implementation Points:**\n",
        "* **Stage Design**: Each stage will consist of a sequence of blocks, where each stage can have different channel configurations and group widths.\n",
        "* **Block Type**: We'll continue using the original RegNetX block for now.\n",
        "Here’s a conceptual example of how to extend RegNetX to four stages:\n",
        "\n"
      ],
      "metadata": {
        "id": "9Om_tS2F8dt_"
      },
      "id": "9Om_tS2F8dt_"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# RegNetX Block (similar to ResNeXt but simplified)\n",
        "class RegNetXBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, group_width=1):\n",
        "        super(RegNetXBlock, self).__init__()\n",
        "        # 1x1 Convolution for reducing channels\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Grouped 3x3 Convolution\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, groups=group_width, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 1x1 Convolution for expanding channels\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Skip connection if needed\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "        else:\n",
        "            self.shortcut = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.shortcut is not None:\n",
        "            shortcut = self.shortcut(shortcut)\n",
        "\n",
        "        x += shortcut\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "# Custom RegNetX Implementation with 4 stages\n",
        "class RegNetX(nn.Module):\n",
        "    def __init__(self, num_classes=10, stages=[32, 64, 128, 256], group_width=4):\n",
        "        super(RegNetX, self).__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, stages[0], kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(stages[0]),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Create stages\n",
        "        self.stage1 = self._make_stage(stages[0], stages[1], blocks=3, stride=1, group_width=group_width)\n",
        "        self.stage2 = self._make_stage(stages[1], stages[2], blocks=4, stride=2, group_width=group_width)\n",
        "        self.stage3 = self._make_stage(stages[2], stages[3], blocks=6, stride=2, group_width=group_width)\n",
        "        self.stage4 = self._make_stage(stages[3], stages[3], blocks=3, stride=2, group_width=group_width)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(stages[-1], num_classes)\n",
        "\n",
        "    def _make_stage(self, in_channels, out_channels, blocks, stride, group_width):\n",
        "        layers = [RegNetXBlock(in_channels, out_channels, stride, group_width)]\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(RegNetXBlock(out_channels, out_channels, 1, group_width))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "model = RegNetX(num_classes=10)\n"
      ],
      "metadata": {
        "id": "5v5ruYJt8okG"
      },
      "id": "5v5ruYJt8okG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve performance:\n",
        "\n",
        "Experiment with varying the number of blocks per stage (e.g., deeper models).\n",
        "Adjust the group width and width multiplier.\n",
        "\n",
        "**2. De-ResNeXt-ify RegNet by Using ResNet Blocks**\n",
        "\n",
        "The RegNetX model is based on the ResNeXt architecture with grouped convolutions. To \"de-ResNeXt-ify\" it, we can replace the RegNetXBlock with a standard ResNet block, which removes grouped convolutions.\n",
        "\n",
        "**Replace RegNetXBlock with a Basic ResNet Block:**"
      ],
      "metadata": {
        "id": "mx0LRqBx8vbW"
      },
      "id": "mx0LRqBx8vbW"
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "        else:\n",
        "            self.shortcut = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.shortcut is not None:\n",
        "            shortcut = self.shortcut(shortcut)\n",
        "\n",
        "        x += shortcut\n",
        "        x = self.relu(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "NIgI6wxX87-P"
      },
      "id": "NIgI6wxX87-P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After replacing the block, train the model and compare its performance to RegNetX.\n",
        "\n",
        "**3. Implement Multiple \"VioNet\" Models**\n",
        "\n",
        "To create the \"VioNet\" family, you could intentionally violate the RegNet design principles, such as:\n",
        "\n",
        "* Irregular block structures: Unequal channel increases per stage.\n",
        "Non-uniform group widths: Use different group widths across stages.\n",
        "Non-optimized scaling of stages.\n",
        "* Experiment with different values of parameters like depth (di), width (ci), group width (gi), and bottleneck ratio (bi), and evaluate which has the most significant impact on performance.\n",
        "\n",
        "**4. Design the \"Perfect\" MLP**\n",
        "\n",
        "Using principles from designing RegNet, you could apply similar ideas to multi-layer perceptrons (MLPs), such as:\n",
        "\n",
        "* Layer widths follow a simple rule (e.g., linear or exponential increase).\n",
        "* Depth control through progressive widening.\n",
        "\n",
        "You can design MLP architectures for a task like predicting housing prices and test how well you can extrapolate from small to large networks by systematically increasing depth and width:"
      ],
      "metadata": {
        "id": "W846OEa_8_Gs"
      },
      "id": "W846OEa_8_Gs"
    },
    {
      "cell_type": "code",
      "source": [
        "class PerfectMLP(nn.Module):\n",
        "    def __init__(self, input_dim, layers=[64, 128, 256], output_dim=1):\n",
        "        super(PerfectMLP, self).__init__()\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        prev_dim = input_dim\n",
        "        for layer_dim in layers:\n",
        "            self.fc_layers.append(nn.Sequential(nn.Linear(prev_dim, layer_dim), nn.ReLU(inplace=True)))\n",
        "            prev_dim = layer_dim\n",
        "        self.output = nn.Linear(prev_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.fc_layers:\n",
        "            x = layer(x)\n",
        "        x = self.output(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "4mKgx2hE9lCV"
      },
      "id": "4mKgx2hE9lCV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now experiment with layer sizes and widths to find optimal architectures based on performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EC0kSFxY9m-R"
      },
      "id": "EC0kSFxY9m-R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "pytorch"
        ],
        "id": "cdaec6a5"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/7463)\n"
      ],
      "id": "cdaec6a5"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}